[
["index.html", "Статистика, R и анализ данных 1 Начало работы", " Статистика, R и анализ данных Поздняков Иван, Петухова Татьяна 2019-05-11 1 Начало работы Здесь будут лежать конспекты занятий, задания и другие материалы. Сайт сделан с помощью RMarkdown, все исходные .RMD файлы лежат на гитхабе "],
["intro.html", "2 День 1. Основы R 2.1 Знакомимся с самым базовым 2.2 Типы данных 2.3 Вектор 2.4 Матрицы (matrix) 2.5 Списки (list) 2.6 Data.frame 2.7 Начинаем работу с реальными данными", " 2 День 1. Основы R 2.1 Знакомимся с самым базовым 2.1.1 RStudio Первый и вполне закономерный вопрос: зачем мы ставили R и отдельно еще какой-то RStudio? Если опустить незначительные детали, то R - это сам язык программирования, а RStudio - это среда (IDE), которая позволяет в этом языке очень удобно работать. Здесь и далее подобные вставки будут в основном для тех, кто пришел из других языков (особенно Python и MATLAB) и просто интересующихся. Остальные могут пропускать. Естественно, RStudio - не единственная среда для R, но, определенно, самая крутая. Почти все пользуются именно ею и не стоит тратить время на поиск чего-то более удобного и лучшего. Если Вы привыкли к Jupyter Notebook, то здесь тоже есть ноутбуки, но еще и кое-что покруче - RMarkdown. И с этим мы тоже разберемся! Так, давайте взглянем на то, что нам тут открылось: Это консоль - здесь Вы будете писать весь код и получать результаты вычислений. Здесь вы можете увидеть Ваши переменные, это поле будет автоматически обновляться по мере того, как вы будете запускать строчки кода и создавать переменные. Еще там есть вкладка с историей - лог всего что вы запускали. Здесь есть очень много всего. Во-первых, небольшой файловый менеджер, во-вторых, там будут появляться графики, когда вы будете их рисовать. Там же есть вкладка с вашими библиотеками (libraries) и хэлп по функциям. Но об этом потом. 2.1.2 R как калькулятор Ой-ей, консоль, скрипт че-то все непонятно. Давайте начнем с самого простого и попробуем использовать R как простой калькулятор. +, -, *, /, ^ (степень), () и т.д. Просто запускайте в консоли пока не надоест: 40+2 ## [1] 42 3-2 ## [1] 1 5*6 ## [1] 30 99/9 ## [1] 11 2^3 ## [1] 8 (2+2)*2 ## [1] 8 Ничего сложного, верно? Вводим выражение и получаем результат. Порядок выполнения арифметических операций как в математике, так что не забывайте про скобочки. 2.1.3 Функции Давайте теперь извлечем корень из какого-нибудь числа. В принципе, если Вы помните школьный курс математики, то возведения в степень Вам будет достаточно: 16^0.5 ## [1] 4 Ну а если нет, то можете воспользоваться специальной функцией: это обычно какие-то буквенные символы с круглыми скобками сразу после названия функции. Внутри этих функций находятся какие-то данные, которые как-то обработаются этой функцией. Вот, например, функция для корня: sqrt(16) ## [1] 4 R - case-sensitive язык, т.е. регистр важен. SQRT(16) не будет работать. А вот так выглядит функция логарифма: log(8) ## [1] 2.079442 Так, вроде бы все нормально, но… Если Вы еще что-то помните из школьной математики, то должны понимать, что что-то здесь не так. Здесь не хватает основания логарифма! Логарифм - показатель степени, в которую надо возвести число, называемое основанием, чтобы получить данное число. То есть у логарифма 8 по основанию 2 будет значение 3: \\(\\log_2 8 = 3\\) То есть если возвести 2 в степень 3 у нас будет 8: \\(2^3 = 8\\) Только наша функция считает все как-то не так. Чтобы понять, что происходит, нам нужно залезть в хэлп этой функции: ?log Справа внизу в RStudio появится вот такое окно: Действительно, у этой функции есть еще аргумент base =. По дефолту он равен числу Эйлера (2.7182818…), т.е. функция считает натуральный логарифм. В большинстве функций R есть какой-то основной инпут - данные в том или ином формате, а есть и дополнительные параметры, которые можно прописывать вручную, если дефолтные нас не устраивают. log(x = 8, base = 2) ## [1] 3 …или просто (если Вы уверены в порядке переменных): log(8,2) ## [1] 3 Более того, Вы можете использовать оутпут одних функций как инпут для других: log(8, sqrt(4)) ## [1] 3 Отличненько. Мы еще много раз будем возвращаться к функциям. Вообще, функции - это одна из важнейших штук в R (примерно так же как и в Python). Мы будем создавать свои функции, использовать функции как инпут для функций и многое-многое другое. В R очень крутые возможности работы с функциями. Поэтому подружитесь с функциями, они клевые. Арифметические знаки, которые мы использовали: +,-,/,^ и т.д. называются операторами и на самом деле тоже являются функциями: &#39;+&#39;(3,4) ## [1] 7 2.1.4 Переменные Важная штука в программировании на практически любом языке - возможность сохранять значения в **переменных. В R это обычно делается с помощью вот этих символов: &lt;-* (но можно использовать и обычное =, хотя это не очень принято). Для этого есть удобное сочетание клавиш: нажмите одновременно Alt - (или option - на Маке). a &lt;- 2 a ## [1] 2 После присвоения переменная появляется во вкладке Environment в RStudio: Можно использовать переменные в функциях и просто вычислениях: b &lt;- a^a+a*a b ## [1] 8 log(b,a) ## [1] 3 Вы можете сравнивать разные переменные: a == b ## [1] FALSE Заметьте, что сравнивая две переменные мы используем два знака равно ==, а не один =. Иначе это будет означать присвоение. a = b a ## [1] 8 Теперь Вы сможете понять комикс про восстание роботов на следующей странице (пусть он и совсем про другой язык программирования) Этот комикс объясняет, как важно не путать присваивание и сравнение (хотя я иногда путаю до сих пор =( ). Иногда нам нужно проверить на неравенство: a &lt;- 2 b &lt;- 3 a==b ## [1] FALSE a!=b ## [1] TRUE Восклицательный язык в программировании вообще и в R в частности стандартно означает отрицание. Еще мы можем сравнивать на больше/меньше: a&gt;b ## [1] FALSE a&lt;b ## [1] TRUE a&gt;=b ## [1] FALSE a&lt;=b ## [1] TRUE 2.2 Типы данных До этого момента мы работали только с числами (numeric): class(a) ## [1] &quot;numeric&quot; Вообще, в R много типов numeric: integer (целые), double (с десятичной дробью), complex (комплексные числа). Последние пишутся так: complexnumber &lt;- 2+2i Однако в R с этим обычно можно вообще не заморачиваться, R сам будет конвертить между форматами при необходимости. Немного подробностей здесь: Разница между numeric и integer, Как работать с комплексными числами в R Теперь же нам нужно ознакомиться с двумя другими важными типами данных в R: character: строки символов. Они должны выделяться кавычками. Можно использовать как “”, так и ’’ (что удобно, когда строчка внутри уже содержит какие-то кавычки). s &lt;- &quot;Мы выучим R за май&quot; s ## [1] &quot;Мы выучим R за май&quot; class(s) ## [1] &quot;character&quot; logical: просто TRUE или FALSE. Можно еще писать T и F (но не True и False!) t1 &lt;- TRUE t2 &lt;- T f1 &lt;- FALSE f2 &lt;- F t1 ## [1] TRUE f2 ## [1] FALSE Теперь вы можете догадаться, что результаты сравнения, например, числовых или строковых переменных вы можете сохранять в переменные тоже! comparison &lt;- a == b comparison ## [1] FALSE Это нам потом очень понадобится, когда мы будем работать с реальными данными: нам нужно будет постоянно вытаскивать какие-то данные из датасета, это построенно как раз на игре со сравнением переменных. Чтобы этим хорошо уметь пользоваться, нам нужно еще освоить как работать с логическими операторами. Про один мы немного уже говорили - это не (!): t1 ## [1] TRUE !t1 ## [1] FALSE !!t1 #Двойное отрицание! ## [1] TRUE Еще есть И (выдаст TRUE только в том случае если обе переменные TRUE): t1&amp;t2 ## [1] TRUE t1&amp;f1 ## [1] FALSE И ИЛИ (выдаст TRUE в случае если хотя бы одна из переменных TRUE): t1 | f1 ## [1] TRUE f1 | f2 ## [1] FALSE Ок, я Вас поздравляю, мы только что разобрались с самой занудной частью. Пора переходить к важному и интересному. ВЕКТОРАМ! 2.3 Вектор Если у вас не было линейной алгебры (или у вас с ней было все плохо), то просто запомните, что вектор (==atomic vector ==atomic) - это столбик чисел в определенном порядке. P.S. Если вы привыкли из школьного курса физики считать вектора стрелочками, то не спешите возмущаться и паниковать. Представьте стрелочки как точки из нуля координат {0,0} до какой-то точки на координатной плоскости, например, {2,1}. Вот последние два числа и будем считать вектором. Поэтому постарайтесь на время выбросить стрелочки из головы. На самом деле, мы уже работали с векторами в R, просто Вы об этом не догадывались. На самом деле, в R нет как таковых “значений”, есть вектора длиной 1. Такие дела! Чтобы создать вектор из нескольких значений, нужно воспользоваться функцией c(): c(4,8,15,16,23,42) ## [1] 4 8 15 16 23 42 c(&quot;Хэй&quot;, &quot;Хэй&quot;, &quot;Ха&quot;) ## [1] &quot;Хэй&quot; &quot;Хэй&quot; &quot;Ха&quot; Одна из самых мерзких и раздражающих причин ошибок в коде - это использование с из кириллицы вместо c из латиницы. Видите разницу? И я не вижу. А R видит. Для создания числовых векторов есть удобный оператор : 1:10 ## [1] 1 2 3 4 5 6 7 8 9 10 5:-3 ## [1] 5 4 3 2 1 0 -1 -2 -3 Этот оператор создает вектор от первого числа до второго с шагом 1. Вы не представляете, как часто эта штука нам пригодится… Если же нужно сделать вектор с другим шагом, то есть функция seq(): seq(10,100, by = 10) ## [1] 10 20 30 40 50 60 70 80 90 100 Кроме того, можно задавать не шаг, а длину вектора. Тогда шаг функция seq() посчитает сама: seq(1,13, length.out = 4) ## [1] 1 5 9 13 Другая функция - rep() - позволяет создавать вектора с повторяющимися значениями. Первый аргумент - значение, которое нужно повторять, а второй аргумент - сколько раз повторять. rep(1, 5) ## [1] 1 1 1 1 1 И первый, и второй аргумент могут быть векторами! rep(1:3, 3) ## [1] 1 2 3 1 2 3 1 2 3 rep(1:3, 1:3) ## [1] 1 2 2 3 3 3 Еще можно объединять вектора (что мы, по сути, и делали, просто с векторами длиной 1): v1 &lt;- c(&quot;Hey&quot;, &quot;Ho&quot;) v2 &lt;- c(&quot;Let&#39;s&quot;, &quot;Go!&quot;) c(v1,v2) ## [1] &quot;Hey&quot; &quot;Ho&quot; &quot;Let&#39;s&quot; &quot;Go!&quot; Ramones in R 2.3.1 Coercion Что будет, если вы объедините два вектора с значениями разных типов? Ошибка? Мы уже обсуждали, что в atomic может быть только один тип данных. В “нормальных” языках программирования при операции с разноразмерными структурами мы бы получили ошибку. А вот в R при несовпадении типов пройзойдет попытка привести типы к “общему знаменателю”, то есть конвертировать данные в более “широкий” тип. Например: c(FALSE, 2) ## [1] 0 2 FALSE превратился в 0 (а TRUE превратился бы в 1), чтобы можно было оба значения объединить в вектор. То же самое произошло бы в случае операций с векторами: 2 + TRUE ## [1] 3 Это называется coercion. Более сложный пример: c(TRUE, 3, &quot;Привет&quot;) ## [1] &quot;TRUE&quot; &quot;3&quot; &quot;Привет&quot; У R есть иерархия коэрсинга: NULL &lt; raw &lt; logical &lt; integer &lt; double &lt; complex &lt; character &lt; list &lt; expression. Мы из этого списка еще многого не знаем, сейчас важно запомнить, что логические данные - TRUE и FALSE - превращаются в 0 и 1 соответственно, а 0 и 1 в строчки &quot;0&quot; и &quot;1&quot;. Если Вы боитесь полагаться на coercion, то можете воспользоваться функциями as.нужныйтипданных: as.numeric(c(T, F, F)) ## [1] 1 0 0 as.character(as.numeric(c(T, F, F))) ## [1] &quot;1&quot; &quot;0&quot; &quot;0&quot; Можно превращать и обратно, например, строковые значения в числовые. Если среди числа встретится буква или другой неподходящий знак, то мы получим NA - пропущенное значение (мы очень скоро научимся с ними работать). as.numeric(c(&quot;1&quot;, &quot;2&quot;, &quot;три&quot;)) ## Warning: в результате преобразования созданы NA ## [1] 1 2 NA 2.3.2 Операции с векторами Все те арифметические операции, что мы использовали ранее, можно использовать с векторами одинаковой длины: n &lt;- 1:4 m &lt;- 4:1 n+m ## [1] 5 5 5 5 n-m ## [1] -3 -1 1 3 n*m ## [1] 4 6 6 4 n/m ## [1] 0.2500000 0.6666667 1.5000000 4.0000000 n^m+m*(n-m) ## [1] -11 5 11 7 Если после какого-нибудь MATLAB Вы привыкли, что по умолчанию операторы работают по правилам линейной алгебры и m*n будет давать скалярное произведение (dot product), то снова нет. Для скалярного произведения нужно использовать операторы с % по краям: n%*%m ## [,1] ## [1,] 20 Абсолютно так же и с операциями с матрицами в R, хотя про матрицы будет немного позже. В принципе, большинство функций в R, которые работают с отдельными значениями, так же хорошо работают и с целыми векторами. Скажем, Вы хотите извлечь корень из нескольких чисел, для этого не нужны никакие циклы (как это обычно делается в других языках программирования). Можно просто “скормить” вектор функции и получить результат применения функции к каждому элементу вектора: sqrt(1:10) ## [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 ## [8] 2.828427 3.000000 3.162278 2.3.3 Recycling Допустим мы хотим совершить какую-нибудь операцию с двумя векторами. Как мы убедились, с этим обычно нет никаких проблем, если они совпадают по длине. А что если вектора не совпадают по длине? Ничего страшного! Здесь будет работать правило recycling’a (правило переписывания). Это означает, что если короткий вектор кратен по длине длинному, то он будет повторять короткий необходимое количество раз: n &lt;- 1:4 m &lt;- 1:2 n*m ## [1] 1 4 3 8 А что будет, если совершать операции с вектором и отдельным значением? Можно считать это частным случаем ресайклинга: короткий вектор длиной 1 будет повторятся столько раз, сколько нужно, чтобы он совпадал по длине с длинным: n*2 ## [1] 2 4 6 8 Если же меньший вектор не кратен большему (например, один из них длиной 3, а другой длиной 4), то R посчитает результат, но выдаст предупреждение. Проблема в том, что эти предупреждения могут в неожиданный момент стать причиной ошибок. Поэтому не стоит полагаться на ресайклинг некратных по длине векторов. См. здесь. А вот ресайклинг кратных по длине векторов - это очень удобная штука, которая используется очень часто. 2.3.4 Индексирование векторов Итак, мы подошли к одному из самых сложных моментов. И одному из основных. От того, как хорошо вы научись с этим работать, зависит весь Ваш дальнейший успех на R-поприще! Речь пойдет об индексировании векторов. Задача, которую Вам придется решать каждые пять минут работы в R - это как выбрать из вектора (или же списка, матрицы и датафрейма - с ними мы очень скоро будем работать) какую-то часть. Для этого используются квадратные скобочки [] (не круглые - они для функций!). Самое простое - это индексировать по номеру индекса - порядку значения в векторе. n &lt;- 1:10 n[1] ## [1] 1 n[10] ## [1] 10 Если вы знакомы с другими языками программирования (не MATLAB, там все так же) и уже научились думать, что индексация с 0 - это очень удобно и очень правильно (ну или просто свыклись с этим), то в R Вам придется переучиться обратно. Здесь первый индекс - это 1, а последний равен длине вектора. С обоих сторон индексы берутся включительно. С помощью индексации можно не только вытаскивать имеющиеся значения в векторе, но и присваивать им новые: n[3] &lt;- 20 n ## [1] 1 2 20 4 5 6 7 8 9 10 Конечно, можно использовать целые векторы для индексации: n[4:7] ## [1] 4 5 6 7 n[10:1] ## [1] 10 9 8 7 6 5 4 20 2 1 Индексация с минусом выдаст вам все значения вектора кроме выбранных: n[-1] ## [1] 2 20 4 5 6 7 8 9 10 n[c(-4, -5)] ## [1] 1 2 20 6 7 8 9 10 Более того, можно использовать логический вектор для индексации. В этом случае нужен логический вектор такой же длины: n[c(T,F,T,F,T,F,T,F,T,F)] ## [1] 1 20 5 7 9 Ну а если они не равны, то тут будет снова работать правило ресайклинга! n[c(T,F)] #то же самое - recycling rule! ## [1] 1 20 5 7 9 Есть еще один способ индексирования векторов, но он несколько более редкий: индексирование по имени. Дело в том, что для значений векторов можно (но не обязательно) присваивать имена: my_named_vector &lt;- c(first = 1, second = 2, third = 3) my_named_vector[&#39;first&#39;] ## first ## 1 А еще можно “вытаскивать” имена из вектора с помощью функции names() и присваивать таким образом новые. d &lt;- 1:4 names(d) &lt;- letters[1:4] d[&quot;a&quot;] ## a ## 1 letters - это “зашитая” в R константа - вектор букв от a до z. Иногда это очень удобно! Кроме того, есть константа LETTERS - то же самое, но заглавными буквами. А еще есть названия месяцев на английском и числовая константа pi. Теперь посчитаем среднее вектора n: mean(n) ## [1] 7.2 А как вытащить все значения, которые больше среднего? Сначала получим логический вектор - какие значения больше среднего: larger &lt;- n&gt;mean(n) larger ## [1] FALSE FALSE TRUE FALSE FALSE FALSE FALSE TRUE TRUE TRUE А теперь используем его для индексирования вектора n: n[larger] ## [1] 20 8 9 10 Можно все это сделать в одну строчку: n[n&gt;mean(n)] ## [1] 20 8 9 10 Предыдущая строчка отражает то, что вы будете постоянно делать в R: вычленять (subset) из данных отдельные куски на основании разных условий. 2.3.5 NA - пропущенные значения В реальных данных у нас часто чего-то не хватает. Например, по какому-то из произведений что-то не удалось посчитать. Для этого в R есть NA. NA - это не строка &quot;NA&quot;, не 0, не пустая строка &quot;&quot; и не FALSE. NA - это NA. Большинство операций с векторами, содержащими NA будут выдавать NA: missed &lt;- NA missed == &quot;NA&quot; ## [1] NA missed == &quot;&quot; ## [1] NA missed == NA ## [1] NA Иногда это очень бесит: n[5] &lt;- NA n ## [1] 1 2 20 4 NA 6 7 8 9 10 mean(n) ## [1] NA Что же делать? Наверное, надо сравнить вектор с NA и исключить этих пакостников. Давайте попробуем: n == NA ## [1] NA NA NA NA NA NA NA NA NA NA Ах да, мы ведь только что узнали, что даже сравнение NA c NA приводит к NA. Даже сравнение NA с NA дает NA! Чтобы этого избежать, используйте функцию is.na(): is.na(n) ## [1] FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE Выкинем их теперь отсюда (и сразу посчитаем среднее). Результат выполнения is.na(n) выдает FALSE в тех местах, где у нас числа и TRUE там, где у нас NA. Нам нужно сделать наоборот. Здесь нам понадобится оператор ! (мы его уже встречали), который инвертирует логические значения: n[!is.na(n)] ## [1] 1 2 20 4 6 7 8 9 10 Ура, мы можем считать среднее! mean(n[!is.na(n)]) ## [1] 7.444444 Теперь Вы понимаете, зачем нужно отрицание (!) Вообще, есть еще один из способов посчитать среднее, если есть NA. Для этого надо залезть в хэлп по функции mean(): ?mean() В хэлпе мы найдем параметр na.rm =, который по дефолту FALSE. Вы знаете, что нужно делать! mean(n, na.rm = T) ## [1] 7.444444 Еееее! NA может появляться в векторах других типов тоже. Кроме NA есть еще NaN - это разные вещи. NaN расшифровывается как Not a Number и получается в результате таких операций как 0/0. 2.3.6 В любой непонятной ситуации - гуглите Если вдруг вы не знаете, что искать в хэлпе, или хэлпа попросту недостаточно, то… гуглите! (Здесь почему-то многие смеются, а зря. Я хотел скинуть смешных картинок из интернета на эту тему, но их чет слишком уж много. Остановлюсь на любимой) Да помогут Вам Stackoverflow и бесчисленные R-туториалы! Главное, помните: загуглить работающий ответ всегда недостаточно. Надо понять, как и почему он работает. Иначе что-то обязательно пойдет не так. Does anyone ever get good at R or do they just get good at googling how to do things in R — 🔬🖤Lauren M. Seyler, Ph.D.❤️⚒ ((???)) May 6, 2019 Итак, с векторами мы более-менее разобрались. Помните, что вектора - это один из краеугольных камней Вашей работы в R. Если Вы хорошо с ними разобрались, то дальше все будет довольно несложно. Тем не менее, вектора - это не все. Есть еще два важных типа данных: списки (list) и матрицы (matrix). Их можно рассматривать как своеобразное “расширение” векторов, каждый в свою сторону. Ну а списки и матрицы нужны чтобы понять основной тип данных в R - data.frame. 2.4 Матрицы (matrix) Если вдруг Вас пугает это слово, то не бойтесь: это всего лишь “двумерный” вектор: вектор, у которого есть не только длина, но и ширина: A &lt;- matrix(1:20, nrow=5,ncol=4) A ## [,1] [,2] [,3] [,4] ## [1,] 1 6 11 16 ## [2,] 2 7 12 17 ## [3,] 3 8 13 18 ## [4,] 4 9 14 19 ## [5,] 5 10 15 20 Если мы знаем сколько значений в матрице и сколько мы хотим строк, то количество колонок указывать необязательно: A &lt;- matrix(1:20, nrow=5) A ## [,1] [,2] [,3] [,4] ## [1,] 1 6 11 16 ## [2,] 2 7 12 17 ## [3,] 3 8 13 18 ## [4,] 4 9 14 19 ## [5,] 5 10 15 20 Все остальное так же как и с векторами: внутри находится данные только одного типа. Поскольку матрица - это уже двумерный массив, то у него имеется два индекса: A[2,3] ## [1] 12 A[2:4, 1:3] ## [,1] [,2] [,3] ## [1,] 2 7 12 ## [2,] 3 8 13 ## [3,] 4 9 14 Первый индекс - выбор строк, второй индекс - выбор колонок. Если же мы оставляем пустое поле вместо числа, то мы выбираем все строки/колонки в зависимости от того, оставили мы поле пустым до или после запятой: A[,1:3] ## [,1] [,2] [,3] ## [1,] 1 6 11 ## [2,] 2 7 12 ## [3,] 3 8 13 ## [4,] 4 9 14 ## [5,] 5 10 15 A[2:4,] ## [,1] [,2] [,3] [,4] ## [1,] 2 7 12 17 ## [2,] 3 8 13 18 ## [3,] 4 9 14 19 A[,] ## [,1] [,2] [,3] [,4] ## [1,] 1 6 11 16 ## [2,] 2 7 12 17 ## [3,] 3 8 13 18 ## [4,] 4 9 14 19 ## [5,] 5 10 15 20 В принципе, это все, что нам нужно знать о матрицах. Матрицы используются в R довольно редко, особенно по сравнению, например, с MATLAB. Но вот индексировать матрицы хорошо бы уметь: это понадобится в работе с датафреймами. То, что матрица - это просто двумерный вектор, не является метафорой: в R матрица - это по сути своей вектор с дополнительными атрибутами dim и dimnames. Атрибуты - это неотъемлемые свойства объектов, например, для всех объектов есть атрибуты типа и длины. Можно задавать свои атрибуты или удалять уже присвоенные: удаление атрибута dim у матрицы превратит ее в обычный вектор. Про атрибуты подробнее можно почитать здесь или на стр. 99 - 101 книги “R in a Nutshell” 2.5 Списки (list) Теперь представим себе вектор без ограничения на одинаковые данные внутри. И получим список! l &lt;- list(42, &quot;Пам пам&quot;, T) l ## [[1]] ## [1] 42 ## ## [[2]] ## [1] &quot;Пам пам&quot; ## ## [[3]] ## [1] TRUE А это значит, что там могут содержаться самые разные данные, в том числе и другие списки и векторы! lbig &lt;- list(c(&quot;Wow&quot;, &quot;this&quot;, &quot;list&quot;, &quot;is&quot;, &quot;so&quot;, &quot;big&quot;), &quot;16&quot;, l) lbig ## [[1]] ## [1] &quot;Wow&quot; &quot;this&quot; &quot;list&quot; &quot;is&quot; &quot;so&quot; &quot;big&quot; ## ## [[2]] ## [1] &quot;16&quot; ## ## [[3]] ## [[3]][[1]] ## [1] 42 ## ## [[3]][[2]] ## [1] &quot;Пам пам&quot; ## ## [[3]][[3]] ## [1] TRUE Если у нас сложный список, то есть очень классная функция, чтобы посмотреть, как он устроен, под названием str(): str(lbig) ## List of 3 ## $ : chr [1:6] &quot;Wow&quot; &quot;this&quot; &quot;list&quot; &quot;is&quot; ... ## $ : chr &quot;16&quot; ## $ :List of 3 ## ..$ : num 42 ## ..$ : chr &quot;Пам пам&quot; ## ..$ : logi TRUE Как и в случае с векторами мы можем давать имена элементам списка: namedl &lt;- list(age = 24, PhDstudent = T, language = &quot;Russian&quot;) namedl ## $age ## [1] 24 ## ## $PhDstudent ## [1] TRUE ## ## $language ## [1] &quot;Russian&quot; К списку можно обращаться как с помощью индексов, так и по именам. Начнем с последнего: namedl$age ## [1] 24 А вот с индексами сложнее, и в этом очень легко запутаться. Давайте попробуем сделать так, как мы делали это раньше: namedl[1] ## $age ## [1] 24 Мы, по сути, получили элемент списка - просто как часть списка, т.е. как список длиной один: class(namedl) ## [1] &quot;list&quot; class(namedl[1]) ## [1] &quot;list&quot; А вот чтобы добраться до самого элемента списка (и сделать с ним что-то хорошее) нам нужна не одна, а две квадратных скобочки: namedl[[1]] ## [1] 24 class(namedl[[1]]) ## [1] &quot;numeric&quot; Есть еще довольно эзотерический способ: использовать имя элемента списка. namedl[[&#39;age&#39;]] ## [1] 24 Хотя последнее - то же самое, что и использование знака $. Списки довольно часто используются в R, но реже, чем в Python. Со многими объектами в R, такими как результаты статистических тестов, объекты ggplot и т.д. удобно работать именно как со списками - к ним все вышеописанное применимо. Кроме того, некоторые данные мы изначально получаем в виде древообразной структуры - хочешь не хочешь, а придется работать с этим как со списком. Но обычно после этого стоит как можно скорее превратить список в датафрейм. 2.6 Data.frame Итак, мы перешли к самому главному. Самому-самому. Датафреймы (data.frames). Более того, сейчас станет понятно, зачем нам нужно было разбираться со всеми предыдущими темами. Без векторов мы не смогли бы разобраться с матрицами и списками. А без последних мы не сможем понять, что такое датафрейм. name &lt;- c(&quot;Ivan&quot;, &quot;Eugeny&quot;, &quot;Lena&quot;, &quot;Misha&quot;, &quot;Sasha&quot;) age &lt;- c(26, 34, 23, 27, 26) student &lt;- c(F, F, T, T, T) df = data.frame(name, age, student) df ## name age student ## 1 Ivan 26 FALSE ## 2 Eugeny 34 FALSE ## 3 Lena 23 TRUE ## 4 Misha 27 TRUE ## 5 Sasha 26 TRUE str(df) ## &#39;data.frame&#39;: 5 obs. of 3 variables: ## $ name : Factor w/ 5 levels &quot;Eugeny&quot;,&quot;Ivan&quot;,..: 2 1 3 4 5 ## $ age : num 26 34 23 27 26 ## $ student: logi FALSE FALSE TRUE TRUE TRUE Вообще, очень похоже на список, не правда ли? Так и есть, датафрейм - это что-то вроде проименованного списка, каждый элемент которого является atomic вектором фиксированной длины. Скорее всего, вы список представляли “горизонтально”, - теперь “переверните” его у себя в голове. Так, чтоб названия векторов оказались сверху, а колонки стали столбцами. Поскольку длина всех этих векторов равна (обязательное условие!), то данные представляют собой табличку, похожую на матрицу. Но в отличие от матрицы, разные столбцы могут имет разные типы данных: первая колонка - character, вторая колонка - numeric, третья колонка - logical. Тем не менее, обращаться с датафреймом можно и как с проименованным списком, и как с матрицей: df$age[2:3] ## [1] 34 23 Здесь мы сначала вытащили колонку age с помощью оператора $. Результатом этой операции является числовой вектор, из которого мы вытащили кусок, выбрав индексы 2 и 3. Используя оператор $ и присваивание можно создавать новые колонки датафрейма: df$lovesR &lt;- T #правило recycling - узнали? df ## name age student lovesR ## 1 Ivan 26 FALSE TRUE ## 2 Eugeny 34 FALSE TRUE ## 3 Lena 23 TRUE TRUE ## 4 Misha 27 TRUE TRUE ## 5 Sasha 26 TRUE TRUE Ну а можно просто обращаться с помощью двух индексов через запятую, как мы это делали с матрицей: df[3:5, 2:3] ## age student ## 3 23 TRUE ## 4 27 TRUE ## 5 26 TRUE Как и с матрицами, первый индекс означает строчки, а второй - столбцы. А еще можно использовать названия колонок внутри квадратных скобок: df[1:2,&quot;age&quot;] ## [1] 26 34 И здесь перед нами открываются невообразимые возможности! Узнаем, любят ли R те, кто моложе среднего возраста в группе: df[df$age &lt; mean(df$age), 4] ## [1] TRUE TRUE TRUE TRUE Эту же задачу можно выполнить другими способами: df$lovesR[df$age &lt; mean(df$age)] ## [1] TRUE TRUE TRUE TRUE df[df$age &lt; mean(df$age), &#39;lovesR&#39;] ## [1] TRUE TRUE TRUE TRUE В большинстве случаев подходят сразу несколько способов - тем не менее, стоит овладеть ими всеми. Датафреймы удобно просматривать в RStudio. Для это нужно написать команду View(df) или же просто нажать на названии нужной переменной из списка вверху справа (там где Environment). Тогда увидите табличку, очень похожую на Excel и тому подобные программы для работы с таблицами. Там же есть и всякие возможности для фильтрации, сортировки и поиска… Но, конечно, интереснее все эти вещи делать руками, т.е. с помощью написания кода. На этом пора заканчивать с введением и приступать к реальным данным. 2.7 Начинаем работу с реальными данными Итак, пришло время перейти к реальным данным. Мы начнем с использования датасета (так мы будем называть любой набор данных) по Игре Престолов, а точнее, по книгам цикла “Песнь льда и пламени” Дж. Мартина. Да, будут спойлеры, но сериал уже настолько далеко ушел вперед, что это уже даже вроде и не спойлеры… 2.7.1 Рабочая папка и проекты Итак, допустим, все скачали файл по ссылке Он, скорее всего, появился у Вас в папке “Загрузки”. Если мы будем просто пытаться прочитать этот файл (например, с помощью read.csv() - мы к этой функцией очень скоро перейдем), указав его имя и разрешение, то наткнемся на такую ошибку: Ошибка в file(file, “rt”) :не могу открыть соединение Вдобавок: Предупреждение: В file(file, “rt”) : не могу открыть файл ‘character-deaths.csv’: No such file or directory Это означает, что R не может найти нужный файл. Вообще-то мы даже не сказали, где искать. Нам нужно как-то совместить место, где R ищет загружаемые файлы и сами файлы. Для этого есть несколько способов. Магомет идет к горе: перемещение файлов в рабочую папку. Для этого нужно узнать, какая папка является рабочей с помощью функции getwd() (без аргументов), найти эту папку в проводнике и переместить туда файл. После этого можно использовать просто название файла с разрешением: got &lt;- read.csv(&quot;character-deaths.csv&quot;) Гора идет к Магомету: изменение рабочей папки. Можно просто сменить рабочую папку с помощью setwd() на ту, где сейчас лежит файл, прописав путь до этой папки. Теперь файл находится в рабочей папке: got &lt;- read.csv(&quot;character-deaths.csv&quot;) Этот вариант использовать не рекомендуется. Как минимум, это сразу делает невозможным запустить скрипт на другом компьютере. Гора находит Магомету по месту прописки: указание полного пути файла. got &lt;- read.csv(&quot;/Users/Username/Some_Folder/character-deaths.csv&quot;) Этот вариант страдает теми же проблемами, что и предыдущий, поэтому тоже не рекомендуется. Магомет использует кнопочный интерфейс: Import Dataset. Во вкладке Environment справа в окне RStudio есть кнопка “Import Dataset”. Возможно, у Вас возникло непреодолимое желание отдохнуть от написания кода и понажимать кнопочки - сопротивляйтесь этому всеми силами, но не вините себя, если не сдержитесь. Гора находит Магомета в интернете. Многие функции в R, предназначенные для чтения файлов, могут прочитать файл не только на Вашем компьютере, но и сразу из интернета. Для этого просто используйте ссылку вместо пути: got &lt;- read.csv(&quot;https://raw.githubusercontent.com/Pozdniakov/stats/master/data/character-deaths.csv&quot;) Каждый Магомет получает по своей горе: использование проектов в RStudio. На первый взгляд это кажется чем-то очень сложным, но это не так. Это очень просто и ОЧЕНЬ удобно. При создании проекта создается отдельная папочка, где у Вас лежат данные, хранятся скрипты, вспомогательные файлы и отчеты. Если нужно вернуться к другому проекту - просто открываете другой проект, с другими файлами и скриптами. Это еще помогает не пересекаться переменным из разных проектов - а то, знаете, использование двух переменных data в разных скриптах чревато ошибками. Например, можно выделить отдельный проект под этот курс. 2.7.2 Импорт данных Как Вы уже поняли, импортирование данных - одна из самых муторных и неприятных вещей в R. Если у Вас получится с этим справится, то все остальное - ерунда. Мы уже разобрались с первой частью этого процесса - нахождением файла с данными, осталось научиться их читать. Здесь стоит сделать небольшую ремарку. Довольно часто данные представляют собой табличку. Или же их можно свести к табличке. Такая табличка, как мы уже выяснили, удобно репрезентируется в виде датафрейма. Но как эти данные хранятся на компьютере? Есть два варианта: в бинарном и в текстовом файл. Текстовый файл означает, что такой файл можно открыть в программе “Блокнот” или ее аналоге и увидеть напечатанный текст: скрипт, роман или упорядоченный набор цифр и букв. Нас сейчас интересует именно последний случай. Таблица может быть представлена как текст: отдельные строчки в файле будут разделять разные строчки таблицы, а какой-нибудь знак-разделитель отделет колонки друг от друга. Для чтения данных из текстового файла есть довольно удобная функция read.table(). Почитайте хэлп по ней и ужаснитесь: столько разных параметров на входе! Но там же вы увидете функции read.csv(), read.csv2() и некоторые другие - по сути, это тот же read.table, но с другими дефолтными параметрами, соответствующие формату файла, который мы загружаем. В данном случае используется формат .csv, что означает Comma Separated Values (Значения, Разделенные Запятыми). Это просто текстовый файл, в котором “закодирована” таблица: разные строчки разделяют разные строчки таблицы, а столбцы отделяются запятыми. С этим связана одна проблема: в некоторых странах (в т.ч. и России) принято использовать запятую для разделения дробной части числа, а не точку, как это делается в большинстве стран мира. Поэтому есть “другой” формат .csv, где значения разделены точкой с запятой (;), а дробные значения - запятой. В этом и различие функций read.csv() и read.csv2() - первая функция предназначена для “международного” формата, вторая - для (условно) “Российского”. В первой строчке обычно содержатся названия переменных - и это чертовски удобно, функции read.csv() и read.csv2() по дефолту считают первую строчку именно как название переменных. Итак, прочитаем наш файл. Для этого используем только параметр file, который идет первым, и для параметра stringsAsFactors поставим значение FALSE: got &lt;- read.csv(&quot;data/character-deaths.csv&quot;, stringsAsFactors = F) По сути, факторы - это примерно то же самое, что и character, но закодированные числами. Когда-то это было придумано для экономии используемых времени и памяти, сейчас же обычно становится просто лишней морокой. Но некоторые функции требуют именно character, некоторые factor, в большинстве случаев без разницы. Но иногда непонимание может привести к дурацким ошибкам. В данном случае мы просто пока обойдемся без факторов. Можете проверить с помощью View(got): все работает! Если же вылезает какая-то странная ерунда или же просто ошибка - попробуйте другие функции и покопаться с параметрами. Для этого читайте хэлп. Кроме .csv формата есть и другие варианты хранения таблиц в виде текста. Например, .tsv - тоже самое, что и .csv, но разделитель - знак табуляции. Для чтения таких файлов есть функция read.delim() и read.delim2(). Впрочем, даже если бы ее и не было, можно было бы просто подобрать нужные параметры для функции read.table(). Есть даже функции (например, fread() из пакета data.table - мы ее будем использовать послезавтра!), которые пытаются сами “угадать” нужные параметры для чтения - часто они справляются с этим довольно удачно. Но не всегда. Поэтому стоит научиться справляться с любого рода данными на входе. Тем не менее, далеко не всегда таблицы представлены в виде текстового файла. Самый распространенный пример таблицы в бинарном виде - родные форматы Microsoft Excel. Если Вы попробуете открыть .xlsx файл в Блокноте, то увидите кракозябры. Это делает работу с этим файлами гораздо менее удобной, поэтому стоит избегать экселевских форматов и стараться все сохранять в .csv. Для работы с экселевскими файлами есть много пакетов: readxl, xlsx, openxlsx. Для чтения файлов SPSS, Stata, SAS есть пакет foreign. Что такое пакеты и как их устанавливать мы изучим завтра. "],
["real.html", "3 День 2. Работа с реальными данными в R 3.1 Препроцессинг данных в R 3.2 Циклы, условия, создание функций 3.3 Работа с текстом 3.4 Работа с дополнительными пакетами 3.5 Решейпинг данных 3.6 Заключение", " 3 День 2. Работа с реальными данными в R 3.1 Препроцессинг данных в R Вчера мы узнали про основы языка R, про то, как работать с векторами, списками, матрицами и, наконец, датафреймами. Мы закончили день на загрузке данных, с чего мы и начнем сегодня: got &lt;- read.csv(&quot;data/character-deaths.csv&quot;, stringsAsFactors = F) После загрузки данных стоит немного “осмотреть” получившийся датафрейм got. 3.1.1 Исследование данных Ок, давайте немного поизучаем датасет. Обычно мы привыкли глазами пробегать по данным, листая строки и столбцы - и это вполне правильно и логично, от этого не нужно отучаться. Но мы можем дополнить наш базовый зрительнопоисковой инструментарий несколькими полезными командами. Во-первых, вспомним другую полезную функцию str(): str(got) ## &#39;data.frame&#39;: 917 obs. of 13 variables: ## $ Name : chr &quot;Addam Marbrand&quot; &quot;Aegon Frey (Jinglebell)&quot; &quot;Aegon Targaryen&quot; &quot;Adrack Humble&quot; ... ## $ Allegiances : chr &quot;Lannister&quot; &quot;None&quot; &quot;House Targaryen&quot; &quot;House Greyjoy&quot; ... ## $ Death.Year : int NA 299 NA 300 NA NA 300 300 NA NA ... ## $ Book.of.Death : int NA 3 NA 5 NA NA 4 5 NA NA ... ## $ Death.Chapter : int NA 51 NA 20 NA NA 35 NA NA NA ... ## $ Book.Intro.Chapter: int 56 49 5 20 NA NA 21 59 11 0 ... ## $ Gender : int 1 1 1 1 1 1 1 0 1 1 ... ## $ Nobility : int 1 1 1 1 1 1 1 1 1 0 ... ## $ GoT : int 1 0 0 0 0 0 1 1 0 0 ... ## $ CoK : int 1 0 0 0 0 1 0 1 1 0 ... ## $ SoS : int 1 1 0 0 1 1 1 1 0 1 ... ## $ FfC : int 1 0 0 0 0 0 1 0 1 0 ... ## $ DwD : int 0 0 1 1 0 0 0 1 0 0 ... Давайте разберемся с переменными в датафрейме: Колонка Name - здесь все понятно. Важно, что эти имена записаны абсолютно по-разному: где-то с фамилией, где-то без, где-то в скобочках есть пояснения. Колонка Allegiances - к какому дому принадлежит персонаж. С этим сложно, иногда они меняют дома, здесь путаются сами семьи и персонажи, лояльные им. Особой разницы между &quot;Stark&quot; и &quot;House Stark&quot; нет. Следующие колонки - &quot;Death Year&quot;, &quot;Book.of.Death&quot;, &quot;Death.Chapter&quot;, &quot;Book.Intro.Chapter&quot; - означают номер главы, в которой персонаж впервые появляется, а так же номер книги, глава и год (от завоевания Вестероса Эйгоном Таргариеном), в которой персонаж умирает. Gender - 1 для мужчин, 0 для женщин. Nobility - дворянское происхождение персонажа. Последние 5 столбцов содержат информацию, появлялся ли персонаж в книге (всего книг пока что 5). Другая полезная функция для больших таблиц - функция head(): она выведет первые несколько (по дефолту 6) строчек датафрейма. head(got) ## Name Allegiances Death.Year Book.of.Death ## 1 Addam Marbrand Lannister NA NA ## 2 Aegon Frey (Jinglebell) None 299 3 ## 3 Aegon Targaryen House Targaryen NA NA ## 4 Adrack Humble House Greyjoy 300 5 ## 5 Aemon Costayne Lannister NA NA ## 6 Aemon Estermont Baratheon NA NA ## Death.Chapter Book.Intro.Chapter Gender Nobility GoT CoK SoS FfC DwD ## 1 NA 56 1 1 1 1 1 1 0 ## 2 51 49 1 1 0 0 1 0 0 ## 3 NA 5 1 1 0 0 0 0 1 ## 4 20 20 1 1 0 0 0 0 1 ## 5 NA NA 1 1 0 0 1 0 0 ## 6 NA NA 1 1 0 1 1 0 0 Есть еще функция tail(). Догадайтесь сами, что она делает. Для некоторых переменных полезно посмотреть таблицы частотности с помощью функции table(): table(got$Allegiances) ## ## Arryn Baratheon Greyjoy House Arryn ## 23 56 51 7 ## House Baratheon House Greyjoy House Lannister House Martell ## 8 24 21 12 ## House Stark House Targaryen House Tully House Tyrell ## 35 19 8 11 ## Lannister Martell Night&#39;s Watch None ## 81 25 116 253 ## Stark Targaryen Tully Tyrell ## 73 17 22 15 ## Wildling ## 40 Уау! Очень просто и удобно, не так ли? Функция table() может принимать сразу несколько столбцов. Это удобно для получения таблиц сопряженности: table(got$Allegiances, got$Gender) ## ## 0 1 ## Arryn 3 20 ## Baratheon 6 50 ## Greyjoy 4 47 ## House Arryn 3 4 ## House Baratheon 0 8 ## House Greyjoy 1 23 ## House Lannister 2 19 ## House Martell 7 5 ## House Stark 6 29 ## House Targaryen 5 14 ## House Tully 0 8 ## House Tyrell 4 7 ## Lannister 12 69 ## Martell 7 18 ## Night&#39;s Watch 0 116 ## None 51 202 ## Stark 21 52 ## Targaryen 1 16 ## Tully 2 20 ## Tyrell 6 9 ## Wildling 16 24 3.1.2 Установка пакетов В какой-то момент базовой функциональности R начинает не хватать install.packages(&quot;&quot;) ## Warning in install.packages : ## package &#39;&#39; is not available (for R version 3.6.0) 3.1.3 Subsetting Как мы обсуждали на прошлом занятии, мы можем сабсеттить (выделять часть датафрейма) датафрейм, обращаясь к нему и как к матрице: датафрейм[вектор_с_номерами_строк, вектор_с_номерами_колонок] got[100:115, 1:2] ## Name Allegiances ## 100 Blue Bard House Tyrell ## 101 Bonifer Hasty Lannister ## 102 Borcas Night&#39;s Watch ## 103 Boremund Harlaw Greyjoy ## 104 Boros Blount Baratheon ## 105 Borroq Wildling ## 106 Bowen Marsh Night&#39;s Watch ## 107 Bran Stark House Stark ## 108 Brandon Norrey Stark ## 109 Brenett None ## 110 Brienne of Tarth Stark ## 111 Bronn Lannister ## 112 Brown Bernarr Night&#39;s Watch ## 113 Brusco None ## 114 Bryan Fossoway Baratheon ## 115 Bryce Caron Baratheon и используя имена колонок: got[508:515, &quot;Name&quot;] ## [1] &quot;Mance Rayder&quot; &quot;Mandon Moore&quot; &quot;Maric Seaworth&quot; &quot;Marei&quot; ## [5] &quot;Margaery Tyrell&quot; &quot;Marillion&quot; &quot;Maris&quot; &quot;Marissa Frey&quot; и даже используя вектора названий колонок! got[508:515, c(&quot;Name&quot;, &quot;Allegiances&quot;, &quot;Gender&quot;)] ## Name Allegiances Gender ## 508 Mance Rayder Wildling 1 ## 509 Mandon Moore Baratheon 1 ## 510 Maric Seaworth House Baratheon 1 ## 511 Marei None 0 ## 512 Margaery Tyrell House Tyrell 0 ## 513 Marillion Arryn 1 ## 514 Maris Wildling 0 ## 515 Marissa Frey None 0 Мы можем вытаскивать отдельные колонки как векторы: houses &lt;- got$Allegiances unique(houses) #посмотреть все уникальные значения - почти как с помощью table() ## [1] &quot;Lannister&quot; &quot;None&quot; &quot;House Targaryen&quot; ## [4] &quot;House Greyjoy&quot; &quot;Baratheon&quot; &quot;Night&#39;s Watch&quot; ## [7] &quot;Arryn&quot; &quot;House Stark&quot; &quot;House Tyrell&quot; ## [10] &quot;Tyrell&quot; &quot;Stark&quot; &quot;Greyjoy&quot; ## [13] &quot;House Lannister&quot; &quot;Martell&quot; &quot;House Martell&quot; ## [16] &quot;Wildling&quot; &quot;Targaryen&quot; &quot;House Arryn&quot; ## [19] &quot;House Tully&quot; &quot;Tully&quot; &quot;House Baratheon&quot; Итак, давайте решим нашу первую задачу - вытащим в отдельный датасет всех представителей Ночного Дозора. Для этого нам нужно создать вектор логических значений - результат сравнений колонки Allegiances со значением “Night’s Watch” и использовать его как вектор индексов для датафрейма. vectornight &lt;- got$Allegiances == &quot;Night&#39;s Watch&quot; head(vectornight) ## [1] FALSE FALSE FALSE FALSE FALSE FALSE Теперь этот вектор с TRUE и FALSE нам надо использовать для индексации строк. Но что со столбцами? Если мы хотем сохранить все столбцы, то после запятой внутри квадратных скобок нам нужно ничего не указывать: nightswatch &lt;- got[vectornight,] head(nightswatch) ## Name Allegiances Death.Year ## 7 Aemon Targaryen (son of Maekar I) Night&#39;s Watch 300 ## 10 Aethan Night&#39;s Watch NA ## 13 Alan of Rosby Night&#39;s Watch 300 ## 16 Albett Night&#39;s Watch NA ## 24 Alliser Thorne Night&#39;s Watch NA ## 49 Arron Night&#39;s Watch NA ## Book.of.Death Death.Chapter Book.Intro.Chapter Gender Nobility GoT CoK ## 7 4 35 21 1 1 1 0 ## 10 NA NA 0 1 0 0 0 ## 13 5 4 18 1 1 0 1 ## 16 NA NA 26 1 0 1 0 ## 24 NA NA 19 1 0 1 1 ## 49 NA NA 75 1 0 0 0 ## SoS FfC DwD ## 7 1 1 0 ## 10 1 0 0 ## 13 1 0 1 ## 16 0 0 0 ## 24 1 0 1 ## 49 1 0 1 Вуаля! Все это можно сделать проще и в одну строку: nightswatch &lt;- got[got$Allegiances == &quot;Night&#39;s Watch&quot;,] И не забывайте про запятую! Теперь попробуем вытащить одновременно всех Одичалых (Wildling) и всех представителей Ночного Дозора. Это можно сделать, используя оператор | (ИЛИ) при выборе колонок: nightwatch_wildling &lt;- got[got$Allegiances == &quot;Night&#39;s Watch&quot; | got$Allegiances == &quot;Wildling&quot;,] head(nightwatch_wildling) ## Name Allegiances Death.Year ## 7 Aemon Targaryen (son of Maekar I) Night&#39;s Watch 300 ## 10 Aethan Night&#39;s Watch NA ## 13 Alan of Rosby Night&#39;s Watch 300 ## 16 Albett Night&#39;s Watch NA ## 24 Alliser Thorne Night&#39;s Watch NA ## 49 Arron Night&#39;s Watch NA ## Book.of.Death Death.Chapter Book.Intro.Chapter Gender Nobility GoT CoK ## 7 4 35 21 1 1 1 0 ## 10 NA NA 0 1 0 0 0 ## 13 5 4 18 1 1 0 1 ## 16 NA NA 26 1 0 1 0 ## 24 NA NA 19 1 0 1 1 ## 49 NA NA 75 1 0 0 0 ## SoS FfC DwD ## 7 1 1 0 ## 10 1 0 0 ## 13 1 0 1 ## 16 0 0 0 ## 24 1 0 1 ## 49 1 0 1 Кажется очевидным следующий вариант: got[got$Allegiances == c(&quot;Night's Watch&quot;, &quot;Wildling&quot;),]. Однако это выдаст не совсем то, что нужно, хотя результат может показаться верным на первый взгляд. Попробуйте самостоятельно ответить на вопрос, что происходит в данном случае и чем результат отличается от предполагаемого. Подсказка: вспомните правило recycling. Однако для таких случаев есть очень удобный оператор %in%, который позволяет сравнить каждое значение вектора с целым набором значений. Если значение вектора хотя бы один раз встречается в векторе справа от %in%, то результат - TRUE: 1:6 %in% c(1,4,5) ## [1] TRUE FALSE FALSE TRUE TRUE FALSE nightwatch_wildling &lt;- got[got$Allegiances %in% c(&quot;Night&#39;s Watch&quot;, &quot;Wildling&quot;),] head(nightwatch_wildling) ## Name Allegiances Death.Year ## 7 Aemon Targaryen (son of Maekar I) Night&#39;s Watch 300 ## 10 Aethan Night&#39;s Watch NA ## 13 Alan of Rosby Night&#39;s Watch 300 ## 16 Albett Night&#39;s Watch NA ## 24 Alliser Thorne Night&#39;s Watch NA ## 49 Arron Night&#39;s Watch NA ## Book.of.Death Death.Chapter Book.Intro.Chapter Gender Nobility GoT CoK ## 7 4 35 21 1 1 1 0 ## 10 NA NA 0 1 0 0 0 ## 13 5 4 18 1 1 0 1 ## 16 NA NA 26 1 0 1 0 ## 24 NA NA 19 1 0 1 1 ## 49 NA NA 75 1 0 0 0 ## SoS FfC DwD ## 7 1 1 0 ## 10 1 0 0 ## 13 1 0 1 ## 16 0 0 0 ## 24 1 0 1 ## 49 1 0 1 3.1.4 Создание новых колонок Давайте создадим новую колонку, которая будет означать, жив ли еще персонаж (по книгам). Заметьте, что в этом датасете, хоть он и посвящен смертям персонажей, нет нужной колонки. Мы можем “вытащить” эту информацию. Во многих колонках &quot;Death.Year&quot;, &quot;Death.Chapter&quot; и &quot;Book.of.Death&quot; стоит NA у многих персонажей. Например, у Arya Stark, которая и по книгам, и по сериалу живее всех живых и мертвых: got[got$Name == &quot;Arya Stark&quot;,] ## Name Allegiances Death.Year Book.of.Death Death.Chapter ## 56 Arya Stark Stark NA NA NA ## Book.Intro.Chapter Gender Nobility GoT CoK SoS FfC DwD ## 56 2 0 1 1 1 1 1 1 Следовательно, если в Book.of.Death стоит NA, мы можем предположить, что Джордж Мартин еще не занес своей карающей руки над этим героем. Мы можем создать новую колонку &quot;Is.Alive&quot;: got$Is.Alive &lt;- is.na(got$Book.of.Death) Готово! Как легко, просто и элегантно, неправда ли? Но в жизни часто бывает все сложнее, поэтому давайте научимся еще некоторым важным инструментам. 3.2 Циклы, условия, создание функций 3.2.1 If, else, elseif, ifelse() Как и во всех “нормальных” языках программирования, в R есть if-else statements. Например: na_slovah &lt;- &quot;Лев Толстой&quot; if (na_slovah == &quot;Лев Толстой&quot;){ na_dele = &quot;Парень простой&quot; } else {na_dele = na_slovah} na_dele ## [1] &quot;Парень простой&quot; В круглых скобках после if - условие. Если оно TRUE, то выполняется то, что внутри последующих фигурных. Если не выполняется, то выполняется то, что в фигурных скобках после else (если else вообще присутствует). Можно использовать несколько условий: na_slovah &lt;- &quot;Алексей толстой&quot; if (na_slovah == &quot;Лев Толстой&quot;){ na_dele = &quot;Парень простой&quot; } else if (na_slovah == &quot;Алексей Толстой&quot;) { na_dele = &quot;Лев Толстой&quot; } else {na_dele = na_slovah} na_dele ## [1] &quot;Алексей толстой&quot; Тем не менее, с if, else, else if есть одна серьезная проблема - на входе нельзя дать вектор, а только единственное значение. Какая боль! Для решения этой проблемы можно воспользоваться функцией ifelse() или циклами. 3.2.2 Функция ifelse() Функция ifelse() принимает три аргумента - 1) условие (т.е., по сути, логический вектор, состоящий из TRUE и FALSE), 2) что выдавать в случае TRUE, 3) что выдавать в случае FALSE. Вот это как раз мы можем применить уже к нашим данным. Давайте сначала сотрем созданную колонку Is.Alive. Для это присвоим ей значение NULL: got$Is.Alive &lt;- NULL Затем создадим ее заново, но уже как текстовую с помощью ifelse(): got$Is.Alive &lt;- ifelse(is.na(got$Book.of.Death), &quot;Alive&quot;, &quot;Dead&quot;) К сожалению, аналога else if в этой функции нет. Но если у вас больше, чем два варианта, то никто не мешает использовать ifelse() внутри ifelse(), чтобы покрыть больше чем два условия. 3.2.3 For loops Во многих других языках программирования циклы (типа for и while) - это основа основ. Но не в R. В R они, конечно, есть, но использовать их не рекомендуется. Векторизированные операции в R экономнее - как в плане более короткого и читаемого кода, так и в плане скорости. Векторизованные функции часто написаны на более низкоуровневом языке (например, С), которые быстрее R. Поэтому дважды подумайте, прежде чем делать то, что я сейчас покажу! Почти всегда в R можно обойтись без циклов. got$Is.Alive &lt;- NULL got$Is.Alive &lt;- NA #сделаем вектор, заполненный NA значениями for (i in 1:length(got$Book.of.Death)){ if (is.na(got$Book.of.Death[i])){ got$Is.Alive[i] &lt;- &quot;Alive&quot; } else {got$Is.Alive[i] &lt;- &quot;Dead&quot;} } Ужас какой! Да еще и легко ошибиться. К тому, чтобы НЕ использовать циклы обычно получается приучиться не сразу у тех, кто пришел из других языков программирования. Часто кажется, что именно в данном случае без циклов не обойтись, но в подавляющем числе случаев это не так. Дело в том, что обычно мы работаем в R с датафреймами, которые представляют собой множество относительно независимых наблюдений. Если мы хотим провести какие-нибудь операции с этими наблюдениями, то они обычно могут быть выполненые параллельно. Скажем, вы хотите для каждого испытуемого пересчитать его массу из фунтов в килограммы. Этот пересчет осуществляется по одинаковой формуле для каждого испытуемого. Эта формула не изменится из-за того, что какой-то испытуемый слишком большой или слишком маленький - для следующего испытуемого формула будет прежняя. Если Вы встречаете подобную задачу (где функцию можно применить независимо для всех значений), то без цикла for вполне можно обойтись. После этих объяснений кому-то может показаться странным, что я вообще упоминаю про эти циклы. Но для кого-то циклы for настолько привычны, что их полное отсутствие в курсе может показаться еще более странным. Поэтому лучше от меня, чем на улице. Бывают случаи, в которых расчет значения в строчке все-таки зависит от предыдущих, но и тогда можно обойтись без циклов! Например, для подсчета кумулятивной суммы можно использовать функцию cumsum(): cumsum(1:10) ## [1] 1 3 6 10 15 21 28 36 45 55 Существуют и исключения - некоторые функции не векторизованы, тогда Если уж хочется сделать цикл, то лучше воспользоваться apply() семейством функций. Но сначала нам нужно научиться создавать собственные функции. 3.2.4 Создание функций Поздравляю, сейчас мы выйдем на качественно новый уровень владения R. Вместо того, чтобы пользоваться теми функциями, которые уже написали за нас, мы можем сами создавать свои функции! В этом нет ничего сложного. Функция - это такой же объект в R, как и остальные. Давайте разберем на примере создания функции sumofsquares, которая будет считать сумму квадратов квадратичных отклонений от среднего: \\(Sum of squares = \\sum_{i=1}^{n}(x_i - \\bar{x})^2\\) Эта формула будет нам часто встречаться, когда мы перейдем к статистике! sumofsquares &lt;- function(x){ centralized_x &lt;- x - mean(x) squares &lt;- centralized_x^2 sum_of_squares &lt;- sum(squares) return(sum_of_squares) } sumofsquares(1:10) ## [1] 82.5 Синтаксис создания функции немного похож на создание циклов. Мы пишем ключевое слово function, в круглых скобках обозначаем переменные, с которыми собираемся что-то делать. Внутри фигурных скобок пишем выражения, которые будут выполняться при запуске функции. У функции есть свое собственное окружение. Это означает, что функция не знает о всех переменных, использованных ранее, для нее существуют только те объекты, которые переданы в круглых скобочках. С ними функция и будет работать. На выходе функция выдаст то, что будет закинуто в return(). Однако функция return() часто опускается: если ее нет, то функция будет выводить результат последнего выражения. Таким образом, нашу функцию можно написать короче: sumofsquares &lt;- function(x){ centralized_x &lt;- x - mean(x) squares &lt;- centralized_x^2 sum(squares) } sumofsquares(1:10) ## [1] 82.5 Можно еще сократить функцию: sumofsquares &lt;- function(x){ sum((x - mean(x))^2) } sumofsquares(1:10) ## [1] 82.5 На самом деле, если функция занимает всего одну строчку, то фигурные скобки и не нужны. sumofsquares &lt;- function(x) sum((x - mean(x))^2) sumofsquares(1:10) ## [1] 82.5 Вообще, фигурные скобки используются для того, чтобы выполнить серию выражений, но вернуть только результат выполнения последнего выражения. Это можно использовать, чтобы не создавать лишних временных переменных в глобальном окружении. Когда стоит создавать функции? Существует “правило трех” - если у вас есть три куска очень похожего кода, то самое время превратить код в функцию. Это очень условное правило, но, действительно, стоит избегать копипастинга в коде. В этом случае очень легко ошибиться, код становится нечитаемым. Но есть и другой подход к созданию функций. Их стоит создавать не столько для того, чтобы использовать тот же код снова, сколько для абстрагирования от того, что происходит в отдельных строчках кода. Если несколько строчек кода были написаны для того, чтобы решить одну задачу, которой можно дать понятное название (например, подсчет какой-то особенной метрики, для которой нет готовой функции в R), то этот код стоит обернуть в функцию. Если функция работает корректно, то теперь не нужно думать над тем, что происходит внутри нее. Вы ее можете мысленно представить как операцию, которая имеет определенный вход и выход - как и встроенные функции в R. The reason for writing a function is not to reuse its code, but to name the operation it performs. — Tim “Agile Otter” Ottinger ((???)) January 22, 2013 3.2.5 Cемейство функций apply() Семейство? Да, их целое множество: apply(), lapply(),sapply(), vapply(),tapply(),mapply(), rapply()… Ладно, не пугайтесь, всех их знать не придется. Обычно достаточно первых двух-трех. Проще всего пояснить как они работают на простой матрице с числами: A &lt;- matrix(1:12,3,4) A ## [,1] [,2] [,3] [,4] ## [1,] 1 4 7 10 ## [2,] 2 5 8 11 ## [3,] 3 6 9 12 Теперь представим, что нам нужно посчитать что-нибудь (например, сумму) по каждой из строк. С помощью функции apply() вы можете в буквальном смысле “применить” какую либо функцию к матрице или датафрейму (правда, датафрейм эта функция будет пытаться превратить в матрицу, так что будьте осторожны). Синтаксис такой: apply(X, MARGIN, FUN, ...), где X - Ваши данные, MARGIN это 1 (для строк), 2 (для колонок), c(1,2) для строк и колонок (т.е. для каждого элемента по отдельности), а FUN - это функция, котору вы хотите применить, но без скобок ()! apply(A, 1, sum) #сумма по каждой строчке ## [1] 22 26 30 apply(A, 2, sum) #сумма по каждой колонке ## [1] 6 15 24 33 apply(A, c(1,2), sum) #кхм... сумма каждого элемента ## [,1] [,2] [,3] [,4] ## [1,] 1 4 7 10 ## [2,] 2 5 8 11 ## [3,] 3 6 9 12 Заметьте, мы вставляем функцию (а не ее аутпут!) как инпут в функцию. 3.2.6 Анонимные функции Если вдумаетесь, то тут возникает определенная сложность: функция apply() будет работать только в том случае, если функция принимает первым аргументом именно то, что мы ей даем… А если это не так? Тогда мы можем создать анонимные функции! Еще можно написать нужные аргументы через запятую после аргумента FUN: apply(A, 1, weighted.mean, w = c(0.2, 0.4, 0.3, 0.1)) ## [1] 4.9 5.9 6.9 Анонимные функции - это функциии, которые будут использоваться один раз и без названия. Питонистам знакомо понятие лямбда-функций. Да, это то же самое Например, мы можем посчитать сумму квадратичных отклонений от среднего без называния этой функции: apply(A, 1, function(x) sum((x-mean(x))^2)) ## [1] 45 45 45 apply(A, 2, function(x) sum((x-mean(x))^2)) ## [1] 2 2 2 2 apply(A, c(1,2), function(x) sum((x-mean(x))^2)) ## [,1] [,2] [,3] [,4] ## [1,] 0 0 0 0 ## [2,] 0 0 0 0 ## [3,] 0 0 0 0 Как и в случае обычной функции, в качестве x выступает тот объект, с которым мы хотим что-то сделать в функции, а потом пишем код того, что хотим с этим x сделать. Можно использовать не х, а что угодно, как и в обычных функциях: apply(A, 1, function(whatevername) sum((whatevername-mean(whatevername))^2)) ## [1] 45 45 45 Ок, с apply() разобрались. А что с остальными? Некоторые из них еще проще и не требуют индексов, например, lapply (для применения к каждому элементу списка и sapply() - упрощенная версия lapply(), которая пытается по возможности “упростить” результат до вектора или матрицы. Давайте теперь сделаем то же самое, что мы и делали (создание колонки got$Is.Alive), но с помощью sapply() функции: got$Is.Alive &lt;- NA got$Is.Alive &lt;- sapply(got$Book.of.Death, function (x) ifelse(is.na(x), &quot;Alive&quot;, &quot;Dead&quot;)) Еще одна функция из семейства apply() - функция replicate() - самый простой способ повторить одну и ту же операцию много раз. Обычно это используется при разнообразных симуляциях данных и моделировании. Например, давайте сделаем выборку и логнормального распределения: set.seed(1) #Это сделает выбор случайных чисел воспроизводимым samp &lt;- rlnorm(30) hist(samp) А теперь давайте сделаем 1000 таких выборок и из каждой возьмем среднее: sampdist &lt;- replicate(1000, mean(rlnorm(30))) hist(sampdist) Про функции для генерации случайных чисел и про визуализацию мы поговорим в следующие дни Если хотите познакомиться с семейством apply() чуточку ближе, то рекомендую вот этот туториал 3.3 Работа с текстом Работа с текстом - это отдельная и сложная задача. И у R есть мощные инструменты для этого!. Для более-менее продвинутой работы с текстом придется выучить специальный язык - “регулярные выражения” (regular expressions или просто regex). Регулярные выражения реализованы на многих языках, в том числе в R. Но мы пока обойдемся наиболее простыми функциями, которые покроют большую часть того, что нам нужно уметь сделать при работе с текстом. У нас есть две текстовые переменные - Name (имя персонажа) и Allegiances (дом, которому персонаж принадлежит/лоялен). Давайте попробуем вытащить всех персонажей, лояльных Старкам - как тех, у которых в Alegiances стоит “House Stark”, так и тех, у кого стоит “Stark”. В этом нам поможет функция grep(). Заметьте, что в этой функции необычного - первым ее аргументом является паттерн, который мы ищем, а не данные (как обычно). Я рекомендую пока что ставить параметр fixed = TRUE. Иначе он будет искать по правилам регулярных выражений (да, R по дефолту работает именно с регулярными выражениями). Сейчас это не создаст нам проблем, а вот если будете искать что-то с математическими или другими знаками - проблемы могут возникнуть. Другой важный параметр - ignore.case, который по дефолту FALSE. Это означает, что “СТАРК” и “старк” функция будет считать разными паттернами. grep(&quot;Stark&quot;,got$Allegiances, fixed = TRUE) ## [1] 17 25 29 30 47 53 56 65 69 85 90 91 107 108 110 127 128 ## [18] 133 141 155 161 175 183 194 198 200 209 217 218 227 250 260 262 265 ## [35] 272 286 326 328 340 342 343 346 348 353 362 367 381 392 397 398 405 ## [52] 411 413 414 417 419 448 464 465 467 471 489 500 518 533 534 539 550 ## [69] 561 570 576 581 590 607 613 623 645 647 664 686 697 698 699 702 705 ## [86] 706 709 713 717 726 744 775 783 789 799 817 820 856 872 876 879 881 ## [103] 894 896 897 898 899 912 Ответ - индексы, которые мы можем использовать, чтобы вытащить всех Старков: starks &lt;- got[grep(&quot;Stark&quot;,got$Allegiances, fixed = TRUE), ] table(starks$Allegiances) ## ## House Stark Stark ## 35 73 Остались только Старки! Если вдруг вы при чтении файла не поставили stringsAsFactors = FALSE, то у Вас останутся другие дома, пусть и с нулевыми значениями. Так работают факторы в R. Чтобы избавиться от “пустых” уровней факторов (иногда это нужно), можно воспользоваться простой функцией droplevels(). С character колонками такой магии не нужно. Хорошо, как находить что-то в текстовых переменных - разобрались. А как заменять? У нас здесь есть очевидная задача: Совместить все &quot;House Stark&quot; и просто &quot;Stark&quot;, но для всех домов в оригинальном датасете. Для этого можно поменять все &quot;House &quot; на пустую строку &quot;&quot; с помощью функции gsub(). Она работает примерно так же как и grep(), но сначала идет искомый паттерн (&quot;House &quot;), затем то, на что мы его меняем (&quot;&quot;), потом наш вектор, после - дополднительные параметры. На выходе мы получим новый вектор, который можно подставить взамен старой колонки got$Allegiances (или создать новую колонку got$Houses): got$Houses &lt;- gsub(&quot;House &quot;, &quot;&quot;, got$Allegiances, fixed = TRUE) table(got$Allegiances) ## ## Arryn Baratheon Greyjoy House Arryn ## 23 56 51 7 ## House Baratheon House Greyjoy House Lannister House Martell ## 8 24 21 12 ## House Stark House Targaryen House Tully House Tyrell ## 35 19 8 11 ## Lannister Martell Night&#39;s Watch None ## 81 25 116 253 ## Stark Targaryen Tully Tyrell ## 73 17 22 15 ## Wildling ## 40 Другие важная функция для работы с текстом: nchar() - количество знаков. Давайте найдем самое длинное имя в книгах Джорджа Мартина про лед, пламя, насилие и инцест: max(nchar(got$Name)) ## [1] 33 33 символа! Интересно, у кого же это? longest &lt;- which.max(nchar(got$Name)) #index of the longest name got[longest, 1:2] ## Name Allegiances ## 7 Aemon Targaryen (son of Maekar I) Night&#39;s Watch А, ну, конечно, вот это вот пояснение в скобочках все испортило. Давайте его уберем. Для этого нам понадобится функция substr(). Она работает как “ножницы”: Сначала берем вектор значений, а потом два числа: откуда и покуда будем вырезать нужный кусок: aemon &lt;- substr(got$Name[longest], 1, 15) aemon ## [1] &quot;Aemon Targaryen&quot; got$Name[longest] &lt;- aemon Последнее, что нам нужно знать, это как объединять строки. Не в вектор, а в одно значение. Для этого есть простые функции paste() и paste0(). Для paste() выбрать разделить sep =, который по дефолту является пробелом, а paste0() - функция paste() с пустым сепаратором: paste(&quot;R&quot;, &quot;is&quot;, &quot;love&quot;) ## [1] &quot;R is love&quot; paste0(&quot;R&quot;, &quot;is&quot;, &quot;love&quot;) ## [1] &quot;Rislove&quot; Обратите внимание: функция paste() принимает в качестве аргуметов векторы, чтобы соединить их в один вектор. Если же нужно превратить один строковый вектор в одно значение, то нужно поставить какое-нибудь значение параметра collapse = (по дефолту это NULL): phrase &lt;- paste(c(&quot;All&quot;, &quot;you&quot;, &quot;need&quot;, &quot;is&quot;, &quot;love&quot;), collapse = &quot;_ESSKEETIT_&quot;) phrase ## [1] &quot;All_ESSKEETIT_you_ESSKEETIT_need_ESSKEETIT_is_ESSKEETIT_love&quot; Функция strsplit() делает наоборот - она разбирает значение на вектор: strsplit(phrase, split = &quot;_ESSKEETIT_&quot;) ## [[1]] ## [1] &quot;All&quot; &quot;you&quot; &quot;need&quot; &quot;is&quot; &quot;love&quot; Для тех, кто привык к C format (printf-style formatting), в R это можно сделать с помощью функции sprintf(): sprintf(&quot;%i на кроссовки; Трачу деньги на %s и трачу их без остановки&quot;, 20000, &quot;ерунду&quot;) ## [1] &quot;20000 на кроссовки; Трачу деньги на ерунду и трачу их без остановки&quot; Пока что этого будет нам достаточно для работы с текстом. В принципе, этих функций достаточно в большинстве случаев. Если же вдруг Вам захочется копнуть глубже - придется освоить язык регулярных выражений. Он кажется страшным, но это займет у Вас всего пару часов с вот этим удобным онлайн туториалом и этим онлайн инструментом. Для базовой работы с текстом в R есть вот эта немного занудная, но короткая книжка. В ней примерно все то же самое, что мы сегодня разобрали, но на более глубоком уровне. 3.4 Работа с дополнительными пакетами Пакеты в R - это обычно набор функций (иногда датасетов и т.п.) с документацией по ним. Они нужны для того, чтобы выйти за рамки функциональности базового R или же просто для того, чтобы сделать работу в R еще удобнее. Для R есть около 12000 пакетов, которые вы можете скачать с Comprehensive R Archive Network (CRAN) с помощью простой функции install.packages(), где в качестве инпута используется вектор имен скачиваемых пакетов. install.packages(c(&quot;data.table&quot;, &quot;dplyr&quot;)) Для установки пакетов Вам необходим интернет! Эти 12000 пакетов содержат в себе уйму всякого. Некоторые представляют собой буквально одну удобную функцию, некоторые посвящены какой-то узкоспециализированной теме (например, работе с текстом), есть даже просто наборы всякой всячины от того или иного разработчика (например, пакет Hmisc). Кроме того, можно устанавливать пакеты из других источников и делать собственные. После установки пакета Вы увидете его во вкладке Packages справа внизу Затем нужно “присоединить” этот пакет. Запомните: устанавливаете пакет всего один раз, а присоединяете его в каждой новой сессии. library(&quot;dplyr&quot;) 3.5 Решейпинг данных Теперь мы возьмем данные по битвам из книг про Игру Престолов. Каждая строчка означает какую-то битву, описанную в книгах нашего любомого пухляша-бородача. Подробнее информацию смотри здесь Скачать данные можно здесь bat &lt;- read.csv(&quot;data/battles.csv&quot;) После освоения базовых возможностей датафрейма, становится понятно, что чего-то не хватает. Допустим, мы хотим узнать, в каких годах были наиболее эпичные битвы. Нам нужно посчитать среднее количество бойцов атакующей армии по годам. Зная все года битв, можно сделать так: mean(bat[bat$year == 298, &quot;attacker_size&quot;], na.rm = T) ## [1] 11175 mean(bat[bat$year == 299, &quot;attacker_size&quot;], na.rm = T) ## [1] 5134.308 mean(bat[bat$year == 300, &quot;attacker_size&quot;], na.rm = T) ## [1] 19333.33 Всякий раз, когда у Вас возникает желание сделать что-нибудь с помощью священного копипаста - задумайтесь: разве ради этого Вы пришли на курс? Конечно, нет! Как говорилось ранее, если появляется желание копипастить одни и те же строчки, это означает, что, скорее всего, это можно сделать быстрее, проще и лучше. Конечно, стандартными возможностями R, которые мы уже освоили, нашу задачу можно выполнить, но довольно неудобно: sapply(unique(bat$year), function(x) mean(bat$attacker_size[bat$year == x], na.rm = T)) ## [1] 11175.000 5134.308 19333.333 В принципе, есть много других способов сделать то же самое - функция aggregate(), split(), но мы на них останавливаться не будем. Тем не менее, задача аггрегации данных - это то, что необходимо постоянно. Усреднить значения по каждому испытуемому, получить средние значения по каждому из уровней всех переменных… А если нужно не усреднять, а делать что-то более сложное? Очевидно, что тут нам нужны какие-то новые инструменты, которых мы еще не знаем. И здесь у нас появляется важная развилка - есть два разных пакета, которые позволяют удобно делать агрегацию и другие операции, о которых мы говорили раньше (например, сабсеттинг) и о которых мы еще поговорим позднее. 3.5.1 data.table vs. dplyr Пакет dplyr от создателя ggplot2 (а еще tidyr, stringr, lubridate, devtools, httr, readr и много других популярных пакетов для R) Хэдли Уиэкхэма. Сейчас этот парень работает в RStudio, следы чего вы можете обнаружить. Например, откройте Help - Cheatsheets: Вы обнаружите читшиты для dplyr. Но не для data.table =) Этот подход сильно перерабатывает синтаксис R, отличается понятностью и читаемостью. Более того, он очень популярен, многие пакеты предполагают, что Вы именно с ним работаете и хорошо им владеете. library(&quot;dplyr&quot;) bat %&gt;% group_by(year) %&gt;% summarise(mean(attacker_size, na.rm = T)) ## # A tibble: 3 x 2 ## year `mean(attacker_size, na.rm = T)` ## &lt;int&gt; &lt;dbl&gt; ## 1 298 11175 ## 2 299 5134. ## 3 300 19333. Просто попытайтесь догадаться, что значат эти строчки: берем датафрейм, группируем по году, выводим какую-то суммирующию информацию по каждой группе. Оператор %&gt;% называется “пайпом” (pipe), т.е. “трубой”. Он означает, что следующая функция принимает на вход в качестве первого аргумента аутпут предыдущей. Фактически, это примерно то же самое, что и вставлять аутпут функции как первый инпут в другую функцию. Просто выглядит это красивее и читабельнее. Как будто данные пропускаются через трубы функций или конвеерную ленту на заводе, если хотите. А то, что первый параметр функции - это почти всегда данные, работает нам на руку. Этот оператор взят из пакета magrittr (поняли отсылку? Если нет, то смотрите здесь: http://www.magritte.be/oeuvre-magritte-en.html ) Возможно, даже если вы не захотите пользоваться dplyr, использование пайпов Вам понравится. Ну а если нет, то тогда вперед к data.table! Другой подход - пакет data.table. Он не так сильно перерабатывает стиль работы в R, но изменяет датафреймы, “совершенствуя” их. Этот пакет сильно повышает скорость обработки данных, поскольку написан с использованием более совершенных алгоритмов. data.table обладает более “суровым” и лаконичным синтаксисом: library(&quot;data.table&quot;) batdt &lt;- as.data.table(bat) batdt[,mean(attacker_size, na.rm = T), by = year] ## year V1 ## 1: 298 11175.000 ## 2: 299 5134.308 ## 3: 300 19333.333 Внешне все очень похоже на работу с обычным data.frame, но если приглядитесь, то увидите, что появился непонятный by = - это как раз-таки группировка. Более того, мы делаем анализ прямо в том месте, где раньше просто выбирали столбцы. Да и столбцы эти (как и строчки) мы выбираем без кавычек. 3.5.2 Так что же выбрать? Мы остановимся на data.table. В принципе, если Вы освоили один пакет, то альтернативный пакет уже не нужен - про это можете почитать замечательную дискуссию от создателей пакетов. Основной вывод - оба пакета позволяют делать нужные нам вещи, но разными способами. 3.5.3 data.table Мы начнем с очень милой функции под названием fread(). Эта функция похожа на функцию read.table(), но быстрее (воистину!) и автоматически подбирает параметры чтения файлов (обычно правильно). В большинстве случаев Вы можете просто использовать эту функцию без задания каких-либо параметров для чтения таблицы - и готово! batdt &lt;- fread(&quot;data/battles.csv&quot;) Ну, на этом датасете Вы едва ли заметите разницу в скорости, а вот если у вас датасет побольше, скажем, на несколько десятков мегабайт, то разница будет заметна. Заметьте, теперь это уже не совсем датафрейм: class(batdt) ## [1] &quot;data.table&quot; &quot;data.frame&quot; Одновременно датафрейм и дататейбл! Это означает, что почти все, что мы умеем делать с датафреймом, мы можем делать так же и с дататейблом, но теперь нам открываются новые возможности (и новый синтаксис). Некоторые используют пакет data.table только для того, чтобы быстрее загружать данные. Если Вы захотите пойти этим путем, то нужно поставить параметр data.table = FALSE - тогда данные загрузятся как “чистый” датафрейм. Кроме того, в R можно использовать функцию, не подключая весь пакет с помощью оператора ::. То есть вот так: batdataframe &lt;- data.table::fread(&quot;data/battles.csv&quot;, data.table = FALSE) Этот оператор :: еще рекомендуется использовать, если у Вас есть есть несколько одноименных функций для одного и того же из разных пакетов, и есть риск запутаться в том, какой именно пакет вы используете. 3.5.3.1 Основы data.table Data.table обладает своим синтаксисом, напоминающим SQL (если Вы не знаете, что это, то Вы счастливый человек; ну а если знаете, то быстрее освоитесь). Главная формула звучит так: DT[i, j, by] Здесь i - это то, какие Вы выбираете строки. Очень похоже на обычный data.frame, не так ли? j - это то, что Вы считаете. Это тоже похоже на датафрейм - Вы выбираете колонки. Но тут есть важное различие - можно что-то считать прямо внутри j, т.е. внутри квадратных скобочек! by - это аггрегация по подгруппам. “General form: DT[i, j, by] “Take DT, subset rows using i, then calculate j grouped by by” (из читшита по data.table). Если проводить аналогии с SQL, то i = WHERE, j = SELECT | UPDATE, by = GROUP BY. Естественно, далеко не всегда используются сразу все три i, j и by. Но это дает прекрасные возможности делать сложные операции с данными в одну строчку. Как и в датафрейме, если Вы хотите выбрать все строчки, просто оставляете поле перед первой запятой пустым. Если не хотите делать группировку, то можете просто не писать вторую запятую. Если же не писать вообще запятых внутри квадратных скобок, то все внутри будет считаться как i, т.е. Вы будете выбирать только строки. Но я советую все-таки ставить одну запятую, чтобы не запутаться с тем, где выбираются строки (i), а где производятся манипуляции с колонками (j). Скажем, мы хотим посчитать средний размер защищающихся армий только для битв, где победили атакующие, группируя по регионам: batdt[attacker_outcome == &quot;win&quot;, mean(attacker_size, na.rm = TRUE), by = region] ## region V1 ## 1: The Westerlands 9000.000 ## 2: The Riverlands 4425.000 ## 3: The North 1107.667 ## 4: The Stormlands 3500.000 ## 5: The Reach NaN Вуаля! Давайте разберем этот пример подробнее: i: выбираем только те строки, где attacker_outcome равен &quot;win&quot;. Заметьте, мы тут используем не вектор (как если бы это была переменная), а название колонки и без кавычек! j: прямо в j считаем средний размер атакующей армии. Опять же - без кавычек используем название столбца. by: группируем по региону. То есть как бы делим дататейбл на пять дататейблов и применяем функцию среднего для каждого. В итоге мы получили новый дататейбл! По дефолту новому столбцу будет присваиваться название V1 (а если такая колонка есть, то V2 и т.д.), но можно присвоить и свое название колонки. Для этого используйте круглые скобки и точку перед ними: batdt[attacker_outcome == &quot;win&quot;, .(mean_attack = mean(attacker_size, na.rm = TRUE)), by = region] ## region mean_attack ## 1: The Westerlands 9000.000 ## 2: The Riverlands 4425.000 ## 3: The North 1107.667 ## 4: The Stormlands 3500.000 ## 5: The Reach NaN .() - это то же самое, что и list(). То есть мы создаем список, а это значит, что мы можем сделать сразу несколько операций: batdt[attacker_outcome == &quot;win&quot;, .(mean_attack = mean(attacker_size, na.rm = TRUE), max_attacker = max(attacker_size, na.rm = TRUE)), by = region] ## Warning in gmax(attacker_size, na.rm = TRUE): No non-missing values found ## in at least one group. Coercing to numeric type and returning &#39;Inf&#39; for ## such groups to be consistent with base ## region mean_attack max_attacker ## 1: The Westerlands 9000.000 15000 ## 2: The Riverlands 4425.000 15000 ## 3: The North 1107.667 4500 ## 4: The Stormlands 3500.000 5000 ## 5: The Reach NaN -Inf 3.5.3.2 Создание новых колонок В data.table есть специальный оператор := для создания новых колонок. Давайте создадим новую колонку, по которой будет проще понять, кто победил в битве: batdt[,outcome:=ifelse(attacker_outcome == &quot;win&quot;, &quot;Победа атакующих&quot;, ifelse(attacker_outcome == &quot;loss&quot;, &quot;Победа защищающихся&quot;, &quot;Исход неизвестен&quot;))] Оператор := создает поверхностную копию, т.е. не копирует физически данные. Заметьте, мы даже не присваиваем результат выполнения этой операции новой переменной: просто в нашем batdt появилась новая колонка. Если мы хотим создать сразу несколько столбцов за раз, то можно использовать оператор := как функцию: batdt[, &#39;:=&#39;(all_army = attacker_size + defender_size, ratio_army = attacker_size / defender_size)] 3.5.3.3 Chaining Chaining (формирование цепочки) - это что-то вроде альтернативы пайпам. В принципе, это можно делать и с обычным датафреймом или матрицей, но именно с data.table это становится удобным и клевым инструментом. А также способом “сделать весь анализ в одну очень длинную строчку”. Все просто - аутпут вычислений в data.table обычно является новый data.table. И ничто не мешает нам делать несколько квадратных скобочек, превращая код в паравозик со множеством вагонов. Это позволяет избежать промежуточных присвоений переменных, как и в случае с пайпами. Давайте шаг за шагом создадим такой паровозик для того, чтобы сделать таблицу частот битв по регионам. Для начала нам нужно посчитать длину столбцов. Для этого в data.table есть .N, и это гораздо удобнее, чем считать length() какого-нибудь столбца: batdt[.N,] ## name year battle_number attacker_king ## 1: Siege of Winterfell 300 38 Stannis Baratheon ## defender_king attacker_1 attacker_2 attacker_3 attacker_4 ## 1: Joffrey/Tommen Baratheon Baratheon Karstark Mormont Glover ## defender_1 defender_2 defender_3 defender_4 attacker_outcome ## 1: Bolton Frey NA NA ## battle_type major_death major_capture attacker_size defender_size ## 1: NA NA 5000 8000 ## attacker_commander defender_commander summer location region note ## 1: Stannis Baratheon Roose Bolton 0 Winterfell The North ## outcome all_army ratio_army ## 1: Исход неизвестен 13000 0.625 Заметьте, мы используем .N в j (т.е. после первой запятой). Если мы используем .N в i, то получим просто последнюю строчку дататейбла. Если же мы аггрегируем по регионам, то получим таблицу частот регионов - что нам и нужно: batdt[,.N, by = region] ## region N ## 1: The Westerlands 3 ## 2: The Riverlands 17 ## 3: The North 10 ## 4: The Stormlands 3 ## 5: The Crownlands 2 ## 6: Beyond the Wall 1 ## 7: The Reach 2 Отличная альтернатива функции table()! Можно было сохранить результат в новой переменной, а можно просто продолжить работать с получившимся дататейблом, “дописывая” его. batdt[,.N, by = region][order(-N),] ## region N ## 1: The Riverlands 17 ## 2: The North 10 ## 3: The Westerlands 3 ## 4: The Stormlands 3 ## 5: The Crownlands 2 ## 6: The Reach 2 ## 7: Beyond the Wall 1 Теперь мы отсортировали регионы по количеству битв. Мы используем функцию order(), чтобы посчитать ранг каждого значения нового столбца N, а потом использовать это для выбора строк в нужном порядке. Добавление минуса позволяет “инвертировать” этот порядок, чтобы получилось от большего к меньшему. batdt[,.N, by = region][order(-N),][N&gt;2,] ## region N ## 1: The Riverlands 17 ## 2: The North 10 ## 3: The Westerlands 3 ## 4: The Stormlands 3 Продолжая наш паровозик, мы “отрезали” от получившегося дататейбла только те регионы, где N больше двух. Для лучшей читаемости можно организовать цепочку таким образом: batdt[,.N, by = region ][order(-N), ][N&gt;2,] ## region N ## 1: The Riverlands 17 ## 2: The North 10 ## 3: The Westerlands 3 ## 4: The Stormlands 3 3.5.4 Широкий и длинный форматы данных Что если у Вас есть несколько измерений по одному испытуемому? Например, вес до и после прохождения курса. Как вы это запишите - как два числовых столбца (один испытуемый - одна строка) или же создадите отдельную “группирующую” колонку, в которой будет написано время измерения, а в другой - измеренные значения (одно измерение - одна строка)? На самом деле, оба варианта приемлимы, оба варианта возможны в реальных данных, а разные функции и статистические пакеты могут требовать от вас как “длинный”, так и “широкий” форматы. 3.5.4.1 “Широкий” формат Студент До курса по R После курса по R Маша 70 63 Рома 80 74 Антонина 86 71 3.5.4.2 “Длинный” формат Студент Время измерения Вес (кг) Маша До курса по R 70 Рома До курса по R 80 Антонина До курса по R 86 Маша После курса по R 63 Рома После курса по R 74 Антонина После курса по R 71 3.5.5 Решейпинг в data.table: melt() и dcast() Таким образом, нам нужно научиться переводить из широкого формата в длинный и наоборот. Это может показаться довольно сложной задачей, но для это в data.table есть специальные функции: melt() (= “плавление”): из широкого в длинный формат dcast()(= “литье”): из длинного в широкий формат 3.5.5.1 Пример 1: melt() для размера армий В нашем дататейбле batdt у нас есть две колонки, которые содержат информацию про размер армий: attacker_size и defender_size. head(batdt[, .(name, year, attacker_size, defender_size)]) ## name year attacker_size defender_size ## 1: Battle of the Golden Tooth 298 15000 4000 ## 2: Battle at the Mummer&#39;s Ford 298 NA 120 ## 3: Battle of Riverrun 298 15000 10000 ## 4: Battle of the Green Fork 298 18000 20000 ## 5: Battle of the Whispering Wood 298 1875 6000 ## 6: Battle of the Camps 298 6000 12625 Это пример широкого формата: у нас два измерения на каждую битву. Допустим, мы хотим сделать длинный формат. В новом дататейбле будет “группирующая” колонка battle_role, а все размеры армий будут в новой колонке army_size: batlong &lt;- melt(batdt, measure.vars = c(&quot;attacker_size&quot;, &quot;defender_size&quot;), variable.name = &quot;battle_role&quot;, value.name = &quot;army_size&quot;) Теперь новый дататейбл batlong в два раза длиннее оригинального, а названия колонок attacker_size и defender_size превратились в значения колонки battle_role. Важные параметры функции melt(): data - Ваш data.table id.vars - вектор имен id. Можно не ставить, если у нас “чистый” длинный формат. measure.vars - вектор названий колонок (т.е. в кавычках!), которые содержат измерения Note: melt() удалит в новом дататейбле все колонки, которые вы написали в id.vars и measure.vars. variable.name - название новой “группирующей” колонки value.name - название новой колонки с измерениями 3.5.5.2 Пример 2: dcast() для размера армий А теперь обратно к широкому формату! Функция dcast() использует формулы. Это новый для нас тип данных, но мы с ним еще столкнемся, когда перейдем к статистическим тестам и моделям, поэтому давайте немного ознакомимся с ними. Собственно, для задания статистических моделей формулы в R и существуют, но иногда они используются и в других случаях. class(y ~ x1 + x2 * x3) ## [1] &quot;formula&quot; В формуле обязательно присутствует тильда (~ - в клавиатуре на кнопке “ё”), которая разделяет левую и правую часть. Давайте вернемся к dcast() batwide &lt;- dcast(batlong, ... ~ battle_role, value.var = &quot;army_size&quot;) Мы практически вернулись к исходному batdt, разве что колонки в другой последовательности. ###Объединение с помощью rbind(), cbind() и merge() Допустим, у нас есть два дататейбла. Мы создадим немного искусственную ситуацию, разделив длинный дататейбл на два: bat_at &lt;- batlong[battle_role == &quot;attacker_size&quot;,] bat_def &lt;- batlong[battle_role == &quot;defender_size&quot;,] Ну а теперь попробуем склеить их обратно! Для этого есть три замечательные функции: rbind(), cbind() и merge(). С первымии двумя все просто. rbind() соединяет вертикально, а cbind() - горизонтально. verylong_bat &lt;-cbind(bat_at, bat_def) #c stands for columns h_bat это результат вертикального соединения. По сути, мы почти вернулись к batlong verywide_bat &lt;- rbind(bat_at, bat_def) #r stands for rows А теперь мы сделали горизонтальное соединение, получив ооочень широкий дататейбл с повторяющимися колонками. Самое сложное (и самое интересное!) - это merge(). На практике часто случается, что нужно объединить два датасета. Например, поведенческие данные с какими-нибудь метриками ЭЭГ. Скажем, время реакции на задачу и мощность альфа-ритма. Или, например, мы хотим добавить в набор данных информацию о поле и возрасте, которая у нас хранится в отдельной табличке. Все, что объединяет два датасета - это id испытуемых, по которым нужно составить новую табличку. Другая проблема может возникнуть, когда мы сделали какой-то анализ с данными, что-то аггрегировали, посчитали, а теперь это нужно вставить в оригинальный датасет. Давайте решим такую задачу: создадим сабсет из нашего batdt, в котором будут только битвы, которые проходили в регионах, где было больше двух битв. Первую часть этой задачи мы уже делали сегодня: считали частоты по регионам, а потом оставляли только регионы с больше чем двумя битвами: batdt[,.N, by = region][order(-N),][N&gt;2,] ## region N ## 1: The Riverlands 17 ## 2: The North 10 ## 3: The Westerlands 3 ## 4: The Stormlands 3 Сохраним этот результат в переменную hot_regions. hot_regions &lt;- batdt[,.N, by = region][order(-N),][N&gt;2,] Теперь воспользуемся merge(): subset_batdt &lt;- merge(hot_regions, batdt, by = &quot;region&quot;, all.x = TRUE, all.y = FALSE) Получилось! А теперь чуть подробнее, о том, что мы сделали. Первые два аргумента в merge() - это дататейблы. by = это тот самый айди, который должен совпадать у обоих дататейблов. Это может быть не одна, а сразу несколько колонок. В качестве значения по умолчанию используются все общие колонки двух дататейблов. Если названия не совпадают, то их можно прописать в by.x = и by.y = отдельно. Следующие важные варианты - это all.x = и all.y =. С помощью этих параметров мы прописываем, что нужно сделать, если список айдишников (в нашем случае - регионов) не совпадает. Они могут принимать значения TRUE и FALSE, в зависимости от этого есть 4 варианта: all = T: добавит новые строки, если в каком-то из дататейблов каких-то значений нет. Что-то вроде логического “ИЛИ” для выбора строк: если хотя бы в одном дататейбле есть строки с каким-то айди, то они добавятся в получившийся дататейбл. all.x = T, all.y = F: возьмет все строки из первого дататейбла, но проигнорирует все строки с айдишниками, которых нет во втором дататейбле. all.x = F, all.y = T: возьмет все строки из второго дататейбла, но проигнорирует лишние строки из первого. all.x = F, all.y = F: возьмет только строчки, айдишники которых пересекаются в обоих дататейблах. Мы взяли именно второй вариант. Взяли все регионы из hot_regions и проигнорировали те регионы, что встречаются только в batdt. 3.6 Заключение Итак, мы научились делать самые сложные штуки в R (из тех, которые жизненно необходимы вне зависимости от данных). Сабсетить данные, агрегировать, вертеть их, соединять… На самом деле, подобные вещи отнимают большую часть времени, и они не раз нам понадобятся в будущем. С другой стороны, какие-то сложные вещи, например, melt(), dcast() и merge() сложно запомнить сразу. И это нормально, главное - понимать, в какую сторону гуглить и какие заметки смотреть в случае необходимости. "],
["vis.html", "4 День 3. Описательная статистика и визуализация 4.1 Описательная статистика", " 4 День 3. Описательная статистика и визуализация 4.1 Описательная статистика Статистика делится на описательную статистику (descriptive statistics) и статистику вывода (inferential statistics). Описательная статистика пытается описать нашу выборку (sample, т.е. те данные, что у нас на руках) различными способами. Проблема в том, что описательная статистика может описать только то, что у нас есть, но не позволяет сделать выводы о генеральной совокупности (population) - это уже цель статистики вывода. Цель описательной статистики - “ужать” данные для их обобщенного понимания с помощью статистик. Заметьте, у выборки (sample) мы считаем статистики (statistics), а у генеральной совокупности (Population) есть параметры (Parameters). Вот такая вот мнемотехника. Статистики часто выступают в роли точечной оценки (point estimators) параметров, так что в этом легко запутаться. Например, среднее (в выборке) - это оценка среднего (в популяции). Да, можно свихнуться. Мы это будем разбирать подробнее в следующие занятия (это действительно важно, поверьте), пока что остановимся только на описании выборки. Сегодня мы будем работать с пакетом survival, в котором есть датасет pbc. Мы его сразу превратим в data.table library(survival) library(data.table) data(pbc) pbcdt &lt;- as.data.table(pbc) Это данные 424 пациентов с первичным билиарным циррозом - редким аутоимунным заболеванием печени. При поступлении в клинику у них измерили разные медицинские показатели, определели в экспериментальную и контрольную группу. В наборе данных есть информация о том, что стало с этими испытуемыми. This data is from the Mayo Clinic trial in primary biliary cirrhosis (PBC) of the liver conducted between 1974 and 1984. A total of 424 PBC patients, referred to Mayo Clinic during that ten-year interval, met eligibility criteria for the randomized placebo controlled trial of the drug D-penicillamine. The first 312 cases in the data set participated in the randomized trial and contain largely complete data. Подробнее про датасет можно почитать здесь или в хэлпе Эти данные часто используются в качестве примера для анализа выживаемости. Эти данные уже в достаточно упорядоченном виде и не нуждаются в предобработке (что, к сожалению, случай малореалистичный). Зато на этом наборе данных можно Для простоты мы удалим все пропущенные значения. Мы уже знакомы с функцией is.na(), теперь познакомимся с еще одной функцией: complete.cases() возвращает вектор, равный длине датафрейма, с FALSE для строчек, где есть хотя бы один NA, и TRUE если пропущенных значений нет. pbcdt &lt;- pbcdt[complete.cases(pbc),] Пока что мы будем использовать только данные о возрасте испытуемых. Для краткости обозначим это вектором a a &lt;- pbcdt$age 4.1.1 Меры центральной тенденции Мера центральной тенденции - это число для описания центра распределения. 4.1.1.1 Арифметическое среднее Самая распространенная мера центральных тенденций - арифметическое среднее, то самое, которые мы считаем с помощью функции mean() \\[\\overline{x}= \\frac{\\sum\\limits_{i=1}^{n} x_{i}} {n}\\] Не пугайтесь значка \\[\\sum\\limits_{i=1}^{n}\\] - это означает сумму от i = 1 до n. Что-то вроде цикла for! В качестве упражнения попробуйте самостоятельно превратить эту формулу в функцию mymean() c помощью sum() и length(). Можете убирать NA по дефолту! Сравните с результатом функции mean(). mean(a) ## [1] 49.79966 4.1.1.2 Медиана Медиана - это середина распределения. Представим, что мы расставили значения по порядку (от меньшего к большему) и взяли значение по середине. Если у нас четное количество значений, то берется среднее значение между теми двумя, что по середине. Для расчета медианы есть функция median(): median(a) ## [1] 49.70979 Разница медианы со средним не очень существенная. Это значит, что распределение довольно “симметричное”. Но бывает и по-другому. Представьте себе, что кто-то говорит про среднюю зарплату в Москве. Но ведь эта средняя зарплата становится гораздо больше, если учитывать относительно небольшое количество мультимиллионеров и миллиардеров! А вот медианная зарплата будет гораздо меньше. Представьте себе, что в эту клинику с циррозом печени пришел 8000-летний Король Ночи из Игры Престолов. Тогда арифметическое среднее станет гораздо больше: mean(c(a, 8000)) ## [1] 78.50075 А вот медиана останется почти той же. median(c(a, 8000)) ## [1] 49.76318 Таким образом, экстремально большие или маленькие значения оказывают сильное влияние на арифметическое среднее, но не на медиану. Поэтому медиана считается более “робастной” оценкой, т.е. более устойчивой к выбросам и крайним значениям. 4.1.1.3 Усеченное среднее (trimmed mean) Если про среднее и медиану слышали все, то про усеченное (тримленное) среднее известно гораздо меньше. Тем не менее, на практике это довольно удобная штука, потому что представляет собой некий компромисс между арифметическим средним и медианой. В усеченном среднем значения ранжируются так же, как и для медианы, но отбрасывается только какой-то процент крайних значений. Усеченное среднее можно посчитать с помощью обычной функции mean(), поставив нужное значение параметра trim =: mean(a, trim = 0.1) ## [1] 49.57392 trim = 0.1 означает, что мы отбросили 10% слева и 10% справа. trim может принимать значения от 0 до 0.5. Что будет, если trim = 0? mean(a, trim = 0) ## [1] 49.79966 Обычное арифметическое среднее! А если trim = 0.5? mean(a, trim = 0.5) ## [1] 49.70979 Медиана! 4.1.1.4 Мода Мода (mode) - это самое частое значение. Обычно используется для номинальных переменных. Например, можно посчитать моду для регионов, в которых происходили битвы. Что интересно, в R нет встроенной функции для подсчета моды. Обычно она и не нужна: мы можем посчитать таблицу частот и даже проранжировать ее (и мы уже умеем это делать разными способами). На случай если Вы все-таки хотите создать свою функцию для моды, можно попробовать что-то такое: mymode &lt;- function(x){names(which.max(table(x)))} mymode(pbcdt$sex) ## [1] &quot;f&quot; 4.1.2 Меры рассеяния Статистик пытался перейти в брод реку, средняя глубина которой 1 метр. И утонул. В чем была его ошибка? Он не учитывал разброс значений глубины! Мер центральной тенденции недостаточно, чтобы описать выборку. Необходимо знать ее вариабельность. 4.1.2.1 Размах Самое очевидное - посчитать размах (range), то есть разницу между минимальным и максимальным значением. В R есть функция для вывода максимального и минимального значений: range(a) ## [1] 26.27789 78.43943 Осталось посчитать разницу между ними: diff(range(a)) ## [1] 52.16153 Естественно, крайние значения очень сильно влияют на этот размах, поэтому на практике он не очень-то используется. 4.1.2.2 Дисперсия Дисперсия (variance) вычисляется по следующей формуле: \\[s^2= \\frac{\\sum\\limits_{i=1}^{n} (x_{i} - \\overline{x})^2} {n}\\] Попробуйте превратить это в функцию myvar()! myvar &lt;- function(x) mean((x - mean(x))^2) Естественно, в R уже есть готовая функция var(). Но, заметьте, ее результат немного отличается от нашего: myvar(a) ## [1] 110.334 var(a) ## [1] 110.7353 Дело в том, что встроенная функция var() делит не на \\(n\\), а на \\(n-1\\). Это связано с тем, что эта функция пытается оценить дисперсию в генеральной совокупности, т.е. относится уже к статистике вывода. Про это мы будем говорить в дальнейших занятиях, сейчас нам нужно только отметить то, что здесь есть небольшое различие. 4.1.2.3 Стандартное отклонение Если вы заметили, значение дисперсии очень большое. Чтобы вернуться к единицам измерения, соответствующих нашим данным используется корень из дисперсии, то есть стандартное отклонение (standard deviation): \\[s= \\sqrt\\frac{\\sum\\limits_{i=1}^{n} (x_{i} - \\overline{x})^2} {n}\\] Для этого есть функция sd(): sd(a) ## [1] 10.52308 Что то же самое, что и: sqrt(var(a)) ## [1] 10.52308 4.1.2.4 Медианное абсолютное отклонение Поскольку стандартное отклонение не устойчово ко всяким выбросам, то иногда используют его альтернативу, которая устойчива к выбросам (особенно если эти выбросы нам как раз и нужно удалить) - медианное абсолютное отклонение (median absolute deviation): \\[mad= median(|x_{i} - median(x)|)\\] Для этого есть функция mad(): mad(a) ## [1] 10.63291 4.1.2.5 Межквартильный размах Другой вариант рабостной оценки вариабельности данных является межквартильный размах (interquartile range = IQR). Это разница между третьим и первым квартилем - значением, которое больше 75% значений в выборке, и значением, которое больше 25% значений в выборке. IQR(a) ## [1] 15.07187 Ну а второй квартиль - это медиана! 4.1.3 Ассиметрия и куртозис 4.1.3.1 Ассиметрия Ассиметрия (skewness) измеряет симметричность распределения. Положительный показатель ассиметрии (“Right-skewed” или positive skewness) означает, что хвосты с правой части распределения длиннее. Негативный показатель ассиметрии (“Left-skewed” или negative skewness) означает, что левый хвост длиннее. В психологии положительная ассиметрия встречается очень часто. Например, время реакции: оно ограничено снизу 0 мс (а по факту не меньше 100 мс - быстрее сигнал не успеет по нервной системе пройти до пальцев), а вот с другой стороны оно никак не ограничено. Испытуемый может на полчаса перед монитором затупить, ага. 4.1.3.2 Куртозис Куртозис (kurtosis) - это мера “вытянутости” распределения: 4.1.3.3 Ассиметрия и куртозис в R К сожалению, в базовом R нет функций для ассиметрии и куртозиса. Зато есть замечательный пакет psych (да-да, специально для психологов). install.packages(&quot;psych&quot;) library(&quot;psych&quot;) В нем есть функции skew() и kurtosi(): skew(a) ## [1] 0.1786867 kurtosi(a) ## [1] -0.5174814 Заметьте, наше распределение атакующих армий сильно вытянуто вверх и имеет длинный хвост справа. 4.1.4 А теперь все вместе! В базовом R есть функция summary(), которая позволяет получить сразу неплохой набор описательных статистик. summary(a) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 26.28 41.51 49.71 49.80 56.58 78.44 Функция summary() - это универсальная (generic) функция. Это означает, что Вы можете ее применять для разных объектов и получать разные результаты. Попробуйте применить ее к векторам с разными типами данных и даже к дата.фреймам и дата.тейблам. Посмотрите, что получится. В пакете psych есть еще и замечательная функция describe(), которая даст Вам еще больше статистик, включая ассиметрию и куртозис: describe(a) ## vars n mean sd median trimmed mad min max range skew ## X1 1 276 49.8 10.52 49.71 49.57 10.63 26.28 78.44 52.16 0.18 ## kurtosis se ## X1 -0.52 0.63 Даже усеченное (trimmed) среднее есть (с trim = 0.1)! Все кроме se мы уже знаем. А про этот se узнаем через позже. Эта функция прекрасно работает в data.table в сочетании с by=: pbcdt[, describe(age), by = stage] ## stage vars n mean sd median trimmed mad min ## 1: 4 1 94 53.09709 10.71781 53.92334 53.20437 10.890666 29.55510 ## 2: 3 1 111 47.94154 10.00419 47.42779 47.41838 9.948946 26.27789 ## 3: 2 1 59 48.52757 10.22616 48.75838 48.34855 10.975908 30.27515 ## 4: 1 1 12 47.41182 10.11477 47.97673 47.75359 12.132762 28.88433 ## max range skew kurtosis se ## 1: 78.43943 48.88433 -0.07684694 -0.4361883 1.105458 ## 2: 71.89322 45.61533 0.35465904 -0.3655477 0.949556 ## 3: 75.01164 44.73648 0.19440406 -0.7000602 1.331333 ## 4: 62.52156 33.63723 -0.06406915 -1.1025021 2.919883 4.1.5 Описательных статистик недостаточно Я в тайне от Вас загрузил данные в переменную xxx. Выглядят они примерно так: head(xxx) ## x y ## 1: 55.3846 97.1795 ## 2: 51.5385 96.0256 ## 3: 46.1538 94.4872 ## 4: 42.8205 91.4103 ## 5: 40.7692 88.3333 ## 6: 38.7179 84.8718 str(xxx) ## Classes &#39;data.table&#39; and &#39;data.frame&#39;: 142 obs. of 2 variables: ## $ x: num 55.4 51.5 46.2 42.8 40.8 ... ## $ y: num 97.2 96 94.5 91.4 88.3 ... ## - attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt; Надеюсь, Вы уже понимаете, как это интерпретировать - два столбца с 142 числами каждый. Представьте себе, как выглядят эти точки на плоскости, если каждая строчка означают координаты одной точки по осям x и y (это называется диаграмма рассеяния, точечная диаграмма или scatterplot). Применим разные функции, которые мы выучили: mean(xxx$x) ## [1] 54.26327 mean(xxx$y) ## [1] 47.83225 median(xxx$x) ## [1] 53.3333 median(xxx$y) ## [1] 46.0256 Средние и медианы примерно одинаковые, при этом по х они около 53-54, а по у - примерно 46-47. Попытайтесь представить это. Идем дальше: sd(xxx$x) ## [1] 16.76514 sd(xxx$y) ## [1] 26.9354 Похоже, расброс по у несколько больше, верно? skew(xxx$x) ## [1] 0.2807568 skew(xxx$y) ## [1] 0.2472603 kurtosi(xxx$x) ## [1] -0.2854912 kurtosi(xxx$y) ## [1] -1.063552 Похоже, оба распределения немного право-ассиметричны и довольно “плоские”. Давайте еще посчитаем корреляцию. Мы про нее будем говорить позже гораздо подробнее. Пока что нам нужно знать, что она говорит о линейной связи двух переменных. Если корреляция положительная (максимум равен 1), то чем больше х, тем больше у. Если отрицательная (минимум равен -1), то чем больше х, тем меньше у. Если же корреляция равна нулю, то такая линейная зависимость отсутствует. cor(xxx$x, xxx$y) ## [1] -0.06447185 Корреляция очень близка к нулю (делайте выводы и представляйте). Давайте напоследок воспользуемся функцией describe() из psych: describe(xxx) ## vars n mean sd median trimmed mad min max range skew ## x 1 142 54.26 16.77 53.33 53.69 15.97 22.31 98.21 75.90 0.28 ## y 2 142 47.83 26.94 46.03 46.90 30.79 2.95 99.49 96.54 0.25 ## kurtosis se ## x -0.29 1.41 ## y -1.06 2.26 Готовы узнать, как выглядят эти данные на самом деле?! Жмите сюда! Из этого можно сделать важный вывод: не стоит слепо доверять описательным статистикам. Нужно визуализировать данные, иначе можно попасть в такую ситуацию в реальности. Все следующее занятие будет посвящено визуализации данных. — Описательная статистика (центральные тенденции, меры разброса, skewness, kurtosis, функции для описательной статистики) — Визуализация в R, базовые средства визуализации и ggplot2 — Plotly — Создание publication-quality графиков, пакет cowplot — Самостоятельное упражнение на визуализацию — RMarkdown "],
["nhst.html", "5 День 4. Статистические оценки и проверка гипотез", " 5 День 4. Статистические оценки и проверка гипотез — Выборка и генеральная совокупность — Виды распределений, параметры распределений — Нормальное распределение. Функции распределений в R — Оценка параметров, точечные и интервальные оценки, доверительный интервал — Проверка гипотез. Ошибки I и II рода — Нулевая и альтернативная гипотеза, p-value — Мощность. z-критерий. t-критерий в случае одной и двух выборок, связанные выборки — Когда применять параметрические, а когда непараметрические методы — Рассчитаем критерии своими руками и изучим готовые функции R "],
["lm.html", "6 День 5. Линейная регрессия и корреляция", " 6 День 5. Линейная регрессия и корреляция — Линейная регрессионная модель — Коэффициенты линейной модели — Множественная линейная регрессия — Предположения линейной модели. “Остатки”, МНК и goodness-of-fit — Обобщенная линейная регрессия — Корреляция. Ковариация, коэффициент корреляции Пирсона — Ранговая корреляция. Частная и множественная корреляция "],
["anova.html", "7 День 6. ANOVA и продвинутые методы препроцессинга 7.1 Введение в ANOVA 7.2 Тестирование значимости нулевой гипотезы в ANOVA. 7.3 Post-hoc тесты 7.4 Другие способы проведения ANOVA в R. 7.5 Factorial ANOVA (Многофакторный ANOVA) 7.6 ANCOVA (ANalysis of COVAriance; Ковариационный анализ) 7.7 Repeated measures ANOVA (Дисперсионный анализ с повторными измерениями) 7.8 Смешанный внутригрупповой-межгрупповой дисперсионный анализ (Mixed between-within-subjects ANOVA) 7.9 Непараметрические аналоги ANOVA 7.10 Заключение", " 7 День 6. ANOVA и продвинутые методы препроцессинга — Дисперсионный анализ (ANOVA) — Однофакторный и многофакторный ANOVA — Анализ повторных измерений. Непараметрические аналоги ANOVA — Пропущенные значения и нормализация — Зачем нужны кластерный анализ, MDS и PCA в работе с биологическими данными На финальном занятии мы разберем дисперсионный анализ (ANalysis Of VAriance, ANOVA). Пожалуй, это самый распространенный статистический метод в экспериментальной психологии и многих других дисциплинах. Он очень хорошо подходит под использование для экспериментальных дизайнов, т.е. для исследовательских планов, в которых мы напрямую управляем уровнями независимой переменной. Связь ANOVA и экспериментирования настолько тесная, что некоторые термины пересекатся, но всегда нужно быть осторожными. Как и в случае с линейной регрессией, если мы переменную называем “предиктором”, это не дает ей никакой дополнительной каузальной силы. Так же и с ANOVA: мы можем называть какие-то переменные “независимыми”, а какие-то “зависимыми”, но это не означает автоматически каузальной связи. Просто терминология экспериментирования и ANOVA слишком тесно переплетены исторически. У дисперсионного анализа есть много разновидностей, которые мы сегодня и будем разбирать, начиная с обычного межгруппового дисперсионного анализа (One-Way ANOVA), заканчивая сложными вариантами этого метода, такими как ANCOVA, факторная ANOVA и ANOVA с повторными измерениями. Здесь будут часто употребляться как термин ANOVA, так и дисперсионный анализ. Это одно и то же. В русскоязычных статьях обычно пишут “дисперсионный анализ”, но в быту все говорят “анова”. Так проще. Зачем нам вообще нужен ANOVA? Ранее мы разбирали как сравнивать средние для двух групп с помощью т-теста. Но что если у нас больше двух групп? В принципе, можно использовать много попарных т-тестов и использовать поправки на множественные сравнения (и мы это сегодня будем делать, но попозже). Но обычно делается сравнение сразу всех групп с помощью дисперсионного анализа. Не дайте названию ввести Вас в заблуждение! Дисперсионный анализ - это все то же сравнение средних, только сразу для нескольких групп. Давайте в этот раз сразу начнем с проведением теста. Мы будем использовать данные с курса по статистике Университета Шеффилда про эффективность диет. library(&quot;data.table&quot;) diet &lt;- fread(&quot;stcp-Rdataset-Diet.csv&quot;) Да, в этот раз не так весело, просто диеты и их влияние на вес. Увы, даже информации про диеты нет: просто сухие цифры 1, 2 и 3… Зато этот датасет достаточно удобен, понятен и достаточно репрезентативен относительно того, какие данные могут получиться в результате эксперимента. Итак, начнем с того, что немного причешем наш датасет. В данном датасете есть несколько пропущенных значений: sum(!complete.cases(diet)) ## [1] 2 Давайте просто удалим их: diet &lt;- na.omit(diet) Мы посчитаем переменную weight.loss - разница до и после. А также сделаем факторной переменную Dietf из численной Diet, иначе 1, 2 и 3 будут читаться как численная переменная. То же самое сделаем для переменной, в которой записан id испытуемого. Осторожнее, с этим очень легко накосячить: если не перевести нужные численные переменные в факторы, то потом можно получить неверные результаты. А это гораздо хуже, чем просто получить ошибку! diet[, weight.loss := weight6weeks - pre.weight] diet[, Dietf := factor(Diet, labels = LETTERS[1:3])] diet[, Person := factor(Person)] Хотите понять, что за магия с LETTERS[1:3]? Все просто, это зашитая в R константа, примерно как число pi, только содержит все буквы латинского алфавита в виде character вектора. LETTERS выводит ЗАГЛАВНЫЕ буквы, а letters - строчные. Иногда это очень удобно. 7.1 Введение в ANOVA Давайте сразу возьмем быка за рога и попробуем провести тест: summary(aov(weight.loss ~ Dietf, diet)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Dietf 2 60.5 30.264 5.383 0.0066 ** ## Residuals 73 410.4 5.622 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Хотя результат выглядит незнакомым, но этот синтаксис где-то мы это уже видели… Да ведь здесь все точно как в линейной регрессии! И действительно, если откроете хэлп по функции aov(), то увидите, что эта функция просто использует функцию lm(). Более того, можете даже попробовать вот так: summary(lm(weight.loss ~ Dietf, diet)) ## ## Call: ## lm(formula = weight.loss ~ Dietf, data = diet) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.7000 -1.6519 -0.1759 1.4420 5.3680 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -3.3000 0.4840 -6.818 2.26e-09 *** ## DietfB 0.0320 0.6776 0.047 0.96246 ## DietfC -1.8481 0.6652 -2.778 0.00694 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.371 on 73 degrees of freedom ## Multiple R-squared: 0.1285, Adjusted R-squared: 0.1047 ## F-statistic: 5.383 on 2 and 73 DF, p-value: 0.006596 Теперь мы получили привычный нам (по предыдущим занятиям) результат, даже значения p-value совпадают. Правда, больше почти ничего общего. Если присмотритесь, то обнаружите, что еще совпадает \\(F\\)-value/statistic и степени свободы. Что это за \\(F\\) и как его получают, мы и будем сегодня разбираться. 7.2 Тестирование значимости нулевой гипотезы в ANOVA. И снова мы повторим логику тестирования значимости нулевой гипотезы. Да-да, опять. Здесь все примерно так же, как и с предыдущими тестами. Формулирование нулевой и альтернативной гипотезы. Наша нулевая гипотеза говорит о том, что между группами нет различий: \\[H_0:\\mu_1 = \\mu_2 = ... = \\mu_n\\] Напоминаю, что греческие буквы означают, что речь идет не о статистиках выборки, а о параметрах генеральной совокупности: нам интересно знать, действительно ли диеты по разному влияют на людей вообще, а не на данной конкретной выборке. Иначе нам достаточно было бы просто посчитать средние и идти пить чай. А вот какая будет альтернативная гипотеза? Хочется сказать, что “все средние различаются друг от друга”, но это не так. На самом деле, альтернативная гипотеза звучит так, что есть хотя бы одна пара групп, где средние не равны. \\[H_1: \\text{Не все средние равны}\\] Подсчет статистики. Мы уже использовали разные статистики (\\(z\\), \\(t\\) и т.п.) для тестирования гипотез. Теперь к ним добавится новая - \\(F\\). Вот ее мы и посчитаем с помощью таблицы ANOVA. Таблица ANOVA Степени свободы Суммы квадратов Средние квадраты F-статистика Межгрупповые \\(df_{b}\\) \\(SS_{b}\\) \\(MS_{b} =\\frac{SS_{b}}{df_{b}}\\) \\(F=\\frac{MS_{b}}{MS_{w}}\\) Внутригрупповые \\(df_{w}\\) \\(SS_{w}\\) \\(MS_{w} =\\frac{SS_{w}}{df_{w}}\\) Общие \\(df_{t}\\) \\(SS_{t}= SS_{b} + SS_{w}\\) Именно эту таблицу мы видели в аутпуте функции aov(): summary(aov(weight.loss ~ Dietf, diet)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Dietf 2 60.5 30.264 5.383 0.0066 ** ## Residuals 73 410.4 5.622 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Здесь вместо between groups (между группами) - Dietf, а вместо within groups (внутри групп) - Residuals. И действительно, внутригрупповые суммы квадратов - это “остатки” (residuals), которые мы не смогли объяснить разницами между диетами. Теперь пришло время разобраться с каждой клеточкой этой таблицы, а заодно и погрузиться в суть дисперсионного анализа. Давайте осторожно и без лишних криков взглянем на формулы: Таблица ANOVA Степени свободы Суммы квадратов Средние квадраты F-статистика Между \\(df_{b}=J-1\\) \\(SS_{b}= \\sum\\limits_{j=1}^J \\sum\\limits_{i=1}^{n_j} (\\overline{x_j}-\\overline{x})^2\\) \\(MS_{b} =\\frac{SS_{b}}{df_{b}}\\) \\(F=\\frac{MS_{b}}{MS_{w}}\\) Внутри \\(df_{w}=N-J\\) \\(SS_{w}= \\sum\\limits_{j=1}^J \\sum\\limits_{i=1}^{n_j} (x_{ij}-\\overline{x_j})^2\\) \\(MS_{w} =\\frac{SS_{w}}{df_{w}}\\) Общие \\(df_{t}=N-1\\) \\(SS_{t}= \\sum\\limits_{j=1}^J \\sum\\limits_{i=1}^{n_j} (x_{ij}-\\overline{x})^2\\) \\(J\\) означает количество групп, \\(N\\) - общее количество наблюдений во всех группах, \\(n_j\\) означает количество наблюдений в группе j, а \\(x_{ij}\\) - наблюдение под номером \\(i\\) в группе \\(j\\). Да, тут много формул, верно. Но суть довольно проста. Есть вариабельность зависимой переменной: как потеря веса распределена между испытуемыми. Она складывается из вариабельности внутри групп и между группами: \\(SS_t = SS_b +SS_w\\). Вариабельность обозначается \\(SS\\) и означает “сумму квадратов” (sum of squares) - это то же, что и дисперсия, только мы не делим вме в конце на количество наблюдений (или количество наблюдений минус один): \\[SS = \\sum\\limits_{i=1}^{n_j} (x_{i}-\\overline{x})^2\\] Мы здесь считаем три суммы квадратов: общие, внутригрупповые и межгрупповые. При этом \\(SS_t = SS_b +SS_w\\), то есть общие суммы квадратов “раскладываются” на межгрупповые и внутригрупповые (см. рисунок ). Рисунок 7.1: Суммы квадратов в ANOVA Если попробуем это представить зрительно, то эти три суммы квадратов будут выглядеть примерно как на рисунке ## ## Attaching package: &#39;cowplot&#39; ## The following object is masked from &#39;package:ggplot2&#39;: ## ## ggsave Рисунок 7.2: Общая вариабельность, межгрупповая вариабельность и внутригрупповая вариабельность в ANOVA. На картинке это сложно отразить, поэтому поясняю словами, что, собственно, “квадраты” означают не сами расстояния, нарисованные палочками, а их квадраты. Можете мысленно представить, что каждая такая вертикальная палочка - это сторона квадрата. Площади этих квадратов мы суммируем. sumofsquares &lt;- function(x) sum((x - mean(x))^2) totalss &lt;- sumofsquares(diet$weight.loss) diet[,lossbydiet := mean(weight.loss), by = Dietf] withinss &lt;- diet[, sum((weight.loss - lossbydiet)^2)] betweenss &lt;- diet[, sum((lossbydiet - mean(weight.loss))^2)] Обновим нашу табличку, поставив полученные суммы квадратов вмета формул: Таблица ANOVA Степени свободы Суммы квадратов Средние квадраты F-статистика Между \\(df_{b}=J-1\\) \\(SS_{b}=\\) 60.53 \\(MS_{b} =\\frac{SS_{b}}{df_{b}}\\) \\(F=\\frac{MS_{b}}{MS_{w}}\\) Внутри \\(df_{w}=N-J\\) \\(SS_{w}=\\) 410.4 \\(MS_{w} =\\frac{SS_{w}}{df_{w}}\\) Общие \\(df_{t}=N-1\\) \\(SS_{t}=\\) 470.93 Кстати, что будет, если поделить межгрупповую сумму квадратов на общую сумму квадратов? betweenss/totalss ## [1] 0.1285269 Получится \\(R^2\\). Помните, мы использовали \\(R^2\\)(коэффициент детерминации) в линейной регрессии для оценки модели? Логично: это соотношение объясненной дисперсии к общей, не может быть меньше нуля и больше единицы. Перед суммами квадратов стоят степени свободы. В отличие от т-теста, когда у нас был один показатель степени свободы, у нас здесь два показателя. Один из них связан с размером групп, другой - с размером выборки: totaldf &lt;- diet[,.N] - 1 betweendf &lt;- diet[,nlevels(Dietf)] - 1 withindf &lt;- diet[,.N] - diet[,nlevels(Dietf)] Хитрая функция nlevels() просто позволяет посчитать количество уровней фактора. Добавим в табличку степени свободы: Таблица ANOVA Степени свободы Суммы квадратов Средние квадраты F-статистика Между \\(df_{b}=\\) 2 \\(SS_{b}=\\) 60.53 \\(MS_{b} =\\frac{SS_{b}}{df_{b}}\\) \\(F=\\frac{MS_{b}}{MS_{w}}\\) Внутри \\(df_{w}=\\) 73 \\(SS_{w}=\\) 410.4 \\(MS_{w} =\\frac{SS_{w}}{df_{w}}\\) Общие \\(df_{t}=\\) 75 \\(SS_{t}=\\) 470.93 Теперь нужно посчитать средние квадраты (mean squares): нужно разделить суммы квадратов на соответствующие степени свободы. withinms &lt;- withinss/withindf betweenms &lt;- betweenss/betweendf Почти готово. Используемая нами в ANOVA статистика F - это отношение межгрупповых средних квадратов к внутригрупповым средним квадратам: f &lt;- betweenms/withinms f ## [1] 5.383104 Все, готово: Таблица ANOVA Степени свободы Суммы квадратов Средние квадраты F-статистика Между \\(df_{b}=\\) 2 \\(SS_{b}=\\) 60.53 \\(MS_{b} =\\) 30.26 \\(F=\\) 5.38 Внутри \\(df_{w}=\\) 73 \\(SS_{w}=\\) 410.4 \\(MS_{w} =\\) 5.62 Общие \\(df_{t}=\\) 75 \\(SS_{t}=\\) 470.93 Подсчет p-value. Помните, как это происходило в т-тесте? Мы смотрели, как статистика распределена при верности нулевой гипотезы (то есть при отсутствии различий в генеральной совокупности). Потом мы считали вероятность получения нашей статистики (или более экстремальной) как площадь под кривой от нашего \\(t\\) и до бесконечности. Мы еще умножали эту вероятность на 2, чтобы наш тест был двусторонним, но этого нам делать не нужно в случае ANOVA и \\(F\\)-статистики. Почему? Давайте взглянем на распределение \\(F\\). Его форма сильно зависит от двух степеней свобод. Давайте нарисуем это распределение. Для этого нам понадобится функция df (из семейства функций для F-распределения: df(), pf(), qf(), rf()). См. рисунок . v &lt;- seq(0.1,10, 0.01) fdist &lt;- data.frame(fvalues = v, pdf = df(v, betweendf, withindf)) library(ggplot2) label &lt;- paste0(&quot;F(&quot;, betweendf, &quot;, &quot;, withindf, &quot;) = &quot;, round(f, 3)) ggplot(fdist, aes(x = fvalues, y = pdf))+ geom_line()+ geom_vline(xintercept = f)+ annotate(&quot;text&quot;, x = f+1, y = 0.2, label = label)+ scale_y_continuous(expand=c(0,0)) + theme_minimal()+ theme(axis.line.y = element_blank(), axis.ticks.y = element_blank(), axis.text.y = element_blank(), axis.title.y = element_blank()) Рисунок 7.3: F-распределение при верности нулевой гипотезы (см. детали в тексте) Оно вообще ни разу не симметричное! Поэтому нам нужно считать только площадь от нашего \\(F\\) до плюс бесконечности. Здесь это не очень много. Чем больше \\(F\\), тем больше соотношение межгрупповой вариабельности (интересующие нас различия плюс “шум”) к внутригрупповой (необъясненный “шум” измерения). На самом деле, \\(F\\)-распределение отнюдь не всегда выглядит так. С другими степенями свободами (т.е. с другим количеством групп и наблюдений) его форма будет совсем другая (см. рисунок ) . Но \\(F\\)-статистика никогда не может быть меньше нуля. Просто потому, что средние квадраты - это всегда какие-то положительные значения. Рисунок 7.4: F-распределения с разными степенями свободы. Картинка взята из Википедии Итак, чтобы подсчитать p-value нам нужно просто воспользоваться функцией pf() подставив в качестве аргументов нашу \\(F\\)-статистику и нужные степени свободы (два значения). Это будет площадь под кривой плотности вероятности от нуля до \\(F\\). Поскольку нас интересует площадь от \\(F\\) до плюс бесконечности, то результат pf() нужно вычесть из единицы: 1 - pf(f, betweendf, withindf) ## [1] 0.006595853 Отлично, последний этап - сравнение p-value с нашим уровнем \\(\\alpha\\), который по дефолту 0.05. Ну и действительно, p-value меньше 0.05, поэтому мы можем отвергнуть нулевую гипотезу, что средние всех групп в генеральной совокупности одинаковые. Но можем ли мы сделать вывод, какие именно группы различаются? По одному ANOVA, увы, нет. Для этого нам нужно провести post-hoc тесты. 7.3 Post-hoc тесты Post-hoc с латинского переводится как “после этого”. Post-hoc тесты проводятся в случае, если Вы уже отвергли нулевую гипотезу ANOVA, но хотите узнать, какие именно группы различаются между собой. И здесь мы снова встречаемся с проблемой множественных сравнений (как и в случае с корреляцией всего со всем). Условно говоря, здесь есть два основных подхода для проведения post-hoc тестов: Применение различных поправок к результатам т-тестов - это мы уже проходили. Поправка Бонферрони, поправка Холма и т.п. Процедура ничем не отличается от того, что мы делали с корреляциями, только теперь у нас т-тесты вместо корреляций. Есть удобная функция pairwise.t.test() для этого: pairwise.t.test(diet$weight.loss, diet$Dietf) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: diet$weight.loss and diet$Dietf ## ## A B ## B 0.962 - ## C 0.017 0.017 ## ## P value adjustment method: holm Мы видим, что при использовании поправки Холма есть различия между результатами диет А и С, В и С, но различия между А и В нет значимых различий. Другой подход - специальные post-hoc тесты для сравнения нескольких групп. Как и в случае с поправками, есть более и менее консервативные варианты, есть довольно специфические, например, тест Даннетта (Dunnett’s test): он позволяет сравнить несколько средних с одним контролем (например, плацебо). Ну а самый распространенный post-hoc тест - это тест Тьюки (Tukey Honest Significant Differences = Tukey HSD). Для этого в R есть простая функция TukeyHSD(), которая применяется к аутпуту функции aov() - объекту класса aov(): modelanova &lt;- aov(weight.loss ~ Dietf, diet) TukeyHSD(modelanova) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = weight.loss ~ Dietf, data = diet) ## ## $Dietf ## diff lwr upr p adj ## B-A 0.032000 -1.589085 1.6530850 0.9987711 ## C-A -1.848148 -3.439554 -0.2567422 0.0188047 ## C-B -1.880148 -3.454614 -0.3056826 0.0152020 Здесь мы видим результаты сравнения каждой группы с каждой, доверительный интервал и уровень значимости (\\(p_{adj}\\) - скорректированный p-value). Результат здесь получился примерно такой же, как и в случае с использованием поправки Холма: результаты использования диет C и А, С и В статистически значимо различаются (при \\(\\alpha\\) равной 0.05), а между А и В не обнаружено статистически значимых различий. 7.4 Другие способы проведения ANOVA в R. Встроенная функция aov() довольно удобная для проведения простой ANOVA. modelanova &lt;- aov(weight.loss ~ Dietf, diet) summary(modelanova) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Dietf 2 60.5 30.264 5.383 0.0066 ** ## Residuals 73 410.4 5.622 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Более того, мы уже обнаружили, что можно применить функцию lm() - это даст такие же результаты. Это может показаться странным, ведь мы раньше использовали в линейной регрессии только численные предикторы. Мы уже пробовали когда-то использовать дихотомические предикторы (когда у нас два уровня, которые могут быть представлены как 0 и 1), чтобы убедиться, что получаем такие же результаты, как и для т-теста. Но что если у нас три группы? Тогда функция lm() автоматически создает новые переменные с помощью так называемого dummy coding. 7.4.1 Dummy coding Dummy coding - это способ превратить номинальную (качественную) переменную в набор количественных. Для этого мы можем просто создать новые переменные типа “является ли эта диета диетой Х”, где Х - тип диеты. Давайте сделаем это. diet[,isA:= as.numeric(Dietf == &quot;A&quot;)] diet[,isB:= as.numeric(Dietf == &quot;B&quot;)] diet[,isC:= as.numeric(Dietf == &quot;C&quot;)] diet[c(1:2,15:16,35:36),c(&quot;Dietf&quot;, &quot;isA&quot;, &quot;isB&quot;, &quot;isC&quot;)] ## Dietf isA isB isC ## 1: A 1 0 0 ## 2: A 1 0 0 ## 3: B 0 1 0 ## 4: B 0 1 0 ## 5: C 0 0 1 ## 6: C 0 0 1 Заметьте, что один (любой) столбик здесь лишний. Если выбранная диета не является диетой В и не является диетой С, то, очевидно, это диета А (если у нас нет других диет - хорошо, что в жизни это не так). Поэтому для dummy coding мы можем удалить одну из колонок: diet[, isA := NULL] А теперь используем новые колонки в качестве предикторов для линейной регрессии: summary(lm(weight.loss ~ isB + isC, diet)) ## ## Call: ## lm(formula = weight.loss ~ isB + isC, data = diet) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.7000 -1.6519 -0.1759 1.4420 5.3680 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -3.3000 0.4840 -6.818 2.26e-09 *** ## isB 0.0320 0.6776 0.047 0.96246 ## isC -1.8481 0.6652 -2.778 0.00694 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.371 on 73 degrees of freedom ## Multiple R-squared: 0.1285, Adjusted R-squared: 0.1047 ## F-statistic: 5.383 on 2 and 73 DF, p-value: 0.006596 Для сравнения, сделаем линейную регрессию с категориальным предиктором без dummy coding: anova_as_lm &lt;- lm(weight.loss ~ Dietf, diet) summary(anova_as_lm) ## ## Call: ## lm(formula = weight.loss ~ Dietf, data = diet) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.7000 -1.6519 -0.1759 1.4420 5.3680 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -3.3000 0.4840 -6.818 2.26e-09 *** ## DietfB 0.0320 0.6776 0.047 0.96246 ## DietfC -1.8481 0.6652 -2.778 0.00694 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.371 on 73 degrees of freedom ## Multiple R-squared: 0.1285, Adjusted R-squared: 0.1047 ## F-statistic: 5.383 on 2 and 73 DF, p-value: 0.006596 Абсолютно то же самое! Более того, есть специальная функция anova(), которая возвращает таблицу ANOVA из объекта lm: anova(anova_as_lm) ## Analysis of Variance Table ## ## Response: weight.loss ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Dietf 2 60.53 30.2635 5.3831 0.006596 ** ## Residuals 73 410.40 5.6219 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 7.4.2 ANOVA как частный случай линейной регрессии Таким образом, ANOVA - это, в некотором смысле, просто частный случай линейной регрессии, когда предиктор представлен в номинальной шкале. В принципе, что ANOVA (со всеми ее разновидностями), что множественная линейная регрессия, что т-тест являются частными случаями общей линейной модели (general linear model). Не путать с обобщенной линейной моделью (generalized linear model)! Это еще более широкое обобщение, которое включает в себя как линейную, так и, например, логистическую регрессию. Да, с названием “обобщенная линейная модель” авторы несколько облажались, мне кажется. Если ANOVA - это линейная регрессия, то и требования к данным в ANOVA все те же, что и для линейной регрессии, правда, называются они немного по-другому. С нормальностью ошибок все так же - нужно, чтобы остатки (residuals) были распределены более-менее нормально (см. рисунок ). hist(residuals(modelanova)) Рисунок 7.5: Гистограмма распределения остатков Впрочем, довольно серьезные отклонения от нормальности для ANOVA не такая уж и проблема (если нет серьезных выбросов, а их мы бы заметили на гистограмме). Второе важное допущение - это гомогенность дисперсий, т.е. равенство дисперсий, т.е. то, что в случае линейной регрессии называют гомоскедастичностью. Если Вы подумали, что это слово придумали только чтобы запутать, то… возможно, Вы и правы. Гомогенность дисперий просто означает, что распределение ошибок не различается в зависимости от группы. diet$residuals &lt;- residuals(modelanova) ggplot(diet, aes(x = Dietf, y = residuals))+ geom_point() Рисунок 7.6: Вариабельность остатков в зависимости от группы Все вполне пристойно: нет какой-то одной группы, у которой разброс ошибок сильно больше (или меньше), чем у других (см. рисунок ). Впрочем, есть и более формальный способ оценить равенство дисперсий: с помощью теста Ливиня (Levene’s test). Для того, чтобы его провести мы воспользуемся новым пакетом ez (читается как “easy”). Он значительно упрощает проведение ANOVA, особенно при более сложных дизайнах, чем тот, который мы использовали, а заодно и проводит нужные дополнительные тесты. library(&quot;ez&quot;) #сначала install.packages(&quot;ez&quot;) если у Вас нет этого пакета ezANOVA(data = diet, dv = weight.loss, wid = Person, between = Dietf, detailed = T) ## Warning: Data is unbalanced (unequal N per group). Make sure you specified ## a well-considered value for the type argument to ezANOVA(). ## Coefficient covariances computed by hccm() ## $ANOVA ## Effect DFn DFd SSn SSd F p p&lt;.05 ges ## 1 Dietf 2 73 60.52701 410.4018 5.383104 0.006595853 * 0.1285269 ## ## $`Levene&#39;s Test for Homogeneity of Variance` ## DFn DFd SSn SSd F p p&lt;.05 ## 1 2 73 2.040419 160.8859 0.4629076 0.6312856 Другой способ провести тест Ливиня - функция leveneTest из пакета car: car::leveneTest(diet$weight.loss, diet$Dietf) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 2 0.4629 0.6313 ## 73 Пользоваться функцией ezANOVA() очень просто: нужно прописать данные в data, название зависимой переменной в dv, прописать переменную с id в wid (например, переменная с номером испытуемого, если такой нет, то нужно ее создать), а в between - групповую переменную. Почему between? Потому что это “обычный” ANOVA (он же One-way ANOVA) предполагает, что все измерения независимы друг от друга, т.е. что-то вроде расширения независимого т-теста. В результате мы получаем суммы квадратов, степени свободы, значение \\(F\\) и p-value. Кроме того, в аутпуте еще и любезно проставлена звездочка, если p-value меньше 0.05. На случай, если кто-то, продравшись через восемь семинаров по R и статистике, не может самостоятельно сравнить два числа друг с другом, да. Ладно, эти звездочки довольно удобны, что я тут придираюсь. Справа в первой строчке стоит что-то новое - это Generalized eta squared, размер эффекта для факторов ANOVA. Вообще, оценок размера эффекта для ANOVA много разных, и в них легко запутаться. Какой из них лучше - сложный вопрос, который выходит за рамки этого курса. Какого-то устоявшегося решения нет, к сожалению. Поэтому важно не просто отмечать размер эффекта, а какой именно из них используется. Что у них общего, так это то, что все они могут принимать значение от 0 до 1, причем чем больше значение размера эффекта, тем больше объясненная фактором дисперсия по отношению к необъясненной. Самые сложности начинаются, когда у нас много факторов в дисперсионном анализе. В однофакторной ANOVA разногласий поменьше (хотя они все равно есть), более того, в данном конкретном случае Generalized eta squared равен межгрупповой сумме квадратов, поделенной на общую сумму квадратов, то есть равен \\(R^2\\), который мы уже считали раньше: betweenss/totalss ## [1] 0.1285269 Это формула для обычной (нескорректированной) eta squared: \\[\\eta^2 = \\frac{SS_b}{SS_t}\\] 7.4.3 Обратно в aov! Последний важный момент в функции ezANOVA(), это возможность создать объект aov с помощью параметра return_aov = T, как будто бы мы пользовались функцией aov(). Это может пригодиться, например, для тех же post-hoc тестов: anova_by_ez &lt;- ezANOVA(data = diet, dv = weight.loss, wid = Person, between = Dietf, detailed = T, return_aov = T) ## Warning: Data is unbalanced (unequal N per group). Make sure you specified ## a well-considered value for the type argument to ezANOVA(). ## Coefficient covariances computed by hccm() summary(anova_by_ez$aov) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Dietf 2 60.5 30.264 5.383 0.0066 ** ## Residuals 73 410.4 5.622 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Вуаля! 7.5 Factorial ANOVA (Многофакторный ANOVA) Раньше мы говорили об One-Way ANOVA, что означает “однофакторную” ANOVA. Тем не менее, в отличие от т-тестов, мы можем исследовать влияние сразу нескольких категориальных переменных на зависимую переменную. В принципе, кардинальных различий нет, просто теперь у нас тестируются сразу несколько факторов. В статьях обычно обозначается количество факторов и уровней в них примерно так: “3x2x2 ANOVA”. В данном конкретном случае это означает, что была проведена трехфакторная ANOVA, причем в первом факторе было три уровня, а во втором и третьем - по два. Мы же сделаем 3x2 ANOVA с факторами “Диета” и “Пол”, с тремя диетами и двумя полами. Здесь у нас есть две гипотезы: что диета влияет на потерю веса и что пол, в целом, влияет на потерю веса. Последнее довольно странно, да. Но в факториальном дисперсионном анализе появляются гипотезы взаимодействия - “пересечения” факторов. В данном случае, это будет интерпретироваться как “разные диеты эффективны по-разному для разных полов”. Давайте нарисуем это для наглядности (см. рисунок ). Отображать на графике влияние больше чем одной переменной не так просто. Самый простой способ (особенно для ситуации двух категориальных независимых переменных с не очень большим количеством уровней) - нарисовать несколько линий. Небольший хинт: тот фактор, у которого больше уровней, лучше расположить по оси Х, а тот, у которого меньше уровней, как независимые линии. diet[, genderf:=factor(gender, labels = c(&quot;ж&quot;, &quot;м&quot;))] sem &lt;- function(x) sd(x)/sqrt(length(x)) pivot &lt;- diet[,.(meanloss = mean(weight.loss), se = sem(weight.loss)), by = .(Dietf, genderf)] library(ggplot2) pd = position_dodge(0.05) ggplot(pivot, aes(x = Dietf, y = meanloss, colour = genderf))+ geom_line(aes(group = genderf), position = pd)+ geom_pointrange(aes(ymin = meanloss - se, ymax = meanloss +se), position = pd) Рисунок 7.7: Пример взаимодействия двух переменных. Хотя в среднем диета С эффективнее остальных, она особенно эффективна для женщин. По крайней мере, так говорит картинка. Но хотелось бы узнать, насколько резонно переносить такие выводы на генеральную совокупность. Итак, у нас будет три гипотезы: о влиянии диеты, пола и их взаимодействия. Как это сделать в R? Давайте сделаем это с помощью функции aov() для начала: summary(aov(weight.loss ~ Dietf + genderf + Dietf:genderf, diet)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Dietf 2 60.5 30.264 5.629 0.00541 ** ## genderf 1 0.2 0.169 0.031 0.85991 ## Dietf:genderf 2 33.9 16.952 3.153 0.04884 * ## Residuals 70 376.3 5.376 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Пересечение факторов мы обозначили знаком :. Но можно и проще: summary(aov(weight.loss ~ Dietf * genderf, diet)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Dietf 2 60.5 30.264 5.629 0.00541 ** ## genderf 1 0.2 0.169 0.031 0.85991 ## Dietf:genderf 2 33.9 16.952 3.153 0.04884 * ## Residuals 70 376.3 5.376 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Вместо + мы использовали *, что авторматически создает нужные взаимодействия. Теперь же сделаем с помощью ezANOVA(). Чтобы задать несколько колонок, нам нужно использовать .(): ezANOVA(data = diet, dv = weight.loss, wid = Person, between = .(Dietf, genderf)) ## Warning: Data is unbalanced (unequal N per group). Make sure you specified ## a well-considered value for the type argument to ezANOVA(). ## Coefficient covariances computed by hccm() ## $ANOVA ## Effect DFn DFd F p p&lt;.05 ges ## 1 Dietf 2 70 5.61902602 0.00545568 * 0.138334829 ## 2 genderf 1 70 0.03137868 0.85990976 0.000448066 ## 3 Dietf:genderf 2 70 3.15320438 0.04884228 * 0.082645860 ## ## $`Levene&#39;s Test for Homogeneity of Variance` ## DFn DFd SSn SSd F p p&lt;.05 ## 1 5 70 5.092595 184.3742 0.3866936 0.8563347 Итак, взаимодействие оказалось статистически значимым, что поддерживает нашу гипотезу о том, что диеты по-разному эффективны для разных полов. 7.5.1 SS Type I, II, III Результаты немного отличаются, Вы заметили? Дело в том, что в ситуации несбалансированного ANOVA, т.е. когда в разных подгруппах разное количество наблюдений, возникает некоторая неопределенность на тему того, как считать сумму квадратов. У нас как раз несбалансированный дизайн (немного, но лучше избегать этого): diet[,.N, by = .(Dietf, genderf)] ## Dietf genderf N ## 1: A ж 14 ## 2: B ж 14 ## 3: C ж 15 ## 4: A м 10 ## 5: B м 11 ## 6: C м 12 Всего есть три типа, они так и называются SS (сумма квадратов) Type I, Type II, Type III. Разница, как видите, не очень большая, но если Вам стало интересно, то советую почитать здесь или здесь. Если коротко, то разница в том, считать ли сумму квадратов для фактора после “вычета” предыдущих эффектов (последовательно, SS Type I), после вычета всех остальных факторов (иерархически, SS Type II) или же после вычета всех остальных факторов и взаимодействий (SS Type III). Рисунок 7.8: SS Types I, II и III Функция aov() использует Type I SS (можете это проверить, поменяв порядок предикторов, - результат будет разный!), а в ezANOVA() используется по дефолту SS Type II, но это можно поменять с помощью параметра type = поставив 1, 2 или 3, соответственно. Если попробуете поставить type = 1, то увидите предупреждение, что этого делать не стоит, и авторы пакета надеются, что это делается исключительно в демонстрационных целях. Действительно, SS Type I рекомендуется избегать, а вот дискуссия между SS Type II и III - тот еще холивар. Ну, ладно, это холивар только для гиков, да и те понимают, что это слишком уж гикство для холиваров. Ок, так что же выбрать? В принципе, SS Type II рекомендуют больше. Или, на крайняк, SS Type III. Что бы Вы не выбрали (II или III), на Вашей стороне будет банда статистиков, которые будут топить за Вашу позицию. SPSS и SAS по умолчанию используют SS Type III. 7.6 ANCOVA (ANalysis of COVAriance; Ковариационный анализ) По названию выглядит как какой-то еще дофига сложный метод, да? Нет, все примерно как и раньше, только теперь появляется ковариата. Это дополнительная числовая переменная, которая (в идеале) объясняет значительную часть дисперсии зависимой переменной. Таким образом, если “вычесть” влияние этой переменной, то можно уменьшить внутригрупповую изменчивость, т.е. получить более выраженный эффект и повысить статистическую мощность. Давайте проведем ANCOVA с ковариатой “Height” (рост): ezANOVA(data = diet, dv = weight.loss, wid = Person, between = Dietf, between_covariates = Height, detailed = T) ## Warning: Data is unbalanced (unequal N per group). Make sure you specified ## a well-considered value for the type argument to ezANOVA(). ## Warning: Implementation of ANCOVA in this version of ez is experimental ## and not yet fully validated. Also, note that ANCOVA is intended purely as ## a tool to increase statistical power; ANCOVA can not eliminate confounds ## in the data. Specifically, covariates should: (1) be uncorrelated with ## other predictors and (2) should have effects on the DV that are independent ## of other predictors. Failure to meet these conditions may dramatically ## increase the rate of false-positives. ## Warning: Covariate&quot;Height&quot; is numeric and will therefore be fit to a linear ## effect. ## Coefficient covariances computed by hccm() ## $ANOVA ## Effect DFn DFd SSn SSd F p p&lt;.05 ges ## 1 Dietf 2 73 52.12043 412.7606 4.608956 0.01303194 * 0.1121156 ## ## $`Levene&#39;s Test for Homogeneity of Variance` ## DFn DFd SSn SSd F p p&lt;.05 ## 1 2 73 1.698883 168.4969 0.3680142 0.693384 В принципе, ANCOVA - это та же линейная регрессия (общая линейная модель), только в ней присутствуют как численные, так и номинальные переменные. 7.7 Repeated measures ANOVA (Дисперсионный анализ с повторными измерениями) Как и в случае с т-тестом, если мы хотим сравнить связанные выборки, то мы должны пользоваться несколько другими формулами. Очень часто “зависимые выборки” - это ситуация с внутригрупповым (within-group) дизайном эксперимента: каждый испытуемый получает все уровни независимой переменной на свою голову или любые другие части своего многострадального тела, а результат этого воздействия записывают. Другой частый вариант - это “до” и “после”. Ранее мы сравнивали изменения (gain score) до и после той или иной диеты. Тем не менее, обычно встречается использование значений до и после как отдельного фактора в так называемом within-subjects ANOVA или repeated measures ANOVA (RM-ANOVA; дисперсионный анализ с повторными измерениями). Если обычный дисперсионный анализ можно рассматривать как “расширение” независимого т-теста, то дисперсионный анализ с повторными измерениями - это своеобразное расширение зависимого т-теста. Только мы опять используем F-статистику Давайте проверим, является ли диета С эффективной, сравнив значения до или после. Для этого нам понадобится melt() для превращения широкого датафрейма в длинный: dietlong &lt;- melt(diet, measure = c(&quot;pre.weight&quot;, &quot;weight6weeks&quot;), variable = &quot;time&quot;, value = &quot;weight&quot;) ## Warning in melt.data.table(diet, measure = c(&quot;pre.weight&quot;, ## &quot;weight6weeks&quot;), : &#39;measure.vars&#39; [pre.weight, weight6weeks] are not all ## of the same type. By order of hierarchy, the molten data value column will ## be of type &#39;double&#39;. All measure variables not of type &#39;double&#39; will be ## coerced too. Check DETAILS in ?melt.data.table for more on coercion. Возьмем только диету С: dietlongC &lt;- droplevels(dietlong[Dietf == &quot;C&quot;,]) Функция droplevels() позволяет избавиться от лишних уровней переменных. Дело в том, что в нашем сабсете уже нет многих испытуемых, а вот запись в факторе Person о них сохранилось. Это может привести к ошибке в некоторых случаях. Теперь проведем RM-ANOVA: ezANOVA(dietlongC, dv = weight, wid = Person, within = time) ## $ANOVA ## Effect DFn DFd F p p&lt;.05 ges ## 2 time 1 26 124.6949 2.030459e-11 * 0.0986036 Пользуясь функцией aov(), нужно прописать переменную, которая группирует ответы одного испытуемого, с помощью Error(): summary(aov(weight ~ time +Error(as.factor(Person)), dietlongC)) ## ## Error: as.factor(Person) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Residuals 26 3196 122.9 ## ## Error: Within ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## time 1 357.8 357.8 124.7 2.03e-11 *** ## Residuals 26 74.6 2.9 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Принципиальное отличие от обычного ANOVA заключается в том, что внутригрупповые суммы квадратов могут быть разделены на две части: “ошибку” (сумму квадратов остатков) и межиндивидуальные различия. Последние мы можем вычесть, что даст нам большую мощность, чем если бы мы просто сравнивали результаты после (см. рисунок ). Рисунок 7.9: Суммы квадратов в дисперсионном анализе с повторными измерениями 7.7.1 Пример расчета RM-ANOVA вручную Чтобы было понятнее, что происходит внутри, давайте посчитаем эту самую RM-ANOVA самостоятельно. Для начала возьмем для удобства сабсет из нашего исходного датасета в широком формате: dd &lt;- diet[Dietf == &quot;C&quot;,c(&quot;pre.weight&quot;, &quot;weight6weeks&quot;)] head(dd) ## pre.weight weight6weeks ## 1: 60 53.0 ## 2: 62 56.4 ## 3: 64 60.6 ## 4: 65 58.2 ## 5: 66 58.2 ## 6: 67 61.6 Формулы здесь немного сложнее, за счет того, что внутригрупповые суммы квадратов мы разделяем на индиудуальные и на остатки. Таблица ANOVA Степени свободы Суммы квадратов Средние квадраты F-статистика Между \\(df_{b}=J-1\\) \\(SS_{b}= n \\sum\\limits_{j=1}^J (\\overline{x_j}-\\overline{x})^2\\) \\(MS_{b} =\\frac{SS_{b}}{df_{b}}\\) \\(F=\\frac{MS_{b}}{MS_{e}}\\) Внутри \\(df_{w}=N-J\\) \\(SS_{w}= SS_t - SS_b\\) Индиви-дуальные \\(df_s = n-1\\) \\(SS_s= J \\sum\\limits_{i=1}^{n} (\\overline{x_i} -\\overline{x})^2\\) Остатки \\(df_e=N-J-n+1\\) \\(SS_e= SS_w - SS_s\\) \\(MS_{e} =\\frac{SS_{e}}{df_{e}}\\) Общие \\(df_{t}=N-1\\) \\(SS_{t}= J \\sum\\limits_{i=1}^{n_j} (x_{ij}-\\overline{x})^2\\) Посчитаем суммы квадратов: globalmean &lt;- mean(unlist(dd)) totalss &lt;- sum((unlist(dd) - globalmean)^2) Просто сумма квадратов по отношению к среднему всех значений betweenss &lt;- sum((apply(dd,2,mean) - globalmean)^2) * nrow(dd) Выглядит сложно, но это просто суммы квадратов средних по столбцам по отношению к среднему всех значений. withinss &lt;- totalss - betweenss Внутригрупповая сумма квадратов - это общая сумма квадратов минус межгрупповая. А теперь нам нужно разделить внутригрупповуюю сумму квадратов на части: subjss &lt;- sum((apply(dd,1,mean) - globalmean)^2)*ncol(dd) Вот это и есть наши межиндивидуальные различия. Заметьте, они составляют большую часть разброса данных. Это вполне логично: даже если диета весьма эффективная, разброс по весу у людей обычно гораздо больше предполагаемого эффекта и его разброса в выборке. errorss &lt;- withinss - subjss Теперь посчитаем степени свободы: totaldf &lt;- length(unlist(dd)) - 1 betweendf &lt;- ncol(dd) - 1 subjdf &lt;- nrow(dd) -1 withindf &lt;- totaldf - betweendf errordf &lt;- withindf - subjdf Осталось посчитать средние межгрупповые квадраты и средние квадраты ошибки… betweenms &lt;- betweenss/betweendf errorms &lt;- errorss/errordf … и поделить одно на другое, чтобы получить F: f &lt;- betweenms/errorms Итоговая таблица: Таблица ANOVA Степени свободы Суммы квадратов Средние квадраты F-статистика Между \\(df_{b}=\\) 1 \\(SS_{b}=\\) 357.8 \\(MS_{b} =\\) 357.8 \\(F=\\) 124.69 Внутри \\(df_{w}=\\) 52 \\(SS_{w}=\\) 3270.84 Индиви-дуальные \\(df_s=\\) 26 \\(SS_s=\\) 3196.23 Остатки \\(df_e=\\) 26 \\(SS_e=\\) 74.6 \\(MS_{e} =\\) 2.87 Общие \\(df_{t}=\\) 53 \\(SS_{t}=\\) 3628.63 \\(F\\) получился большой! Давайте теперь посмотрим, насколько получить такой или больше F при условии верности нулевой гипотезы: 1 - pf(f, betweendf, errordf) ## [1] 2.030465e-11 В данном конкретном случае мы могли применить просто зависимый т-тест, ведь у нас всего две выборки (до и после): t.test(dd$pre.weight,dd$weight6weeks, paired = T, var.equal = T) ## ## Paired t-test ## ## data: dd$pre.weight and dd$weight6weeks ## t = 11.167, df = 26, p-value = 2.03e-11 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 4.200493 6.095803 ## sample estimates: ## mean of the differences ## 5.148148 Заметьте, то же самое p-value. Более того, в случае двух выборок \\(F\\) - это просто квадрат от \\(t\\): t &lt;- t.test(dd$pre.weight,dd$weight6weeks, paired = T, var.equal = T)$statistic t ## t ## 11.16669 t^2 ## t ## 124.6949 7.8 Смешанный внутригрупповой-межгрупповой дисперсионный анализ (Mixed between-within-subjects ANOVA) Нам никто не запрещает совмещать оба типа ANOVA в одном тесте. В ezANOVA() это делается просто с помощью прописывания разных факторов в нужных переменных: between и within. ezANOVA(data = dietlong, wid = Person, dv = weight, between = Dietf, within = time) ## Warning: Data is unbalanced (unequal N per group). Make sure you specified ## a well-considered value for the type argument to ezANOVA(). ## $ANOVA ## Effect DFn DFd F p p&lt;.05 ges ## 2 Dietf 2 73 0.8280758 4.409507e-01 0.021710057 ## 3 time 1 73 210.5004045 3.346036e-23 * 0.059209996 ## 4 Dietf:time 2 73 5.3831045 6.595853e-03 * 0.003208607 Здесь нас интересует взаимодействие диеты и времени. Мы получили тот же самый результат, что и при обычном ANOVA на разницу между до и после. Что неудивительно! А вот если мы проведем ANCOVA на вес после с ковариатой “вес до”, то результат будет несколько другим. Разница в том, что в таком случае мы не просто “вычитаем” значение веса до диеты, но используем его как предиктор - с оценкой его коэффициента: ezANOVA(data = diet, wid = Person, dv = weight6weeks, between_covariate = pre.weight, between = Dietf) ## Warning: Data is unbalanced (unequal N per group). Make sure you specified ## a well-considered value for the type argument to ezANOVA(). ## Warning: Implementation of ANCOVA in this version of ez is experimental ## and not yet fully validated. Also, note that ANCOVA is intended purely as ## a tool to increase statistical power; ANCOVA can not eliminate confounds ## in the data. Specifically, covariates should: (1) be uncorrelated with ## other predictors and (2) should have effects on the DV that are independent ## of other predictors. Failure to meet these conditions may dramatically ## increase the rate of false-positives. ## Warning: Covariate&quot;pre.weight&quot; is numeric and will therefore be fit to a ## linear effect. ## Coefficient covariances computed by hccm() ## $ANOVA ## Effect DFn DFd F p p&lt;.05 ges ## 1 Dietf 2 73 4.957468 0.009576091 * 0.1195796 ## ## $`Levene&#39;s Test for Homogeneity of Variance` ## DFn DFd SSn SSd F p p&lt;.05 ## 1 2 73 3.654284 160.5353 0.8308538 0.4397546 7.9 Непараметрические аналоги ANOVA Как было описано выше, ANOVA довольно устойчив к разным отклонениям от нормальности и некоторой гетероскедастичности (разным дисперсиям в выборках). Но если уж у Вас данные ну совсем-совсем ненормальные, несимметричные, а от преобразований шкалы Вы по каким-то причинам отказались, то стоит упомянуть о непараметрических аналогах ANOVA. 7.9.1 Тест Краскела-Уоллеса Это тест Краскела-Уоллеса - обобщение теста Манна-Уитни на несколько выборок (т.е. аналог межгруппового ANOVA): kruskal.test(weight.loss ~ Dietf, diet) ## ## Kruskal-Wallis rank sum test ## ## data: weight.loss by Dietf ## Kruskal-Wallis chi-squared = 9.4159, df = 2, p-value = 0.009023 7.9.2 Тест Фридмана Для зависимых выборок есть тест Фридмана - непараметрический аналог дисперсионного анализа с повторными измерениями: friedman.test(weight ~ time | Person, dietlongC) ## ## Friedman rank sum test ## ## data: weight and time and Person ## Friedman chi-squared = 27, df = 1, p-value = 2.035e-07 7.10 Заключение Мы разобрали много разных вариантов дисперсионного анализа. Зачем так много? ANOVA - один из самых распространенных методов как в психологии, так и во многих других областях. Естественно, это отнюдь не все методы, используемые в той же психологии. Более того, некоторые вопросы остались за бортом. Постараюсь коротко их перечислить: многомерный ANOVA (Multivariate ANalysis Of Variance; MANOVA) - расширение ANOVA для ситуации нескольких зависимых переменных. Честно говоря, я практически не встречал применение этого метода на практике. тестирование сферичности для дисперсионного анализа с повторноми измерениями с помощью теста сферичности Моучли (Mauchly’s sphericity test). Этот тест проверяет использует матрицу ковариаций разниц каждого условия с каждым: дисперсии разниц между условиями должны быть примерно одинаковыми. Если нулевая гипотеза о сферичности может быть отброшена (p-value &lt; \\(\\alpha\\)), то нужно проводить специальные поправки, обычно это поправки Гринхауса-Гейсера (Greenhouse-Geisser corrections). Мы этого не делали, потому что в ситуации RM-ANOVA с всего двумя условиями эта сферичность никогда не нарушается: у нас всего одна дисперсия разниц между условиями, которую просто-напросто не с чем сравнивать. Тест сферичности Моучли вместе с поправками Гринхауса-Гейсера проводятся автоматически для RM-ANOVA с тремя или более группами при использовании функции ezANOVA(), так что особо париться над этим не стоит. Правда, нужно помнить, что как и все подобные статистические тесты допущений, они обладают проблемами, связанными с тем, что это статистические тесты: на маленьких выборках они не заметят даже серьезных отклонений от сферичности, на больших - даже маленькие отклонения, а \\(p-value &lt; 0.05\\), по сути, не может интерпретироваться как верность нулевой гипотезы. Тем не менее, это довольно стандартная процедура. Как правильно репортить результаты дисперсионного анализа. Здесь все, конечно, зависит от стиля, используемого конкретным журналом. В психологии и близких к ней дисциплинам фактическим lingua franca является стиль Американской Психологической Ассоциации (APA). И тут у меня есть для Вас хорошие новости: есть куча пакетов в R, которые позволяют репортить результаты статистических тестов в APA-стиле! Спасибо дотошным авторам руководства APA по офромлению статей, что этот стиль настолько точно прописывает, как нужно описывать результаты исследований, что это можно запрограммировать. Я лично пользуюсь пакетом apa, он весьма удобен: library(apa) anova_apa(anova_by_ez, format = &quot;rmarkdown&quot;) ## Dietf: *F*(2, 73) = 5.38, *p* = .007, $\\eta^2_p$ = .13 В тексте это будет выглядеть это будет вот так: Dietf: F(2, 73) = 5.38, p = .007, \\(\\eta^2_p\\) = .13 Еще есть пакет Андрея Четверикова APAstats, пакеты apaStyle и papaja, которые могут даже сразу делать весь документ в APA-формате! Если же Вы описываете результаты самостоятельно вручную, то нужно помнить: ни в коем случае не описывайте только p-value. Обязательно прописывайте значение \\(F\\) и степени свободы, желательно с размером эффекта. Для post-hoc теста часто репортятся только p-value (зачастую только для статистически значимых сравнений), но обязательно нужно прописывать какие именно post-hoc тесты проводились, какой показатель размера эффекта использовался (если использовался), применялись ли тест сферичности Моучли вместе с поправками Гринхауса-Гейсера для дисперсионного анализа с повторными измерениями. Модели со смешанными эффектами (mixed-effects models) / иерархическая регрессия (hierarchical regression) / многоуровневое моделирование (multilevel modelling). очень популярный нынче метод, которому повезло иметь много названий - в зависимости от области, в которой он используется. В экспериментальной психологии обычно он называется “модели со смешанными эффектами” и позволяет включать в линейную регрессию не только фиксированные эффекты (fixed effects), но и случайные эффекты (random effects). Для экспериментальной психологии это интересно тем, что в таких моделях можно не усреднять показатели по испытуемым, а учитывать влияние группирующей переменной “испытуемый” как случайный эффект. Подобные модели используются в самых разных областях. Для их использования в R есть два известных пакета: nlme и lme4. "],
["ind.html", "8 День 7. Самостоятельный проект", " 8 День 7. Самостоятельный проект — Исследование и препроцессинг данных, выбор методов анализа — Формулировка гипотез и статистический анализ — Выводы, интерпретация и визуализация — Презентация результатов и обсуждение с другими участниками "]
]
