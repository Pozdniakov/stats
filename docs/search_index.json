[
["index.html", "Статистика, R и анализ данных 1 Начало работы", " Статистика, R и анализ данных Поздняков Иван, Петухова Татьяна 2019-04-08 1 Начало работы Здесь будут лежать конспекты занятий, задания и другие материалы. Сайт сделан с помощью RMarkdown, все исходные .RMD файлы лежат на гитхабе "],
["intro.html", "2 День 1. Основы R", " 2 День 1. Основы R — Презентация плана программы: краткий overview — Введение в R и RStudio — Операторы, функции — Создание переменных — Типы данных: вектора, матрицы, списки, датафреймы — Импорт данных You can label chapter and section titles using {#label} after them, e.g., we can reference Chapter 2. If you do not manually label them, there will be automatic labels anyway, e.g., Chapter ??. Figures and tables with captions will be placed in figure and table environments, respectively. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Рисунок 2.1: Here is a nice figure! Reference a figure by its code chunk label with the fig: prefix, e.g., see Figure 2.1. Similarly, you can reference tables generated from knitr::kable(), e.g., see Table 2.1. knitr::kable( head(iris, 20), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Таблица 2.1: Here is a nice table! Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa 5.7 4.4 1.5 0.4 setosa 5.4 3.9 1.3 0.4 setosa 5.1 3.5 1.4 0.3 setosa 5.7 3.8 1.7 0.3 setosa 5.1 3.8 1.5 0.3 setosa You can write citations, too. For example, we are using the bookdown package (Xie 2019) in this sample book, which was built on top of R Markdown and knitr (Xie 2015). References "],
["real.html", "3 День 2. Работа с реальными данными в R", " 3 День 2. Работа с реальными данными в R — Препроцессинг данных в R — Работа с пакетами — Работа со строками — Создание функций — Циклы и семейство функций apply — Решейпинг и агрегация данных — Пакеты data.table, dplyr "],
["vis.html", "4 День 3. Описательная статистика и визуализация", " 4 День 3. Описательная статистика и визуализация — Описательная статистика (центральные тенденции, меры разброса, skewness, kurtosis, функции для описательной статистики) — Визуализация в R, базовые средства визуализации и ggplot2 — Plotly — Создание publication-quality графиков, пакет cowplot — Самостоятельное упражнение на визуализацию — RMarkdown "],
["nhst.html", "5 День 4. Статистические оценки и проверка гипотез", " 5 День 4. Статистические оценки и проверка гипотез — Выборка и генеральная совокупность — Виды распределений, параметры распределений — Нормальное распределение. Функции распределений в R — Оценка параметров, точечные и интервальные оценки, доверительный интервал — Проверка гипотез. Ошибки I и II рода — Нулевая и альтернативная гипотеза, p-value — Мощность. z-критерий. t-критерий в случае одной и двух выборок, связанные выборки — Когда применять параметрические, а когда непараметрические методы — Рассчитаем критерии своими руками и изучим готовые функции R "],
["lm.html", "6 День 5. Линейная регрессия и корреляция", " 6 День 5. Линейная регрессия и корреляция — Линейная регрессионная модель — Коэффициенты линейной модели — Множественная линейная регрессия — Предположения линейной модели. “Остатки”, МНК и goodness-of-fit — Обобщенная линейная регрессия — Корреляция. Ковариация, коэффициент корреляции Пирсона — Ранговая корреляция. Частная и множественная корреляция "],
["anova.html", "7 День 6. ANOVA и продвинутые методы препроцессинга 7.1 Введение в ANOVA 7.2 Тестирование значимости нулевой гипотезы в ANOVA. 7.3 Post-hoc тесты 7.4 Другие способы проведения ANOVA в R. 7.5 Factorial ANOVA (Многофакторный ANOVA) 7.6 ANCOVA (ANalysis of COVAriance; Ковариационный анализ) 7.7 Repeated measures ANOVA (Дисперсионный анализ с повторными измерениями) 7.8 Смешанный внутригрупповой-межгрупповой дисперсионный анализ (Mixed between-within-subjects ANOVA) 7.9 Непараметрические аналоги ANOVA 7.10 Заключение", " 7 День 6. ANOVA и продвинутые методы препроцессинга — Дисперсионный анализ (ANOVA) — Однофакторный и многофакторный ANOVA — Анализ повторных измерений. Непараметрические аналоги ANOVA — Пропущенные значения и нормализация — Зачем нужны кластерный анализ, MDS и PCA в работе с биологическими данными На финальном занятии мы разберем дисперсионный анализ (ANalysis Of VAriance, ANOVA). Пожалуй, это самый распространенный статистический метод в экспериментальной психологии и многих других дисциплинах. Он очень хорошо подходит под использование для экспериментальных дизайнов, т.е. для исследовательских планов, в которых мы напрямую управляем уровнями независимой переменной. Связь ANOVA и экспериментирования настолько тесная, что некоторые термины пересекатся, но всегда нужно быть осторожными. Как и в случае с линейной регрессией, если мы переменную называем “предиктором”, это не дает ей никакой дополнительной каузальной силы. Так же и с ANOVA: мы можем называть какие-то переменные “независимыми”, а какие-то “зависимыми”, но это не означает автоматически каузальной связи. Просто терминология экспериментирования и ANOVA слишком тесно переплетены исторически. У дисперсионного анализа есть много разновидностей, которые мы сегодня и будем разбирать, начиная с обычного межгруппового дисперсионного анализа (One-Way ANOVA), заканчивая сложными вариантами этого метода, такими как ANCOVA, факторная ANOVA и ANOVA с повторными измерениями. Здесь будут часто употребляться как термин ANOVA, так и дисперсионный анализ. Это одно и то же. В русскоязычных статьях обычно пишут “дисперсионный анализ”, но в быту все говорят “анова”. Так проще. Зачем нам вообще нужен ANOVA? Ранее мы разбирали как сравнивать средние для двух групп с помощью т-теста. Но что если у нас больше двух групп? В принципе, можно использовать много попарных т-тестов и использовать поправки на множественные сравнения (и мы это сегодня будем делать, но попозже). Но обычно делается сравнение сразу всех групп с помощью дисперсионного анализа. Не дайте названию ввести Вас в заблуждение! Дисперсионный анализ - это все то же сравнение средних, только сразу для нескольких групп. Давайте в этот раз сразу начнем с проведением теста. Мы будем использовать данные с курса по статистике Университета Шеффилда про эффективность диет. library(&quot;data.table&quot;) diet &lt;- fread(&quot;stcp-Rdataset-Diet.csv&quot;) Да, в этот раз не так весело, просто диеты и их влияние на вес. Увы, даже информации про диеты нет: просто сухие цифры 1, 2 и 3… Зато этот датасет достаточно удобен, понятен и достаточно репрезентативен относительно того, какие данные могут получиться в результате эксперимента. Итак, начнем с того, что немного причешем наш датасет. В данном датасете есть несколько пропущенных значений: sum(!complete.cases(diet)) ## [1] 2 Давайте просто удалим их: diet &lt;- na.omit(diet) Мы посчитаем переменную weight.loss - разница до и после. А также сделаем факторной переменную Dietf из численной Diet, иначе 1, 2 и 3 будут читаться как численная переменная. То же самое сделаем для переменной, в которой записан id испытуемого. Осторожнее, с этим очень легко накосячить: если не перевести нужные численные переменные в факторы, то потом можно получить неверные результаты. А это гораздо хуже, чем просто получить ошибку! diet[, weight.loss := weight6weeks - pre.weight] diet[, Dietf := factor(Diet, labels = LETTERS[1:3])] diet[, Person := factor(Person)] Хотите понять, что за магия с LETTERS[1:3]? Все просто, это зашитая в R константа, примерно как число pi, только содержит все буквы латинского алфавита в виде character вектора. LETTERS выводит ЗАГЛАВНЫЕ буквы, а letters - строчные. Иногда это очень удобно. 7.1 Введение в ANOVA Давайте сразу возьмем быка за рога и попробуем провести тест: summary(aov(weight.loss ~ Dietf, diet)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Dietf 2 60.5 30.264 5.383 0.0066 ** ## Residuals 73 410.4 5.622 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Хотя результат выглядит незнакомым, но этот синтаксис где-то мы это уже видели… Да ведь здесь все точно как в линейной регрессии! И действительно, если откроете хэлп по функции aov(), то увидите, что эта функция просто использует функцию lm(). Более того, можете даже попробовать вот так: summary(lm(weight.loss ~ Dietf, diet)) ## ## Call: ## lm(formula = weight.loss ~ Dietf, data = diet) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.7000 -1.6519 -0.1759 1.4420 5.3680 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -3.3000 0.4840 -6.818 2.26e-09 *** ## DietfB 0.0320 0.6776 0.047 0.96246 ## DietfC -1.8481 0.6652 -2.778 0.00694 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.371 on 73 degrees of freedom ## Multiple R-squared: 0.1285, Adjusted R-squared: 0.1047 ## F-statistic: 5.383 on 2 and 73 DF, p-value: 0.006596 Теперь мы получили привычный нам (по предыдущим занятиям) результат, даже значения p-value совпадают. Правда, больше почти ничего общего. Если присмотритесь, то обнаружите, что еще совпадает \\(F\\)-value/statistic и степени свободы. Что это за \\(F\\) и как его получают, мы и будем сегодня разбираться. 7.2 Тестирование значимости нулевой гипотезы в ANOVA. И снова мы повторим логику тестирования значимости нулевой гипотезы. Да-да, опять. Здесь все примерно так же, как и с предыдущими тестами. Формулирование нулевой и альтернативной гипотезы. Наша нулевая гипотеза говорит о том, что между группами нет различий: \\[H_0:\\mu_1 = \\mu_2 = ... = \\mu_n\\] Напоминаю, что греческие буквы означают, что речь идет не о статистиках выборки, а о параметрах генеральной совокупности: нам интересно знать, действительно ли диеты по разному влияют на людей вообще, а не на данной конкретной выборке. Иначе нам достаточно было бы просто посчитать средние и идти пить чай. А вот какая будет альтернативная гипотеза? Хочется сказать, что “все средние различаются друг от друга”, но это не так. На самом деле, альтернативная гипотеза звучит так, что есть хотя бы одна пара групп, где средние не равны. \\[H_1: \\text{Не все средние равны}\\] Подсчет статистики. Мы уже использовали разные статистики (\\(z\\), \\(t\\) и т.п.) для тестирования гипотез. Теперь к ним добавится новая - \\(F\\). Вот ее мы и посчитаем с помощью таблицы ANOVA. Таблица ANOVA Степени свободы Суммы квадратов Средние квадраты F-статистика Межгрупповые \\(df_{b}\\) \\(SS_{b}\\) \\(MS_{b} =\\frac{SS_{b}}{df_{b}}\\) \\(F=\\frac{MS_{b}}{MS_{w}}\\) Внутригрупповые \\(df_{w}\\) \\(SS_{w}\\) \\(MS_{w} =\\frac{SS_{w}}{df_{w}}\\) Общие \\(df_{t}\\) \\(SS_{t}= SS_{b} + SS_{w}\\) Именно эту таблицу мы видели в аутпуте функции aov(): summary(aov(weight.loss ~ Dietf, diet)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Dietf 2 60.5 30.264 5.383 0.0066 ** ## Residuals 73 410.4 5.622 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Здесь вместо between groups (между группами) - Dietf, а вместо within groups (внутри групп) - Residuals. И действительно, внутригрупповые суммы квадратов - это “остатки” (residuals), которые мы не смогли объяснить разницами между диетами. Теперь пришло время разобраться с каждой клеточкой этой таблицы, а заодно и погрузиться в суть дисперсионного анализа. Давайте осторожно и без лишних криков взглянем на формулы: Таблица ANOVA Степени свободы Суммы квадратов Средние квадраты F-статистика Между \\(df_{b}=J-1\\) \\(SS_{b}= \\sum\\limits_{j=1}^J \\sum\\limits_{i=1}^{n_j} (\\overline{x_j}-\\overline{x})^2\\) \\(MS_{b} =\\frac{SS_{b}}{df_{b}}\\) \\(F=\\frac{MS_{b}}{MS_{w}}\\) Внутри \\(df_{w}=N-J\\) \\(SS_{w}= \\sum\\limits_{j=1}^J \\sum\\limits_{i=1}^{n_j} (x_{ij}-\\overline{x_j})^2\\) \\(MS_{w} =\\frac{SS_{w}}{df_{w}}\\) Общие \\(df_{t}=N-1\\) \\(SS_{t}= \\sum\\limits_{j=1}^J \\sum\\limits_{i=1}^{n_j} (x_{ij}-\\overline{x})^2\\) \\(J\\) означает количество групп, \\(N\\) - общее количество наблюдений во всех группах, \\(n_j\\) означает количество наблюдений в группе j, а \\(x_{ij}\\) - наблюдение под номером \\(i\\) в группе \\(j\\). Да, тут много формул, верно. Но суть довольно проста. Есть вариабельность зависимой переменной: как потеря веса распределена между испытуемыми. Она складывается из вариабельности внутри групп и между группами: \\(SS_t = SS_b +SS_w\\). Вариабельность обозначается \\(SS\\) и означает “сумму квадратов” (sum of squares) - это то же, что и дисперсия, только мы не делим вме в конце на количество наблюдений (или количество наблюдений минус один): \\[SS = \\sum\\limits_{i=1}^{n_j} (x_{i}-\\overline{x})^2\\] Мы здесь считаем три суммы квадратов: общие, внутригрупповые и межгрупповые. При этом \\(SS_t = SS_b +SS_w\\), то есть общие суммы квадратов “раскладываются” на межгрупповые и внутригрупповые (см. рисунок ). Рисунок 7.1: Суммы квадратов в ANOVA Если попробуем это представить зрительно, то эти три суммы квадратов будут выглядеть примерно как на рисунке ## ## Attaching package: &#39;cowplot&#39; ## The following object is masked from &#39;package:ggplot2&#39;: ## ## ggsave Рисунок 7.2: Общая вариабельность, межгрупповая вариабельность и внутригрупповая вариабельность в ANOVA. На картинке это сложно отразить, поэтому поясняю словами, что, собственно, “квадраты” означают не сами расстояния, нарисованные палочками, а их квадраты. Можете мысленно представить, что каждая такая вертикальная палочка - это сторона квадрата. Площади этих квадратов мы суммируем. sumofsquares &lt;- function(x) sum((x - mean(x))^2) totalss &lt;- sumofsquares(diet$weight.loss) diet[,lossbydiet := mean(weight.loss), by = Dietf] withinss &lt;- diet[, sum((weight.loss - lossbydiet)^2)] betweenss &lt;- diet[, sum((lossbydiet - mean(weight.loss))^2)] Обновим нашу табличку, поставив полученные суммы квадратов вмета формул: Таблица ANOVA Степени свободы Суммы квадратов Средние квадраты F-статистика Между \\(df_{b}=J-1\\) \\(SS_{b}=\\) 60.53 \\(MS_{b} =\\frac{SS_{b}}{df_{b}}\\) \\(F=\\frac{MS_{b}}{MS_{w}}\\) Внутри \\(df_{w}=N-J\\) \\(SS_{w}=\\) 410.4 \\(MS_{w} =\\frac{SS_{w}}{df_{w}}\\) Общие \\(df_{t}=N-1\\) \\(SS_{t}=\\) 470.93 Кстати, что будет, если поделить межгрупповую сумму квадратов на общую сумму квадратов? betweenss/totalss ## [1] 0.1285269 Получится \\(R^2\\). Помните, мы использовали \\(R^2\\)(коэффициент детерминации) в линейной регрессии для оценки модели? Логично: это соотношение объясненной дисперсии к общей, не может быть меньше нуля и больше единицы. Перед суммами квадратов стоят степени свободы. В отличие от т-теста, когда у нас был один показатель степени свободы, у нас здесь два показателя. Один из них связан с размером групп, другой - с размером выборки: totaldf &lt;- diet[,.N] - 1 betweendf &lt;- diet[,nlevels(Dietf)] - 1 withindf &lt;- diet[,.N] - diet[,nlevels(Dietf)] Хитрая функция nlevels() просто позволяет посчитать количество уровней фактора. Добавим в табличку степени свободы: Таблица ANOVA Степени свободы Суммы квадратов Средние квадраты F-статистика Между \\(df_{b}=\\) 2 \\(SS_{b}=\\) 60.53 \\(MS_{b} =\\frac{SS_{b}}{df_{b}}\\) \\(F=\\frac{MS_{b}}{MS_{w}}\\) Внутри \\(df_{w}=\\) 73 \\(SS_{w}=\\) 410.4 \\(MS_{w} =\\frac{SS_{w}}{df_{w}}\\) Общие \\(df_{t}=\\) 75 \\(SS_{t}=\\) 470.93 Теперь нужно посчитать средние квадраты (mean squares): нужно разделить суммы квадратов на соответствующие степени свободы. withinms &lt;- withinss/withindf betweenms &lt;- betweenss/betweendf Почти готово. Используемая нами в ANOVA статистика F - это отношение межгрупповых средних квадратов к внутригрупповым средним квадратам: f &lt;- betweenms/withinms f ## [1] 5.383104 Все, готово: Таблица ANOVA Степени свободы Суммы квадратов Средние квадраты F-статистика Между \\(df_{b}=\\) 2 \\(SS_{b}=\\) 60.53 \\(MS_{b} =\\) 30.26 \\(F=\\) 5.38 Внутри \\(df_{w}=\\) 73 \\(SS_{w}=\\) 410.4 \\(MS_{w} =\\) 5.62 Общие \\(df_{t}=\\) 75 \\(SS_{t}=\\) 470.93 Подсчет p-value. Помните, как это происходило в т-тесте? Мы смотрели, как статистика распределена при верности нулевой гипотезы (то есть при отсутствии различий в генеральной совокупности). Потом мы считали вероятность получения нашей статистики (или более экстремальной) как площадь под кривой от нашего \\(t\\) и до бесконечности. Мы еще умножали эту вероятность на 2, чтобы наш тест был двусторонним, но этого нам делать не нужно в случае ANOVA и \\(F\\)-статистики. Почему? Давайте взглянем на распределение \\(F\\). Его форма сильно зависит от двух степеней свобод. Давайте нарисуем это распределение. Для этого нам понадобится функция df (из семейства функций для F-распределения: df(), pf(), qf(), rf()). См. рисунок . v &lt;- seq(0.1,10, 0.01) fdist &lt;- data.frame(fvalues = v, pdf = df(v, betweendf, withindf)) library(ggplot2) label &lt;- paste0(&quot;F(&quot;, betweendf, &quot;, &quot;, withindf, &quot;) = &quot;, round(f, 3)) ggplot(fdist, aes(x = fvalues, y = pdf))+ geom_line()+ geom_vline(xintercept = f)+ annotate(&quot;text&quot;, x = f+1, y = 0.2, label = label)+ scale_y_continuous(expand=c(0,0)) + theme_minimal()+ theme(axis.line.y = element_blank(), axis.ticks.y = element_blank(), axis.text.y = element_blank(), axis.title.y = element_blank()) Рисунок 7.3: F-распределение при верности нулевой гипотезы (см. детали в тексте) Оно вообще ни разу не симметричное! Поэтому нам нужно считать только площадь от нашего \\(F\\) до плюс бесконечности. Здесь это не очень много. Чем больше \\(F\\), тем больше соотношение межгрупповой вариабельности (интересующие нас различия плюс “шум”) к внутригрупповой (необъясненный “шум” измерения). На самом деле, \\(F\\)-распределение отнюдь не всегда выглядит так. С другими степенями свободами (т.е. с другим количеством групп и наблюдений) его форма будет совсем другая (см. рисунок ) . Но \\(F\\)-статистика никогда не может быть меньше нуля. Просто потому, что средние квадраты - это всегда какие-то положительные значения. Рисунок 7.4: F-распределения с разными степенями свободы. Картинка взята из Википедии Итак, чтобы подсчитать p-value нам нужно просто воспользоваться функцией pf() подставив в качестве аргументов нашу \\(F\\)-статистику и нужные степени свободы (два значения). Это будет площадь под кривой плотности вероятности от нуля до \\(F\\). Поскольку нас интересует площадь от \\(F\\) до плюс бесконечности, то результат pf() нужно вычесть из единицы: 1 - pf(f, betweendf, withindf) ## [1] 0.006595853 Отлично, последний этап - сравнение p-value с нашим уровнем \\(\\alpha\\), который по дефолту 0.05. Ну и действительно, p-value меньше 0.05, поэтому мы можем отвергнуть нулевую гипотезу, что средние всех групп в генеральной совокупности одинаковые. Но можем ли мы сделать вывод, какие именно группы различаются? По одному ANOVA, увы, нет. Для этого нам нужно провести post-hoc тесты. 7.3 Post-hoc тесты Post-hoc с латинского переводится как “после этого”. Post-hoc тесты проводятся в случае, если Вы уже отвергли нулевую гипотезу ANOVA, но хотите узнать, какие именно группы различаются между собой. И здесь мы снова встречаемся с проблемой множественных сравнений (как и в случае с корреляцией всего со всем). Условно говоря, здесь есть два основных подхода для проведения post-hoc тестов: Применение различных поправок к результатам т-тестов - это мы уже проходили. Поправка Бонферрони, поправка Холма и т.п. Процедура ничем не отличается от того, что мы делали с корреляциями, только теперь у нас т-тесты вместо корреляций. Есть удобная функция pairwise.t.test() для этого: pairwise.t.test(diet$weight.loss, diet$Dietf) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: diet$weight.loss and diet$Dietf ## ## A B ## B 0.962 - ## C 0.017 0.017 ## ## P value adjustment method: holm Мы видим, что при использовании поправки Холма есть различия между результатами диет А и С, В и С, но различия между А и В нет значимых различий. Другой подход - специальные post-hoc тесты для сравнения нескольких групп. Как и в случае с поправками, есть более и менее консервативные варианты, есть довольно специфические, например, тест Даннетта (Dunnett’s test): он позволяет сравнить несколько средних с одним контролем (например, плацебо). Ну а самый распространенный post-hoc тест - это тест Тьюки (Tukey Honest Significant Differences = Tukey HSD). Для этого в R есть простая функция TukeyHSD(), которая применяется к аутпуту функции aov() - объекту класса aov(): modelanova &lt;- aov(weight.loss ~ Dietf, diet) TukeyHSD(modelanova) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = weight.loss ~ Dietf, data = diet) ## ## $Dietf ## diff lwr upr p adj ## B-A 0.032000 -1.589085 1.6530850 0.9987711 ## C-A -1.848148 -3.439554 -0.2567422 0.0188047 ## C-B -1.880148 -3.454614 -0.3056826 0.0152020 Здесь мы видим результаты сравнения каждой группы с каждой, доверительный интервал и уровень значимости (\\(p_{adj}\\) - скорректированный p-value). Результат здесь получился примерно такой же, как и в случае с использованием поправки Холма: результаты использования диет C и А, С и В статистически значимо различаются (при \\(\\alpha\\) равной 0.05), а между А и В не обнаружено статистически значимых различий. 7.4 Другие способы проведения ANOVA в R. Встроенная функция aov() довольно удобная для проведения простой ANOVA. modelanova &lt;- aov(weight.loss ~ Dietf, diet) summary(modelanova) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Dietf 2 60.5 30.264 5.383 0.0066 ** ## Residuals 73 410.4 5.622 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Более того, мы уже обнаружили, что можно применить функцию lm() - это даст такие же результаты. Это может показаться странным, ведь мы раньше использовали в линейной регрессии только численные предикторы. Мы уже пробовали когда-то использовать дихотомические предикторы (когда у нас два уровня, которые могут быть представлены как 0 и 1), чтобы убедиться, что получаем такие же результаты, как и для т-теста. Но что если у нас три группы? Тогда функция lm() автоматически создает новые переменные с помощью так называемого dummy coding. 7.4.1 Dummy coding Dummy coding - это способ превратить номинальную (качественную) переменную в набор количественных. Для этого мы можем просто создать новые переменные типа “является ли эта диета диетой Х”, где Х - тип диеты. Давайте сделаем это. diet[,isA:= as.numeric(Dietf == &quot;A&quot;)] diet[,isB:= as.numeric(Dietf == &quot;B&quot;)] diet[,isC:= as.numeric(Dietf == &quot;C&quot;)] diet[c(1:2,15:16,35:36),c(&quot;Dietf&quot;, &quot;isA&quot;, &quot;isB&quot;, &quot;isC&quot;)] ## Dietf isA isB isC ## 1: A 1 0 0 ## 2: A 1 0 0 ## 3: B 0 1 0 ## 4: B 0 1 0 ## 5: C 0 0 1 ## 6: C 0 0 1 Заметьте, что один (любой) столбик здесь лишний. Если выбранная диета не является диетой В и не является диетой С, то, очевидно, это диета А (если у нас нет других диет - хорошо, что в жизни это не так). Поэтому для dummy coding мы можем удалить одну из колонок: diet[, isA := NULL] А теперь используем новые колонки в качестве предикторов для линейной регрессии: summary(lm(weight.loss ~ isB + isC, diet)) ## ## Call: ## lm(formula = weight.loss ~ isB + isC, data = diet) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.7000 -1.6519 -0.1759 1.4420 5.3680 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -3.3000 0.4840 -6.818 2.26e-09 *** ## isB 0.0320 0.6776 0.047 0.96246 ## isC -1.8481 0.6652 -2.778 0.00694 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.371 on 73 degrees of freedom ## Multiple R-squared: 0.1285, Adjusted R-squared: 0.1047 ## F-statistic: 5.383 on 2 and 73 DF, p-value: 0.006596 Для сравнения, сделаем линейную регрессию с категориальным предиктором без dummy coding: anova_as_lm &lt;- lm(weight.loss ~ Dietf, diet) summary(anova_as_lm) ## ## Call: ## lm(formula = weight.loss ~ Dietf, data = diet) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.7000 -1.6519 -0.1759 1.4420 5.3680 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -3.3000 0.4840 -6.818 2.26e-09 *** ## DietfB 0.0320 0.6776 0.047 0.96246 ## DietfC -1.8481 0.6652 -2.778 0.00694 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.371 on 73 degrees of freedom ## Multiple R-squared: 0.1285, Adjusted R-squared: 0.1047 ## F-statistic: 5.383 on 2 and 73 DF, p-value: 0.006596 Абсолютно то же самое! Более того, есть специальная функция anova(), которая возвращает таблицу ANOVA из объекта lm: anova(anova_as_lm) ## Analysis of Variance Table ## ## Response: weight.loss ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Dietf 2 60.53 30.2635 5.3831 0.006596 ** ## Residuals 73 410.40 5.6219 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 7.4.2 ANOVA как частный случай линейной регрессии Таким образом, ANOVA - это, в некотором смысле, просто частный случай линейной регрессии, когда предиктор представлен в номинальной шкале. В принципе, что ANOVA (со всеми ее разновидностями), что множественная линейная регрессия, что т-тест являются частными случаями общей линейной модели (general linear model). Не путать с обобщенной линейной моделью (generalized linear model)! Это еще более широкое обобщение, которое включает в себя как линейную, так и, например, логистическую регрессию. Да, с названием “обобщенная линейная модель” авторы несколько облажались, мне кажется. Если ANOVA - это линейная регрессия, то и требования к данным в ANOVA все те же, что и для линейной регрессии, правда, называются они немного по-другому. С нормальностью ошибок все так же - нужно, чтобы остатки (residuals) были распределены более-менее нормально (см. рисунок ). hist(residuals(modelanova)) Рисунок 7.5: Гистограмма распределения остатков Впрочем, довольно серьезные отклонения от нормальности для ANOVA не такая уж и проблема (если нет серьезных выбросов, а их мы бы заметили на гистограмме). Второе важное допущение - это гомогенность дисперсий, т.е. равенство дисперсий, т.е. то, что в случае линейной регрессии называют гомоскедастичностью. Если Вы подумали, что это слово придумали только чтобы запутать, то… возможно, Вы и правы. Гомогенность дисперий просто означает, что распределение ошибок не различается в зависимости от группы. diet$residuals &lt;- residuals(modelanova) ggplot(diet, aes(x = Dietf, y = residuals))+ geom_point() Рисунок 7.6: Вариабельность остатков в зависимости от группы Все вполне пристойно: нет какой-то одной группы, у которой разброс ошибок сильно больше (или меньше), чем у других (см. рисунок ). Впрочем, есть и более формальный способ оценить равенство дисперсий: с помощью теста Ливиня (Levene’s test). Для того, чтобы его провести мы воспользуемся новым пакетом ez (читается как “easy”). Он значительно упрощает проведение ANOVA, особенно при более сложных дизайнах, чем тот, который мы использовали, а заодно и проводит нужные дополнительные тесты. library(&quot;ez&quot;) #сначала install.packages(&quot;ez&quot;) если у Вас нет этого пакета ezANOVA(data = diet, dv = weight.loss, wid = Person, between = Dietf, detailed = T) ## Warning: Data is unbalanced (unequal N per group). Make sure you specified ## a well-considered value for the type argument to ezANOVA(). ## Coefficient covariances computed by hccm() ## $ANOVA ## Effect DFn DFd SSn SSd F p p&lt;.05 ges ## 1 Dietf 2 73 60.52701 410.4018 5.383104 0.006595853 * 0.1285269 ## ## $`Levene&#39;s Test for Homogeneity of Variance` ## DFn DFd SSn SSd F p p&lt;.05 ## 1 2 73 2.040419 160.8859 0.4629076 0.6312856 Другой способ провести тест Ливиня - функция leveneTest из пакета car: car::leveneTest(diet$weight.loss, diet$Dietf) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 2 0.4629 0.6313 ## 73 Пользоваться функцией ezANOVA() очень просто: нужно прописать данные в data, название зависимой переменной в dv, прописать переменную с id в wid (например, переменная с номером испытуемого, если такой нет, то нужно ее создать), а в between - групповую переменную. Почему between? Потому что это “обычный” ANOVA (он же One-way ANOVA) предполагает, что все измерения независимы друг от друга, т.е. что-то вроде расширения независимого т-теста. В результате мы получаем суммы квадратов, степени свободы, значение \\(F\\) и p-value. Кроме того, в аутпуте еще и любезно проставлена звездочка, если p-value меньше 0.05. На случай, если кто-то, продравшись через восемь семинаров по R и статистике, не может самостоятельно сравнить два числа друг с другом, да. Ладно, эти звездочки довольно удобны, что я тут придираюсь. Справа в первой строчке стоит что-то новое - это Generalized eta squared, размер эффекта для факторов ANOVA. Вообще, оценок размера эффекта для ANOVA много разных, и в них легко запутаться. Какой из них лучше - сложный вопрос, который выходит за рамки этого курса. Какого-то устоявшегося решения нет, к сожалению. Поэтому важно не просто отмечать размер эффекта, а какой именно из них используется. Что у них общего, так это то, что все они могут принимать значение от 0 до 1, причем чем больше значение размера эффекта, тем больше объясненная фактором дисперсия по отношению к необъясненной. Самые сложности начинаются, когда у нас много факторов в дисперсионном анализе. В однофакторной ANOVA разногласий поменьше (хотя они все равно есть), более того, в данном конкретном случае Generalized eta squared равен межгрупповой сумме квадратов, поделенной на общую сумму квадратов, то есть равен \\(R^2\\), который мы уже считали раньше: betweenss/totalss ## [1] 0.1285269 Это формула для обычной (нескорректированной) eta squared: \\[\\eta^2 = \\frac{SS_b}{SS_t}\\] 7.4.3 Обратно в aov! Последний важный момент в функции ezANOVA(), это возможность создать объект aov с помощью параметра return_aov = T, как будто бы мы пользовались функцией aov(). Это может пригодиться, например, для тех же post-hoc тестов: anova_by_ez &lt;- ezANOVA(data = diet, dv = weight.loss, wid = Person, between = Dietf, detailed = T, return_aov = T) ## Warning: Data is unbalanced (unequal N per group). Make sure you specified ## a well-considered value for the type argument to ezANOVA(). ## Coefficient covariances computed by hccm() summary(anova_by_ez$aov) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Dietf 2 60.5 30.264 5.383 0.0066 ** ## Residuals 73 410.4 5.622 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Вуаля! 7.5 Factorial ANOVA (Многофакторный ANOVA) Раньше мы говорили об One-Way ANOVA, что означает “однофакторную” ANOVA. Тем не менее, в отличие от т-тестов, мы можем исследовать влияние сразу нескольких категориальных переменных на зависимую переменную. В принципе, кардинальных различий нет, просто теперь у нас тестируются сразу несколько факторов. В статьях обычно обозначается количество факторов и уровней в них примерно так: “3x2x2 ANOVA”. В данном конкретном случае это означает, что была проведена трехфакторная ANOVA, причем в первом факторе было три уровня, а во втором и третьем - по два. Мы же сделаем 3x2 ANOVA с факторами “Диета” и “Пол”, с тремя диетами и двумя полами. Здесь у нас есть две гипотезы: что диета влияет на потерю веса и что пол, в целом, влияет на потерю веса. Последнее довольно странно, да. Но в факториальном дисперсионном анализе появляются гипотезы взаимодействия - “пересечения” факторов. В данном случае, это будет интерпретироваться как “разные диеты эффективны по-разному для разных полов”. Давайте нарисуем это для наглядности (см. рисунок ). Отображать на графике влияние больше чем одной переменной не так просто. Самый простой способ (особенно для ситуации двух категориальных независимых переменных с не очень большим количеством уровней) - нарисовать несколько линий. Небольший хинт: тот фактор, у которого больше уровней, лучше расположить по оси Х, а тот, у которого меньше уровней, как независимые линии. diet[, genderf:=factor(gender, labels = c(&quot;ж&quot;, &quot;м&quot;))] sem &lt;- function(x) sd(x)/sqrt(length(x)) pivot &lt;- diet[,.(meanloss = mean(weight.loss), se = sem(weight.loss)), by = .(Dietf, genderf)] library(ggplot2) pd = position_dodge(0.05) ggplot(pivot, aes(x = Dietf, y = meanloss, colour = genderf))+ geom_line(aes(group = genderf), position = pd)+ geom_pointrange(aes(ymin = meanloss - se, ymax = meanloss +se), position = pd) Рисунок 7.7: Пример взаимодействия двух переменных. Хотя в среднем диета С эффективнее остальных, она особенно эффективна для женщин. По крайней мере, так говорит картинка. Но хотелось бы узнать, насколько резонно переносить такие выводы на генеральную совокупность. Итак, у нас будет три гипотезы: о влиянии диеты, пола и их взаимодействия. Как это сделать в R? Давайте сделаем это с помощью функции aov() для начала: summary(aov(weight.loss ~ Dietf + genderf + Dietf:genderf, diet)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Dietf 2 60.5 30.264 5.629 0.00541 ** ## genderf 1 0.2 0.169 0.031 0.85991 ## Dietf:genderf 2 33.9 16.952 3.153 0.04884 * ## Residuals 70 376.3 5.376 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Пересечение факторов мы обозначили знаком :. Но можно и проще: summary(aov(weight.loss ~ Dietf * genderf, diet)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Dietf 2 60.5 30.264 5.629 0.00541 ** ## genderf 1 0.2 0.169 0.031 0.85991 ## Dietf:genderf 2 33.9 16.952 3.153 0.04884 * ## Residuals 70 376.3 5.376 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Вместо + мы использовали *, что авторматически создает нужные взаимодействия. Теперь же сделаем с помощью ezANOVA(). Чтобы задать несколько колонок, нам нужно использовать .(): ezANOVA(data = diet, dv = weight.loss, wid = Person, between = .(Dietf, genderf)) ## Warning: Data is unbalanced (unequal N per group). Make sure you specified ## a well-considered value for the type argument to ezANOVA(). ## Coefficient covariances computed by hccm() ## $ANOVA ## Effect DFn DFd F p p&lt;.05 ges ## 1 Dietf 2 70 5.61902602 0.00545568 * 0.138334829 ## 2 genderf 1 70 0.03137868 0.85990976 0.000448066 ## 3 Dietf:genderf 2 70 3.15320438 0.04884228 * 0.082645860 ## ## $`Levene&#39;s Test for Homogeneity of Variance` ## DFn DFd SSn SSd F p p&lt;.05 ## 1 5 70 5.092595 184.3742 0.3866936 0.8563347 Итак, взаимодействие оказалось статистически значимым, что поддерживает нашу гипотезу о том, что диеты по-разному эффективны для разных полов. 7.5.1 SS Type I, II, III Результаты немного отличаются, Вы заметили? Дело в том, что в ситуации несбалансированного ANOVA, т.е. когда в разных подгруппах разное количество наблюдений, возникает некоторая неопределенность на тему того, как считать сумму квадратов. У нас как раз несбалансированный дизайн (немного, но лучше избегать этого): diet[,.N, by = .(Dietf, genderf)] ## Dietf genderf N ## 1: A ж 14 ## 2: B ж 14 ## 3: C ж 15 ## 4: A м 10 ## 5: B м 11 ## 6: C м 12 Всего есть три типа, они так и называются SS (сумма квадратов) Type I, Type II, Type III. Разница, как видите, не очень большая, но если Вам стало интересно, то советую почитать здесь или здесь. Если коротко, то разница в том, считать ли сумму квадратов для фактора после “вычета” предыдущих эффектов (последовательно, SS Type I), после вычета всех остальных факторов (иерархически, SS Type II) или же после вычета всех остальных факторов и взаимодействий (SS Type III). Рисунок 7.8: SS Types I, II и III Функция aov() использует Type I SS (можете это проверить, поменяв порядок предикторов, - результат будет разный!), а в ezANOVA() используется по дефолту SS Type II, но это можно поменять с помощью параметра type = поставив 1, 2 или 3, соответственно. Если попробуете поставить type = 1, то увидите предупреждение, что этого делать не стоит, и авторы пакета надеются, что это делается исключительно в демонстрационных целях. Действительно, SS Type I рекомендуется избегать, а вот дискуссия между SS Type II и III - тот еще холивар. Ну, ладно, это холивар только для гиков, да и те понимают, что это слишком уж гикство для холиваров. Ок, так что же выбрать? В принципе, SS Type II рекомендуют больше. Или, на крайняк, SS Type III. Что бы Вы не выбрали (II или III), на Вашей стороне будет банда статистиков, которые будут топить за Вашу позицию. SPSS и SAS по умолчанию используют SS Type III. 7.6 ANCOVA (ANalysis of COVAriance; Ковариационный анализ) По названию выглядит как какой-то еще дофига сложный метод, да? Нет, все примерно как и раньше, только теперь появляется ковариата. Это дополнительная числовая переменная, которая (в идеале) объясняет значительную часть дисперсии зависимой переменной. Таким образом, если “вычесть” влияние этой переменной, то можно уменьшить внутригрупповую изменчивость, т.е. получить более выраженный эффект и повысить статистическую мощность. Давайте проведем ANCOVA с ковариатой “Height” (рост): ezANOVA(data = diet, dv = weight.loss, wid = Person, between = Dietf, between_covariates = Height, detailed = T) ## Warning: Data is unbalanced (unequal N per group). Make sure you specified ## a well-considered value for the type argument to ezANOVA(). ## Warning: Implementation of ANCOVA in this version of ez is experimental ## and not yet fully validated. Also, note that ANCOVA is intended purely as ## a tool to increase statistical power; ANCOVA can not eliminate confounds ## in the data. Specifically, covariates should: (1) be uncorrelated with ## other predictors and (2) should have effects on the DV that are independent ## of other predictors. Failure to meet these conditions may dramatically ## increase the rate of false-positives. ## Warning: Covariate&quot;Height&quot; is numeric and will therefore be fit to a linear ## effect. ## Coefficient covariances computed by hccm() ## $ANOVA ## Effect DFn DFd SSn SSd F p p&lt;.05 ges ## 1 Dietf 2 73 52.12043 412.7606 4.608956 0.01303194 * 0.1121156 ## ## $`Levene&#39;s Test for Homogeneity of Variance` ## DFn DFd SSn SSd F p p&lt;.05 ## 1 2 73 1.698883 168.4969 0.3680142 0.693384 В принципе, ANCOVA - это та же линейная регрессия (общая линейная модель), только в ней присутствуют как численные, так и номинальные переменные. 7.7 Repeated measures ANOVA (Дисперсионный анализ с повторными измерениями) Как и в случае с т-тестом, если мы хотим сравнить связанные выборки, то мы должны пользоваться несколько другими формулами. Очень часто “зависимые выборки” - это ситуация с внутригрупповым (within-group) дизайном эксперимента: каждый испытуемый получает все уровни независимой переменной на свою голову или любые другие части своего многострадального тела, а результат этого воздействия записывают. Другой частый вариант - это “до” и “после”. Ранее мы сравнивали изменения (gain score) до и после той или иной диеты. Тем не менее, обычно встречается использование значений до и после как отдельного фактора в так называемом within-subjects ANOVA или repeated measures ANOVA (RM-ANOVA; дисперсионный анализ с повторными измерениями). Если обычный дисперсионный анализ можно рассматривать как “расширение” независимого т-теста, то дисперсионный анализ с повторными измерениями - это своеобразное расширение зависимого т-теста. Только мы опять используем F-статистику Давайте проверим, является ли диета С эффективной, сравнив значения до или после. Для этого нам понадобится melt() для превращения широкого датафрейма в длинный: dietlong &lt;- melt(diet, measure = c(&quot;pre.weight&quot;, &quot;weight6weeks&quot;), variable = &quot;time&quot;, value = &quot;weight&quot;) ## Warning in melt.data.table(diet, measure = c(&quot;pre.weight&quot;, ## &quot;weight6weeks&quot;), : &#39;measure.vars&#39; [pre.weight, weight6weeks] are not all ## of the same type. By order of hierarchy, the molten data value column will ## be of type &#39;double&#39;. All measure variables not of type &#39;double&#39; will be ## coerced too. Check DETAILS in ?melt.data.table for more on coercion. Возьмем только диету С: dietlongC &lt;- droplevels(dietlong[Dietf == &quot;C&quot;,]) Функция droplevels() позволяет избавиться от лишних уровней переменных. Дело в том, что в нашем сабсете уже нет многих испытуемых, а вот запись в факторе Person о них сохранилось. Это может привести к ошибке в некоторых случаях. Теперь проведем RM-ANOVA: ezANOVA(dietlongC, dv = weight, wid = Person, within = time) ## $ANOVA ## Effect DFn DFd F p p&lt;.05 ges ## 2 time 1 26 124.6949 2.030459e-11 * 0.0986036 Пользуясь функцией aov(), нужно прописать переменную, которая группирует ответы одного испытуемого, с помощью Error(): summary(aov(weight ~ time +Error(as.factor(Person)), dietlongC)) ## ## Error: as.factor(Person) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Residuals 26 3196 122.9 ## ## Error: Within ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## time 1 357.8 357.8 124.7 2.03e-11 *** ## Residuals 26 74.6 2.9 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Принципиальное отличие от обычного ANOVA заключается в том, что внутригрупповые суммы квадратов могут быть разделены на две части: “ошибку” (сумму квадратов остатков) и межиндивидуальные различия. Последние мы можем вычесть, что даст нам большую мощность, чем если бы мы просто сравнивали результаты после (см. рисунок ). Рисунок 7.9: Суммы квадратов в дисперсионном анализе с повторными измерениями 7.7.1 Пример расчета RM-ANOVA вручную Чтобы было понятнее, что происходит внутри, давайте посчитаем эту самую RM-ANOVA самостоятельно. Для начала возьмем для удобства сабсет из нашего исходного датасета в широком формате: dd &lt;- diet[Dietf == &quot;C&quot;,c(&quot;pre.weight&quot;, &quot;weight6weeks&quot;)] head(dd) ## pre.weight weight6weeks ## 1: 60 53.0 ## 2: 62 56.4 ## 3: 64 60.6 ## 4: 65 58.2 ## 5: 66 58.2 ## 6: 67 61.6 Формулы здесь немного сложнее, за счет того, что внутригрупповые суммы квадратов мы разделяем на индиудуальные и на остатки. Таблица ANOVA Степени свободы Суммы квадратов Средние квадраты F-статистика Между \\(df_{b}=J-1\\) \\(SS_{b}= n \\sum\\limits_{j=1}^J (\\overline{x_j}-\\overline{x})^2\\) \\(MS_{b} =\\frac{SS_{b}}{df_{b}}\\) \\(F=\\frac{MS_{b}}{MS_{e}}\\) Внутри \\(df_{w}=N-J\\) \\(SS_{w}= SS_t - SS_b\\) Индиви-дуальные \\(df_s = n-1\\) \\(SS_s= J \\sum\\limits_{i=1}^{n} (\\overline{x_i} -\\overline{x})^2\\) Остатки \\(df_e=N-J-n+1\\) \\(SS_e= SS_w - SS_s\\) \\(MS_{e} =\\frac{SS_{e}}{df_{e}}\\) Общие \\(df_{t}=N-1\\) \\(SS_{t}= J \\sum\\limits_{i=1}^{n_j} (x_{ij}-\\overline{x})^2\\) Посчитаем суммы квадратов: globalmean &lt;- mean(unlist(dd)) totalss &lt;- sum((unlist(dd) - globalmean)^2) Просто сумма квадратов по отношению к среднему всех значений betweenss &lt;- sum((apply(dd,2,mean) - globalmean)^2) * nrow(dd) Выглядит сложно, но это просто суммы квадратов средних по столбцам по отношению к среднему всех значений. withinss &lt;- totalss - betweenss Внутригрупповая сумма квадратов - это общая сумма квадратов минус межгрупповая. А теперь нам нужно разделить внутригрупповуюю сумму квадратов на части: subjss &lt;- sum((apply(dd,1,mean) - globalmean)^2)*ncol(dd) Вот это и есть наши межиндивидуальные различия. Заметьте, они составляют большую часть разброса данных. Это вполне логично: даже если диета весьма эффективная, разброс по весу у людей обычно гораздо больше предполагаемого эффекта и его разброса в выборке. errorss &lt;- withinss - subjss Теперь посчитаем степени свободы: totaldf &lt;- length(unlist(dd)) - 1 betweendf &lt;- ncol(dd) - 1 subjdf &lt;- nrow(dd) -1 withindf &lt;- totaldf - betweendf errordf &lt;- withindf - subjdf Осталось посчитать средние межгрупповые квадраты и средние квадраты ошибки… betweenms &lt;- betweenss/betweendf errorms &lt;- errorss/errordf … и поделить одно на другое, чтобы получить F: f &lt;- betweenms/errorms Итоговая таблица: Таблица ANOVA Степени свободы Суммы квадратов Средние квадраты F-статистика Между \\(df_{b}=\\) 1 \\(SS_{b}=\\) 357.8 \\(MS_{b} =\\) 357.8 \\(F=\\) 124.69 Внутри \\(df_{w}=\\) 52 \\(SS_{w}=\\) 3270.84 Индиви-дуальные \\(df_s=\\) 26 \\(SS_s=\\) 3196.23 Остатки \\(df_e=\\) 26 \\(SS_e=\\) 74.6 \\(MS_{e} =\\) 2.87 Общие \\(df_{t}=\\) 53 \\(SS_{t}=\\) 3628.63 \\(F\\) получился большой! Давайте теперь посмотрим, насколько получить такой или больше F при условии верности нулевой гипотезы: 1 - pf(f, betweendf, errordf) ## [1] 2.030465e-11 В данном конкретном случае мы могли применить просто зависимый т-тест, ведь у нас всего две выборки (до и после): t.test(dd$pre.weight,dd$weight6weeks, paired = T, var.equal = T) ## ## Paired t-test ## ## data: dd$pre.weight and dd$weight6weeks ## t = 11.167, df = 26, p-value = 2.03e-11 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 4.200493 6.095803 ## sample estimates: ## mean of the differences ## 5.148148 Заметьте, то же самое p-value. Более того, в случае двух выборок \\(F\\) - это просто квадрат от \\(t\\): t &lt;- t.test(dd$pre.weight,dd$weight6weeks, paired = T, var.equal = T)$statistic t ## t ## 11.16669 t^2 ## t ## 124.6949 7.8 Смешанный внутригрупповой-межгрупповой дисперсионный анализ (Mixed between-within-subjects ANOVA) Нам никто не запрещает совмещать оба типа ANOVA в одном тесте. В ezANOVA() это делается просто с помощью прописывания разных факторов в нужных переменных: between и within. ezANOVA(data = dietlong, wid = Person, dv = weight, between = Dietf, within = time) ## Warning: Data is unbalanced (unequal N per group). Make sure you specified ## a well-considered value for the type argument to ezANOVA(). ## $ANOVA ## Effect DFn DFd F p p&lt;.05 ges ## 2 Dietf 2 73 0.8280758 4.409507e-01 0.021710057 ## 3 time 1 73 210.5004045 3.346036e-23 * 0.059209996 ## 4 Dietf:time 2 73 5.3831045 6.595853e-03 * 0.003208607 Здесь нас интересует взаимодействие диеты и времени. Мы получили тот же самый результат, что и при обычном ANOVA на разницу между до и после. Что неудивительно! А вот если мы проведем ANCOVA на вес после с ковариатой “вес до”, то результат будет несколько другим. Разница в том, что в таком случае мы не просто “вычитаем” значение веса до диеты, но используем его как предиктор - с оценкой его коэффициента: ezANOVA(data = diet, wid = Person, dv = weight6weeks, between_covariate = pre.weight, between = Dietf) ## Warning: Data is unbalanced (unequal N per group). Make sure you specified ## a well-considered value for the type argument to ezANOVA(). ## Warning: Implementation of ANCOVA in this version of ez is experimental ## and not yet fully validated. Also, note that ANCOVA is intended purely as ## a tool to increase statistical power; ANCOVA can not eliminate confounds ## in the data. Specifically, covariates should: (1) be uncorrelated with ## other predictors and (2) should have effects on the DV that are independent ## of other predictors. Failure to meet these conditions may dramatically ## increase the rate of false-positives. ## Warning: Covariate&quot;pre.weight&quot; is numeric and will therefore be fit to a ## linear effect. ## Coefficient covariances computed by hccm() ## $ANOVA ## Effect DFn DFd F p p&lt;.05 ges ## 1 Dietf 2 73 4.957468 0.009576091 * 0.1195796 ## ## $`Levene&#39;s Test for Homogeneity of Variance` ## DFn DFd SSn SSd F p p&lt;.05 ## 1 2 73 3.654284 160.5353 0.8308538 0.4397546 7.9 Непараметрические аналоги ANOVA Как было описано выше, ANOVA довольно устойчив к разным отклонениям от нормальности и некоторой гетероскедастичности (разным дисперсиям в выборках). Но если уж у Вас данные ну совсем-совсем ненормальные, несимметричные, а от преобразований шкалы Вы по каким-то причинам отказались, то стоит упомянуть о непараметрических аналогах ANOVA. 7.9.1 Тест Краскела-Уоллеса Это тест Краскела-Уоллеса - обобщение теста Манна-Уитни на несколько выборок (т.е. аналог межгруппового ANOVA): kruskal.test(weight.loss ~ Dietf, diet) ## ## Kruskal-Wallis rank sum test ## ## data: weight.loss by Dietf ## Kruskal-Wallis chi-squared = 9.4159, df = 2, p-value = 0.009023 7.9.2 Тест Фридмана Для зависимых выборок есть тест Фридмана - непараметрический аналог дисперсионного анализа с повторными измерениями: friedman.test(weight ~ time | Person, dietlongC) ## ## Friedman rank sum test ## ## data: weight and time and Person ## Friedman chi-squared = 27, df = 1, p-value = 2.035e-07 7.10 Заключение Мы разобрали много разных вариантов дисперсионного анализа. Зачем так много? ANOVA - один из самых распространенных методов как в психологии, так и во многих других областях. Естественно, это отнюдь не все методы, используемые в той же психологии. Более того, некоторые вопросы остались за бортом. Постараюсь коротко их перечислить: многомерный ANOVA (Multivariate ANalysis Of Variance; MANOVA) - расширение ANOVA для ситуации нескольких зависимых переменных. Честно говоря, я практически не встречал применение этого метода на практике. тестирование сферичности для дисперсионного анализа с повторноми измерениями с помощью теста сферичности Моучли (Mauchly’s sphericity test). Этот тест проверяет использует матрицу ковариаций разниц каждого условия с каждым: дисперсии разниц между условиями должны быть примерно одинаковыми. Если нулевая гипотеза о сферичности может быть отброшена (p-value &lt; \\(\\alpha\\)), то нужно проводить специальные поправки, обычно это поправки Гринхауса-Гейсера (Greenhouse-Geisser corrections). Мы этого не делали, потому что в ситуации RM-ANOVA с всего двумя условиями эта сферичность никогда не нарушается: у нас всего одна дисперсия разниц между условиями, которую просто-напросто не с чем сравнивать. Тест сферичности Моучли вместе с поправками Гринхауса-Гейсера проводятся автоматически для RM-ANOVA с тремя или более группами при использовании функции ezANOVA(), так что особо париться над этим не стоит. Правда, нужно помнить, что как и все подобные статистические тесты допущений, они обладают проблемами, связанными с тем, что это статистические тесты: на маленьких выборках они не заметят даже серьезных отклонений от сферичности, на больших - даже маленькие отклонения, а \\(p-value &lt; 0.05\\), по сути, не может интерпретироваться как верность нулевой гипотезы. Тем не менее, это довольно стандартная процедура. Как правильно репортить результаты дисперсионного анализа. Здесь все, конечно, зависит от стиля, используемого конкретным журналом. В психологии и близких к ней дисциплинам фактическим lingua franca является стиль Американской Психологической Ассоциации (APA). И тут у меня есть для Вас хорошие новости: есть куча пакетов в R, которые позволяют репортить результаты статистических тестов в APA-стиле! Спасибо дотошным авторам руководства APA по офромлению статей, что этот стиль настолько точно прописывает, как нужно описывать результаты исследований, что это можно запрограммировать. Я лично пользуюсь пакетом apa, он весьма удобен: library(apa) anova_apa(anova_by_ez, format = &quot;rmarkdown&quot;) ## Dietf: *F*(2, 73) = 5.38, *p* = .007, $\\eta^2_p$ = .13 В тексте это будет выглядеть это будет вот так: Dietf: F(2, 73) = 5.38, p = .007, \\(\\eta^2_p\\) = .13 Еще есть пакет Андрея Четверикова APAstats, пакеты apaStyle и papaja, которые могут даже сразу делать весь документ в APA-формате! Если же Вы описываете результаты самостоятельно вручную, то нужно помнить: ни в коем случае не описывайте только p-value. Обязательно прописывайте значение \\(F\\) и степени свободы, желательно с размером эффекта. Для post-hoc теста часто репортятся только p-value (зачастую только для статистически значимых сравнений), но обязательно нужно прописывать какие именно post-hoc тесты проводились, какой показатель размера эффекта использовался (если использовался), применялись ли тест сферичности Моучли вместе с поправками Гринхауса-Гейсера для дисперсионного анализа с повторными измерениями. Модели со смешанными эффектами (mixed-effects models) / иерархическая регрессия (hierarchical regression) / многоуровневое моделирование (multilevel modelling). очень популярный нынче метод, которому повезло иметь много названий - в зависимости от области, в которой он используется. В экспериментальной психологии обычно он называется “модели со смешанными эффектами” и позволяет включать в линейную регрессию не только фиксированные эффекты (fixed effects), но и случайные эффекты (random effects). Для экспериментальной психологии это интересно тем, что в таких моделях можно не усреднять показатели по испытуемым, а учитывать влияние группирующей переменной “испытуемый” как случайный эффект. Подобные модели используются в самых разных областях. Для их использования в R есть два известных пакета: nlme и lme4. "],
["ind.html", "8 День 7. Самостоятельный проект", " 8 День 7. Самостоятельный проект — Исследование и препроцессинг данных, выбор методов анализа — Формулировка гипотез и статистический анализ — Выводы, интерпретация и визуализация — Презентация результатов и обсуждение с другими участниками "]
]
